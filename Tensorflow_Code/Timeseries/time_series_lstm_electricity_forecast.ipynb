{
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "version": "3.6.4",
      "file_extension": ".py",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "name": "python",
      "mimetype": "text/x-python"
    },
    "colab": {
      "name": "time-series-lstm-electricity-forecast",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/shuchimishra/Tensorflow_projects/blob/main/Tensorflow_Code/Timeseries/time_series_lstm_electricity_forecast.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "source": [
        "\n",
        "# IMPORTANT: RUN THIS CELL IN ORDER TO IMPORT YOUR KAGGLE DATA SOURCES\n",
        "# TO THE CORRECT LOCATION (/kaggle/input) IN YOUR NOTEBOOK,\n",
        "# THEN FEEL FREE TO DELETE THIS CELL.\n",
        "# NOTE: THIS NOTEBOOK ENVIRONMENT DIFFERS FROM KAGGLE'S PYTHON\n",
        "# ENVIRONMENT SO THERE MAY BE MISSING LIBRARIES USED BY YOUR\n",
        "# NOTEBOOK.\n",
        "\n",
        "import os\n",
        "import sys\n",
        "from tempfile import NamedTemporaryFile\n",
        "from urllib.request import urlopen\n",
        "from urllib.parse import unquote, urlparse\n",
        "from urllib.error import HTTPError\n",
        "from zipfile import ZipFile\n",
        "import tarfile\n",
        "import shutil\n",
        "\n",
        "CHUNK_SIZE = 40960\n",
        "DATA_SOURCE_MAPPING = 'electric-power-consumption-data-set:https%3A%2F%2Fstorage.googleapis.com%2Fkaggle-data-sets%2F122%2F260%2Fbundle%2Farchive.zip%3FX-Goog-Algorithm%3DGOOG4-RSA-SHA256%26X-Goog-Credential%3Dgcp-kaggle-com%2540kaggle-161607.iam.gserviceaccount.com%252F20240508%252Fauto%252Fstorage%252Fgoog4_request%26X-Goog-Date%3D20240508T014723Z%26X-Goog-Expires%3D259200%26X-Goog-SignedHeaders%3Dhost%26X-Goog-Signature%3D64443141516cfecae776beb6bd26a1a43e159b2b66002408720991644b781a01b35d765e26e5372f59c59427a88cba8b86d2282b11f4661d29ea78d28852d714dacee877bfea3371d737922261e2191bb2344578c5557d0499aa3760a269036a544a4ccbdd2be5c35a2356c32770b2a58ee719a29fad452d840b282a3f3c25c9286490cd241a13a0115901e44c7a7e0c1ac46cc3a72ddbb831316b24e2ba8604f8179b2c9b7dc9e98559777473d4cd7f3cf186df6e3c55a7c8269a55a34e2a36bdce745b043ac17d5bcb7fcffa550ffe8948371c6bfa67d082bf6ef271950eced246f98f324cfc50ed401bdb4b4e4ff958297c696e990ee7cff41e5ccc0cf2ba'\n",
        "\n",
        "KAGGLE_INPUT_PATH='/kaggle/input'\n",
        "KAGGLE_WORKING_PATH='/kaggle/working'\n",
        "KAGGLE_SYMLINK='kaggle'\n",
        "\n",
        "!umount /kaggle/input/ 2> /dev/null\n",
        "shutil.rmtree('/kaggle/input', ignore_errors=True)\n",
        "os.makedirs(KAGGLE_INPUT_PATH, 0o777, exist_ok=True)\n",
        "os.makedirs(KAGGLE_WORKING_PATH, 0o777, exist_ok=True)\n",
        "\n",
        "try:\n",
        "  os.symlink(KAGGLE_INPUT_PATH, os.path.join(\"..\", 'input'), target_is_directory=True)\n",
        "except FileExistsError:\n",
        "  pass\n",
        "try:\n",
        "  os.symlink(KAGGLE_WORKING_PATH, os.path.join(\"..\", 'working'), target_is_directory=True)\n",
        "except FileExistsError:\n",
        "  pass\n",
        "\n",
        "for data_source_mapping in DATA_SOURCE_MAPPING.split(','):\n",
        "    directory, download_url_encoded = data_source_mapping.split(':')\n",
        "    download_url = unquote(download_url_encoded)\n",
        "    filename = urlparse(download_url).path\n",
        "    destination_path = os.path.join(KAGGLE_INPUT_PATH, directory)\n",
        "    try:\n",
        "        with urlopen(download_url) as fileres, NamedTemporaryFile() as tfile:\n",
        "            total_length = fileres.headers['content-length']\n",
        "            print(f'Downloading {directory}, {total_length} bytes compressed')\n",
        "            dl = 0\n",
        "            data = fileres.read(CHUNK_SIZE)\n",
        "            while len(data) > 0:\n",
        "                dl += len(data)\n",
        "                tfile.write(data)\n",
        "                done = int(50 * dl / int(total_length))\n",
        "                sys.stdout.write(f\"\\r[{'=' * done}{' ' * (50-done)}] {dl} bytes downloaded\")\n",
        "                sys.stdout.flush()\n",
        "                data = fileres.read(CHUNK_SIZE)\n",
        "            if filename.endswith('.zip'):\n",
        "              with ZipFile(tfile) as zfile:\n",
        "                zfile.extractall(destination_path)\n",
        "            else:\n",
        "              with tarfile.open(tfile.name) as tarfile:\n",
        "                tarfile.extractall(destination_path)\n",
        "            print(f'\\nDownloaded and uncompressed: {directory}')\n",
        "    except HTTPError as e:\n",
        "        print(f'Failed to load (likely expired) {download_url} to path {destination_path}')\n",
        "        continue\n",
        "    except OSError as e:\n",
        "        print(f'Failed to load {download_url} to path {destination_path}')\n",
        "        continue\n",
        "\n",
        "print('Data source import complete.')\n"
      ],
      "metadata": {
        "id": "eUKrSUT3hgUe",
        "outputId": "9b766f95-0b5b-42db-e721-1e6ce95f1937",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "cell_type": "code",
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading electric-power-consumption-data-set, 20357475 bytes compressed\n",
            "[==================================================] 20357475 bytes downloaded\n",
            "Downloaded and uncompressed: electric-power-consumption-data-set\n",
            "Data source import complete.\n"
          ]
        }
      ],
      "execution_count": 1
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Multi-Step LSTM Time-Series Forecasting Models for Power Usage**"
      ],
      "metadata": {
        "id": "dDMLvVnmfDDr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1. About the Data"
      ],
      "metadata": {
        "id": "e65c7d4c-e134-493e-949f-755466471726",
        "tags": []
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Data Source**\n",
        "\n",
        "[Household Electric Power Consumption from UCI Machine Learning Repository](https://archive.ics.uci.edu/ml/datasets/individual+household+electric+power+consumption)\n"
      ],
      "metadata": {
        "id": "WjWdMqSwylTd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Data Background**\n",
        "\n",
        "* The Household Power Consumption dataset is a multivariate time series dataset that describes the electricity consumption (with a one-minute sampling rate) for a single household over four years\n",
        "\n",
        "* The data contains 2,075,259 observations and 8 features (including timestamp) collected from a house in France between December 2006 and November 2010\n"
      ],
      "metadata": {
        "id": "P2fSkWUvynpl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Data Dictionary**\n",
        "\n",
        "|Variable|Definition|\n",
        "|:---|:---|\n",
        "|Datetime|yyyy-mm-dd hh:mm:ss\n",
        "|Global_active_power|The total active power in kilowatts (kW) consumed by the household\n",
        "|Global_reactive_power|The total reactive power in kilowatts (kW) consumed by the household\n",
        "|Voltage|Average voltage (V)\n",
        "|Global_intensity|Average current intensity (A)\n",
        "|Sub_metering_1|Active energy for kitchen in watt-hours (Wh)\n",
        "|Sub_metering_2|Active energy for laundry in watt-hours (Wh)\n",
        "|Sub_metering_3|Active energy for climate control systems in watt-hours (Wh)\n",
        "|Sub_metering_4$^{1}$|Active energy in watt-hours (Wh)"
      ],
      "metadata": {
        "id": "JEfGn_xtzm-z"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "$^{1}$Newly created feature using the following calculation: global_active_power * 1000/60 - (sub_metering_1 + sub_metering_2 + sub_metering_3)"
      ],
      "metadata": {
        "id": "gYYUBU4BhgUf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---"
      ],
      "metadata": {
        "id": "fXJ9YojghgUg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2. Business question\n",
        "\n",
        "* What is the expected household power usage for each day over the next seven days?\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "896UJK6zAYA1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3. Documentation summary and data insights"
      ],
      "metadata": {
        "id": "5afe530a-993c-4069-9893-5b106b934e39",
        "tags": []
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Exploratory data analysis, insights drawn from it and time-series modelling can be summarized as follows:\n",
        "\n",
        "|||\n",
        "|:---|:---|\n",
        "|**Initial data exploration:**|* The data set contains 8 features (including time) and 2,075,259 observations\n",
        "||* Column names were cleaned (strings to lower case)\n",
        "||* '?' were replaced with missing values ('NaN')\n",
        "||* Object datatypes were converted to float, all datatypes ended up being float\n",
        "||* Missing values (25,979 per feature) were imputed with a value at the same time one day ago\n",
        "||* A new feature 'sub_metering_4' was created, because the total energy consumption was larger than the sum of the three sub meters combined. The new feature was calculated as follows: global_active_power * 1000/60 - (sub_metering_1 + sub_metering_2 + sub_metering_3)\n",
        "||* Dataset spans 1441 days (2006-12-16 to 2010-11-26)\n",
        "||\n",
        "|**Data visualization:**|* 'voltage' is a constant and can therefore be dropped for subsequent analysis\n",
        "||**Histograms:**\n",
        "||* 'global_active_power' (power consumption) data was converted from per-minute sampling (2,075,259 observations) into total daily consumption (1442 observations)\n",
        "||* Target variable 'global_active_power' (total daily power consumption) is almost normally distributed with a slight positive skew\n",
        "||**Time series:**\n",
        "||* Target variable 'global_active_power' (total daily power consumption): time-series is stationary and shows seasonality. However, variance shows some variability. Exclude the first 5 months for modelling?\n",
        "||**Correlation heatmap:**\n",
        "||* 'global_intensity' is highly correlated with other features and should therefore be dropped before modelling\n",
        "||\n",
        "|**Test for stationarity:**|* Augmented Dicky-Fuller test concluded that the time series is stationary\n",
        "||\n",
        "|**Modelling:**|* A total of 4 multi-step LSTM prediction models were used, two based on univariate and two based on multivariate analysis\n",
        "||* For each analysis, two main types of LSTM models for multi-step forecasting were employed: Vector Output Model (Stacked LSTM) and Encoder-Decoder Model\n",
        "||* Data was split into 75% train (1082 observations) and 25% test (360 observations)\n",
        "||* The data was scaled using mean and standard deviation of the train set\n",
        "||* A sliding window approach was used to create multiple input/output samples (X, y) from the time-series sequence\n",
        "||* 14 days of past observations (input X) were used to forecast a 7-day period (output y), i.e. 1062 train and 340 test samples were created with 14 timesteps for X and 7 timesteps for y each\n",
        "||* Models were optimized using a loss function and learning curves were plotted showing training and validation loss\n",
        "||* Model prediction was performed on elements of the test set and plotted against actual data\n",
        "||* Evaluation metric RMSE was used to compare model performance\n",
        "||* Under the current conditions employed (i.e., number of input/output steps, model definitions, etc.), univariate models performed slightly better than multivariate models. However, it must be noted that the **models had not been tuned**, only the number of nodes were adjusted to reduce over-fitting\n",
        "||"
      ],
      "metadata": {
        "id": "cs5BoMk2wrJL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---"
      ],
      "metadata": {
        "id": "A4XQEx3IhgUh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 4. Loading Python libraries"
      ],
      "metadata": {
        "id": "436dc76b-698b-4e4b-88f0-b35eff84e29c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import random\n",
        "\n",
        "from matplotlib.ticker import StrMethodFormatter\n",
        "from statsmodels.tsa.stattools import adfuller\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, LSTM, Dropout, RepeatVector, TimeDistributed\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from tensorflow.keras.backend import clear_session\n",
        "\n",
        "from tensorflow.random import set_seed\n",
        "set_seed(42)\n",
        "\n",
        "%matplotlib inline"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-02-19T05:43:30.339288Z",
          "iopub.execute_input": "2023-02-19T05:43:30.339956Z",
          "iopub.status.idle": "2023-02-19T05:43:39.177641Z",
          "shell.execute_reply.started": "2023-02-19T05:43:30.339836Z",
          "shell.execute_reply": "2023-02-19T05:43:39.176699Z"
        },
        "trusted": true,
        "id": "bs0MolrwhgUh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.style.use('ggplot')"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-02-19T05:43:47.979791Z",
          "iopub.execute_input": "2023-02-19T05:43:47.980538Z",
          "iopub.status.idle": "2023-02-19T05:43:47.987053Z",
          "shell.execute_reply.started": "2023-02-19T05:43:47.980506Z",
          "shell.execute_reply": "2023-02-19T05:43:47.98529Z"
        },
        "trusted": true,
        "id": "A6NC0-ckhgUh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check library version\n",
        "print('Numpy: ', np.__version__)\n",
        "print('Pandas: ', pd.__version__)\n",
        "print('Seaborn: ', sns.__version__)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-02-19T05:43:50.036756Z",
          "iopub.execute_input": "2023-02-19T05:43:50.0376Z",
          "iopub.status.idle": "2023-02-19T05:43:50.043957Z",
          "shell.execute_reply.started": "2023-02-19T05:43:50.037547Z",
          "shell.execute_reply": "2023-02-19T05:43:50.042777Z"
        },
        "trusted": true,
        "id": "6Vuj0U8shgUh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---"
      ],
      "metadata": {
        "id": "d_FaG0-OhgUi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 5. Exploratory data analysis"
      ],
      "metadata": {
        "id": "5c56b5aa-ece2-4ab7-8791-db1b00759c89"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5.1. Loading data"
      ],
      "metadata": {
        "id": "51d9cb57-3a54-4fae-b10d-6e1078fe9bbe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
        "    for filename in filenames:\n",
        "        print(os.path.join(dirname, filename))"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-02-19T05:43:56.024221Z",
          "iopub.execute_input": "2023-02-19T05:43:56.024623Z",
          "iopub.status.idle": "2023-02-19T05:43:56.039588Z",
          "shell.execute_reply.started": "2023-02-19T05:43:56.024592Z",
          "shell.execute_reply": "2023-02-19T05:43:56.03878Z"
        },
        "trusted": true,
        "id": "mbTB-fJ_hgUi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('/kaggle/input/electric-power-consumption-data-set/household_power_consumption.txt', sep=';', header=0, low_memory=False,\n",
        "                 infer_datetime_format=True, parse_dates={'datetime':[0,1]}, index_col=0)"
      ],
      "metadata": {
        "trusted": true,
        "id": "dGX5m1AahgUi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5.2. Exploring and cleaning data"
      ],
      "metadata": {
        "id": "fa65da93-5b6e-4df0-a433-8f39173fa0a2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Check data dimension\n",
        "df.shape"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-02-19T05:47:15.918765Z",
          "iopub.execute_input": "2023-02-19T05:47:15.919217Z",
          "iopub.status.idle": "2023-02-19T05:47:15.929883Z",
          "shell.execute_reply.started": "2023-02-19T05:47:15.919182Z",
          "shell.execute_reply": "2023-02-19T05:47:15.927752Z"
        },
        "trusted": true,
        "id": "HMtwgHvnhgUi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Preview data\n",
        "df.head(5)"
      ],
      "metadata": {
        "id": "_tlF2iJohgUi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        " df.tail(5)"
      ],
      "metadata": {
        "id": "Qd--ArkchgUi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Clean column names\n",
        "df.columns = df.columns.str.lower()"
      ],
      "metadata": {
        "id": "WljStZt2hgUi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Summarize data\n",
        "df.info()"
      ],
      "metadata": {
        "id": "H8zasHnJhgUi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Generate descriptive statistics\n",
        "df.describe(include='all').T"
      ],
      "metadata": {
        "id": "T4HAkyaEhgUi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Replace '?' with missing value ('NaN') and check\n",
        "df.replace('?', 'NaN', inplace=True)\n",
        "df.describe(include='all').T"
      ],
      "metadata": {
        "id": "hqSqA7_mhgUi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert all dtypes to float and check\n",
        "df = df.astype('float')\n",
        "df.dtypes"
      ],
      "metadata": {
        "id": "OE6kEYC3hgUi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Descriptive statistics\n",
        "df.describe().T"
      ],
      "metadata": {
        "id": "3xiAAE9ehgUi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check for missing values\n",
        "df.isna().sum()"
      ],
      "metadata": {
        "id": "eS4a-BfshgUj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # Function to fill missing values with a value at the same time one day ago\n",
        "# def fill_missing(values):\n",
        "#   one_day = 60 * 24\n",
        "#   for row in range(values.shape[0]):\n",
        "#     for col in range(values.shape[1]):\n",
        "#       if np.isnan(values[row, col]):\n",
        "#         # print(\"Copying \",values[row - one_day, col],\" in location\", row, col)\n",
        "#         values[row, col] = values[row - one_day, col]\\"
      ],
      "metadata": {
        "id": "bYHU3uSzhgUj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#commenting above fill_missing function since it is not working as expected.\n",
        "df.ffill(inplace=True)"
      ],
      "metadata": {
        "id": "OjlncQG4vrNE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check for missing values\n",
        "df.isna().sum().sum()"
      ],
      "metadata": {
        "id": "BrkxsH_T3pKv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Descriptive statistics\n",
        "df.describe().T"
      ],
      "metadata": {
        "id": "QBYBXcqphgUj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Note! Note! Note! Note! Note!\n",
        "\n",
        "The total energy consumption was larger than the sum of the three sub meters combined. Therefore, add a new feature 'sub_metering_4' will be added according to the following calculation: global_active_power * 1000/60 - (sub_metering_1 + sub_metering_2 + sub_metering_3)"
      ],
      "metadata": {
        "id": "Ntx8uYDfhgUj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Add column for remaining sub metering\n",
        "df['sub_metering_4'] = (df.iloc[:, 0] * 1000 / 60) - (df.iloc[:, 4] + df.iloc[:, 5] + df.iloc[:, 6])\n",
        "df.head(3)\n",
        "\n",
        "# Alternatively,\n",
        "# values = df.values\n",
        "# df['sub_metering_4'] = (values[:,0] * 1000 / 60) - (values[:,4] + values[:,5] + values[:,6])"
      ],
      "metadata": {
        "id": "zatA8XwohgUj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Descriptive statistics\n",
        "df.describe().T"
      ],
      "metadata": {
        "id": "57lpvlTnhgUj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check index\n",
        "df.index"
      ],
      "metadata": {
        "id": "5ZQK8GOjhgUj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset timeframe\n",
        "print('Dataset start', df.index.min())\n",
        "print('Dataset end', df.index.max())\n",
        "print('Dataset spans', df.index.max() - df.index.min())"
      ],
      "metadata": {
        "id": "2EFnk_qvhgUn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---"
      ],
      "metadata": {
        "id": "tUV4qYlvhgUn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5.3. Visualizing data"
      ],
      "metadata": {
        "id": "cp478DlChgUn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 5.3.1. Plotting data based on one-minute sampling rate"
      ],
      "metadata": {
        "id": "DI0XgxfPhgUn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## Histograms: Plotting feature distributions\n",
        "\n",
        "# Features to plot\n",
        "columns = df.columns\n",
        "\n",
        "# Creating subplot axes\n",
        "fig, axes = plt.subplots(4, 2, figsize=(14,16), sharey=False)\n",
        "\n",
        "# Iterating through axes and columns\n",
        "for col, ax in zip(columns, axes.flatten()):\n",
        "    sns.histplot(x=col, kde=True, data=df, ax=ax)\n",
        "    ax.tick_params(axis='x', labelsize=8)\n",
        "    ax.yaxis.set_major_formatter(StrMethodFormatter('{x:,.0f}'))\n",
        "    plt.subplots_adjust(hspace=0.3);"
      ],
      "metadata": {
        "id": "apBr3ToAhgUn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Documentation**\n",
        "* Voltage is a constant and will therefore be dropped for subsequent analysis"
      ],
      "metadata": {
        "id": "G0GY3iAFhgUn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 5.3.2. Plotting data based on hourly-sampling rate"
      ],
      "metadata": {
        "id": "_1-WCzfrhgUo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Convert power consumption data from per-minute sampling into total hourly consumption and drop voltage"
      ],
      "metadata": {
        "id": "55HrdPHRhgUo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert (or resample) time series minutes data (here into total per hour data)\n",
        "hdf = df.drop(['voltage'], axis=1).resample('H').sum()\n",
        "\n",
        "# Summarize resampled df\n",
        "print(hdf.shape)\n",
        "hdf.head(3)"
      ],
      "metadata": {
        "id": "RzHPbdqGhgUo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Histograms: Plotting feature distributions\n",
        "\n",
        "# Features to plot\n",
        "columns = hdf.columns\n",
        "\n",
        "# Creating subplot axes\n",
        "fig, axes = plt.subplots(4, 2, figsize=(14,16), sharey=False)\n",
        "axes[3,1].set_axis_off()\n",
        "\n",
        "# Iterating through axes and columns\n",
        "for col, ax in zip(columns, axes.flatten()):\n",
        "    sns.histplot(x=col, kde=True, data=hdf, ax=ax)\n",
        "    ax.tick_params(axis='x', labelsize=8)\n",
        "    ax.yaxis.set_major_formatter(StrMethodFormatter('{x:,.0f}'))\n",
        "    plt.subplots_adjust(hspace=0.3);"
      ],
      "metadata": {
        "id": "Dv95XNmRhgUo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Plotting features over time\n",
        "\n",
        "# Features to plot\n",
        "columns = hdf.columns\n",
        "\n",
        "# Creating subplot axes\n",
        "fig, axes = plt.subplots(4, 2, figsize=(14,16), sharey=False)\n",
        "axes[3,1].set_axis_off()\n",
        "\n",
        "# Iterating through axes and columns\n",
        "for col, ax in zip(columns, axes.flatten()):\n",
        "    sns.lineplot(data=hdf, x=hdf.index, y=col, ax=ax, color='green')\n",
        "    ax.tick_params(axis='x', labelrotation=45, labelsize=8)\n",
        "    ax.yaxis.set_major_formatter(StrMethodFormatter('{x:,.0f}'))\n",
        "    plt.subplots_adjust(hspace=0.4);"
      ],
      "metadata": {
        "id": "EML1G_0PhgUo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 5.3.3. Plotting data based on daily-sampling rate"
      ],
      "metadata": {
        "id": "Vxk5dNK2hgUo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Convert power consumption data from per-minute sampling into total daily consumption and drop voltage"
      ],
      "metadata": {
        "id": "9SH7bW4UhgUo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert (or resample) time series minutes data (here into total per day data)\n",
        "ddf = df.drop(['voltage'], axis=1).resample('D').sum()\n",
        "\n",
        "# Summarize resampled df\n",
        "print(ddf.shape)\n",
        "ddf.head(3)"
      ],
      "metadata": {
        "id": "MZb1e95RhgUo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Save dataset\n",
        "# ddf.to_csv('household_power_consumption_days.csv')"
      ],
      "metadata": {
        "id": "DVjQsYW2hgUo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Histograms: Plotting feature distributions\n",
        "\n",
        "# Features to plot\n",
        "columns = ddf.columns\n",
        "\n",
        "# Creating subplot axes\n",
        "fig, axes = plt.subplots(4, 2, figsize=(14,16), sharey=False)\n",
        "axes[3,1].set_axis_off()\n",
        "\n",
        "# Iterating through axes and columns\n",
        "for col, ax in zip(columns, axes.flatten()):\n",
        "    sns.histplot(x=col, kde=True, data=ddf, ax=ax)\n",
        "    ax.tick_params(axis='x', labelsize=8)\n",
        "    ax.yaxis.set_major_formatter(StrMethodFormatter('{x:,.0f}'))\n",
        "    plt.subplots_adjust(hspace=0.3);"
      ],
      "metadata": {
        "id": "2EPoTlu9hgUo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Documentation**\n",
        "* Target variable 'global_active_power' (total daily power consumption) is almost normally distributed with a slight skew to the right"
      ],
      "metadata": {
        "id": "vsvoY1CphgUp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## Plotting features over time\n",
        "\n",
        "# Features to plot\n",
        "columns = ddf.columns\n",
        "\n",
        "# Creating subplot axes\n",
        "fig, axes = plt.subplots(4, 2, figsize=(14,16), sharey=False)\n",
        "axes[3,1].set_axis_off()\n",
        "\n",
        "# Iterating through axes and columns\n",
        "for col, ax in zip(columns, axes.flatten()):\n",
        "    sns.lineplot(data=ddf, x=ddf.index, y=col, ax=ax, color='green')\n",
        "    ax.tick_params(axis='x', labelrotation=45, labelsize=8)\n",
        "    ax.yaxis.set_major_formatter(StrMethodFormatter('{x:,.0f}'))\n",
        "    plt.subplots_adjust(hspace=0.4);"
      ],
      "metadata": {
        "id": "kOfqJ3o8hgUp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Plotting features over time (with a different aspect ratio)\n",
        "\n",
        "# Features to plot\n",
        "columns = ddf.columns\n",
        "\n",
        "# Creating subplot axes\n",
        "fig, axes = plt.subplots(7, 1, figsize=(14,16), sharey=False)\n",
        "\n",
        "# Iterating through axes and columns\n",
        "for col, ax in zip(columns, axes.flatten()):\n",
        "    sns.lineplot(data=ddf, x=ddf.index, y=col, ax=ax, color='darkorange')\n",
        "    ax.tick_params(axis='x', labelrotation=45, labelsize=8)\n",
        "    ax.yaxis.set_major_formatter(StrMethodFormatter('{x:,.0f}'))\n",
        "    plt.subplots_adjust(hspace=0.4);"
      ],
      "metadata": {
        "id": "gpKTvxTAhgUp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Documentation**\n",
        "* Target variable 'global_active_power' (total daily power consumption): time-series is stationary and shows seasonality. However, variance shows some variability. Exclude the first couple of months for modelling?"
      ],
      "metadata": {
        "id": "8C7v3FiQhgUp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## Plot global_active_power for the first 8 months to check when variance decreased\n",
        "\n",
        "plt.figure(figsize=(7,4))\n",
        "sns.lineplot(data=ddf, x=ddf.index, y='global_active_power', color='blue')\n",
        "plt.tick_params(axis='x', labelrotation=45, labelsize=8)\n",
        "\n",
        "# Zoom in\n",
        "plt.xlim([ddf.index[1], ddf.index[200]]);"
      ],
      "metadata": {
        "id": "cEJl6eK2hgUp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Documentation**\n",
        "* Exclude the first 5 months for modelling?"
      ],
      "metadata": {
        "id": "HDi0MNZthgUp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## Correlation heatmap\n",
        "sns.set_theme(style=\"white\")\n",
        "plt.subplots(figsize=(7,6))\n",
        "\n",
        "# Generate mask for upper triangle\n",
        "mask = np.zeros_like(ddf.corr(), dtype=bool) #generate mask of \"0's\"\n",
        "mask[np.triu_indices_from(mask)] = True #return upper triangle\n",
        "# Set diverging colormap\n",
        "cmap = sns.color_palette('coolwarm', as_cmap=True)\n",
        "# Draw heatmap with mask and correct aspect ratio\n",
        "sns.heatmap(ddf.corr(), mask=mask, cmap=cmap, vmin=-1, vmax=1, center=0, fmt='.1g',\n",
        "            square=True, linewidths=.5, cbar_kws={\"shrink\": .5}, annot=True);"
      ],
      "metadata": {
        "id": "LdNJKhjBhgUp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Documentation**\n",
        "* 'global_intensity' is highly correlated with other features and should therefore be dropped before modelling"
      ],
      "metadata": {
        "id": "uElhn6eChgUp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 5.3.3.1. Stationarity: Augmented Dicky-Fuller test"
      ],
      "metadata": {
        "id": "PL9CcsiAhgUp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "A statistical test to identify whether a time series is non-stationary is the augmented Dicky-Fuller test.\n",
        "\n",
        "**Null hypothesis H$_{0}$: Time series is not stationary due to trend.**"
      ],
      "metadata": {
        "id": "G7WYqO14hgUp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "results = adfuller(ddf['global_active_power']) #results object is a tuple\n",
        "\n",
        "# Print Dicky-Fuller test results\n",
        "print(f'Dicky-Fuller test results:{results}\\n') #0th element: test statistic, 1st element: pval\n",
        "\n",
        "# Print test statistic\n",
        "print(f'test statistic:{results[0]}\\n')\n",
        "\n",
        "# Print p-value\n",
        "print(f'p-value:{np.round(results[1], 3)}\\n')\n",
        "\n",
        "# Print critical values\n",
        "print(f'critical values:{results[4]}\\n')\n",
        "\n",
        "# Significance statement\n",
        "alpha = 0.05\n",
        "\n",
        "if results[1] < alpha:\n",
        "    print(f'\\033[1mp-value < {alpha}: We reject the null hypothesis\\nConclusion: Time series is stationary\\033[0m')\n",
        "else:\n",
        "    print(f'\\033[1mp-value > {alpha}: We accept the null hypothesis\\nConclusion: Time series is not stationary due to trend\\033[0m')"
      ],
      "metadata": {
        "id": "OnuhulnzhgUp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 5.3.4. Plotting data based on monthly-sampling rate"
      ],
      "metadata": {
        "id": "N_Ja1fznhgUp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Convert power consumption data from per-minute sampling into total monthly consumption and drop voltage"
      ],
      "metadata": {
        "id": "BAZgogBYhgUp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert (or resample) time series minutes data (here into total per month data)\n",
        "mdf = df.drop(['voltage'], axis=1).resample('M').sum()\n",
        "\n",
        "# Summarize resampled df\n",
        "print(mdf.shape)\n",
        "mdf.head(3)"
      ],
      "metadata": {
        "id": "X-F5yCTWhgUp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.style.use('ggplot')"
      ],
      "metadata": {
        "id": "I38G6cyohgUp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Histograms: Plotting feature distributions\n",
        "\n",
        "# Features to plot\n",
        "columns = mdf.columns\n",
        "\n",
        "# Creating subplot axes\n",
        "fig, axes = plt.subplots(4, 2, figsize=(14,16), sharey=False)\n",
        "axes[3,1].set_axis_off()\n",
        "\n",
        "# Iterating through axes and columns\n",
        "for col, ax in zip(columns, axes.flatten()):\n",
        "    sns.histplot(x=col, kde=True, data=mdf, ax=ax)\n",
        "    ax.tick_params(axis='x', labelsize=8)\n",
        "    ax.yaxis.set_major_formatter(StrMethodFormatter('{x:,.0f}'))\n",
        "    plt.subplots_adjust(hspace=0.3);"
      ],
      "metadata": {
        "id": "sE9eoUfqhgUq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Plotting features over time\n",
        "\n",
        "# Features to plot\n",
        "columns = mdf.columns\n",
        "\n",
        "# Creating subplot axes\n",
        "fig, axes = plt.subplots(4, 2, figsize=(14,16), sharey=False)\n",
        "axes[3,1].set_axis_off()\n",
        "\n",
        "# Iterating through axes and columns\n",
        "for col, ax in zip(columns, axes.flatten()):\n",
        "    sns.lineplot(data=mdf, x=mdf.index, y=col, ax=ax, color='green')\n",
        "    ax.tick_params(axis='x', labelrotation=45, labelsize=8)\n",
        "    ax.yaxis.set_major_formatter(StrMethodFormatter('{x:,.0f}'))\n",
        "    plt.subplots_adjust(hspace=0.4);"
      ],
      "metadata": {
        "id": "0BHnh8mBhgUq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---"
      ],
      "metadata": {
        "id": "8iP3RULVhgUq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 6. Modelling"
      ],
      "metadata": {
        "id": "4xYLuKfmhgUq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Types of LSTM Models:\n",
        "* Univariate Single-Step Prediction\n",
        "* Multivariate Single-Step Prediction\n",
        "* Univariate Multi-Step Prediction\n",
        "* Multivariate Multi-Step Prediction"
      ],
      "metadata": {
        "id": "UDPcoMN-hgUq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "What does this mean? Let's explore this a little bit further with an example for Univariate Single-Step Prediction LSTM Models:\n",
        "\n",
        "There are problems comprised of a single series of observations and a model is required to learn from the series of past observations to predict the next value in the sequence. Before a univariate series can be modeled, it must be prepared. **The LSTM model will learn a function that maps a sequence of past observations as input to an output observation. As such, the sequence of observations must be transformed into multiple examples from which the LSTM can learn.**"
      ],
      "metadata": {
        "id": "U6Q-pHtmhgUq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Consider a given univariate sequence as input (equal to a feature/column):\n",
        "# [10, 20, 30, 40, 50, 60, 70, 80, 90]"
      ],
      "metadata": {
        "id": "a-P9jEukhgUq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The sequence can be divided into **multiple input/output patterns called samples** by making use of a **sliding window approach**, where three time steps are used as input (past observations) and one time step is used as output (future observations) for the **one-step prediction** that is being learned."
      ],
      "metadata": {
        "id": "_gsp4jwahgUr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Input, Output: X, y\n",
        "# [10, 20, 30] 40\n",
        "# [20, 30, 40] 50\n",
        "# [30, 40, 50] 60\n",
        "# [40, 50, 60] 70\n",
        "# [50, 60, 70] 80\n",
        "# [60, 70, 80] 90"
      ],
      "metadata": {
        "id": "G-UMJs_AhgUr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This sequence transformation will be performed in the respective data preparation steps prior to modeling.\n",
        "\n",
        "**Note!** LSTM models expect a certain **shape of input for each sample** specified in the `input_shape=(n_steps, n_features)` argument in terms of the number of time steps and the number of features. The input X has the shape `[samples, timesteps]`. Since LSTM models will always expect multiple samples as the input component of training data, X needs to be re-shaped into the following dimensions or shape: `[samples, timesteps, features]`"
      ],
      "metadata": {
        "id": "Fbxunu1ohgUr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 6.1. Functions"
      ],
      "metadata": {
        "tags": [],
        "id": "dt2z1mo-hgUr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 6.1.1. Splitting data into train and test"
      ],
      "metadata": {
        "id": "pRIroWpXhgUr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def split_data(data, test_size=0.2, analysis='univariate'):\n",
        "    \"\"\"\n",
        "    Function to split time series data into train and test set\n",
        "    Parameters:\n",
        "        test_size: float, default=0.2\n",
        "        analysis: {'univariate', 'univariate'}, default='univariate'\n",
        "    \"\"\"\n",
        "    if analysis == 'univariate':\n",
        "        position = int(round(len(data) * (1-test_size)))\n",
        "        train = np.array(data[:position]).reshape(-1,1)\n",
        "        test = np.array(data[position:]).reshape(-1,1)\n",
        "\n",
        "    elif analysis == 'multivariate':\n",
        "        position = int(round(len(data) * (1-test_size)))\n",
        "        train = data[:position]\n",
        "        test = data[position:]\n",
        "\n",
        "    else:\n",
        "        print(\"Please specify if analysis is univariate or multivariate\")\n",
        "\n",
        "    return train, test"
      ],
      "metadata": {
        "id": "MTl2k0ZMhgUr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 6.1.2. Scaling data"
      ],
      "metadata": {
        "id": "TvZGtioThgUr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def scale(data, train_split):\n",
        "    \"\"\"\n",
        "    Function to scale the entire dataset using the mean and standard deviation of the training data only\n",
        "    \"\"\"\n",
        "    data_mean = data[:train_split].mean(axis=0)\n",
        "    data_std = data[:train_split].std(axis=0)\n",
        "\n",
        "    return (data - data_mean) / data_std"
      ],
      "metadata": {
        "id": "mtYAE4UBhgUr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def inv_scale(data, scaled_data, train_split):\n",
        "    \"\"\"\n",
        "    Function to inverse scaling of data by using the mean and standard deviation of the training data only\n",
        "    \"\"\"\n",
        "    data_mean = data[:train_split].mean(axis=0)\n",
        "    data_std = data[:train_split].std(axis=0)\n",
        "\n",
        "    return scaled_data * data_std + data_mean"
      ],
      "metadata": {
        "id": "qWvgZgPghgUr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 6.1.3. Create samples"
      ],
      "metadata": {
        "id": "i3UTLuwuhgUr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Out in the wild this process is sometimes called create features, to supervised (X, y) or data windowing (input and labels)"
      ],
      "metadata": {
        "id": "my4_QhAAhgUr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**LSTM model type: Univariate multi-step prediction**"
      ],
      "metadata": {
        "id": "LvP9Lz-phgUr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def create_samples_univar(data, n_input, n_output):\n",
        "    \"\"\"\n",
        "    Function to convert time series observations\n",
        "    into input X and output y\n",
        "    \"\"\"\n",
        "    X, y = [], []\n",
        "\n",
        "    for i in range(n_input, len(data)): #start, stop\n",
        "        if i+n_output > len(data):\n",
        "            break\n",
        "        X.append(data[i-n_input : i])\n",
        "        y.append(data[i : i+n_output])\n",
        "\n",
        "    return np.array(X), np.array(y)"
      ],
      "metadata": {
        "id": "PRmyJ6ZLhgUr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**LSTM model type: Multivariate multi-step prediction**"
      ],
      "metadata": {
        "id": "7Aps-uLAhgUr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def create_samples_multivar(data, n_input, n_output, target_index=0):\n",
        "    \"\"\"\n",
        "    Function to convert time series observations\n",
        "    into input X and output y\n",
        "    \"\"\"\n",
        "    X, y = [], []\n",
        "\n",
        "    # Move column defined by target_index to first position\n",
        "    a = data[:, target_index].reshape(-1,1)\n",
        "    b = np.delete(data, target_index, axis=1)\n",
        "    data = np.concatenate((a, b), axis=1)\n",
        "\n",
        "    for i in range(n_input, len(data)): #start, stop\n",
        "        if i+n_output > len(data):\n",
        "            break\n",
        "        X.append(data[i-n_input : i, :])\n",
        "        y.append(data[i : i+n_output, 0])\n",
        "\n",
        "    return np.array(X), np.array(y)"
      ],
      "metadata": {
        "id": "hFTS95cDhgUr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 6.1.4. Model evaluation"
      ],
      "metadata": {
        "id": "SoYZGPpChgUs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Evaluation is a process during development of the model to check whether the model is best fit for the given problem and corresponding data."
      ],
      "metadata": {
        "id": "R7cGSnIzhgUs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def summarize_scores(name, score, scores):\n",
        "    \"\"\"\n",
        "    Function to summarize scores\n",
        "    \"\"\"\n",
        "    s_scores = ', '.join(['%.1f' % s for s in scores])\n",
        "    print('%s: [%.3f] %s' % (name, score, s_scores))"
      ],
      "metadata": {
        "id": "AohE2as2hgUs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_model(history):\n",
        "    \"\"\"\n",
        "    Function to plot training and validation loss\n",
        "    \"\"\"\n",
        "    plt.figure(figsize=(10,5))\n",
        "    plt.plot(history.history[\"loss\"], color=\"r\", label=\"Training Loss\")\n",
        "    plt.plot(history.history[\"val_loss\"], color=\"b\", label=\"Validation Loss\")\n",
        "    plt.legend(loc=\"upper right\")\n",
        "    plt.xlabel(\"Epoch\", fontsize=16)\n",
        "    plt.ylabel(\"Loss\", fontsize=16)\n",
        "    plt.ylim([0, max(plt.ylim())])\n",
        "    plt.title(\"Training and Validation Loss\", fontsize=16);"
      ],
      "metadata": {
        "id": "zyo9BXXMhgUs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 6.2. Part 1: Univariate LSTM Models (multi-step prediction)"
      ],
      "metadata": {
        "tags": [],
        "id": "cmvmZ8UlhgUs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Number of features: 1\n",
        "* Multi-step prediction"
      ],
      "metadata": {
        "id": "mTBz-1HBhgUs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "A time series forecasting problem that requires a **prediction of multiple time steps** into the future can be referred to as **multi-step time series forecasting.**\n",
        "Specifically, these are problems where the forecast horizon or interval is **more than one time step.**\n",
        "There are **two main types of LSTM models** that can be used **for multi-step forecasting**, which are:\n",
        "\n",
        "**1. Vector Output Model**\n",
        "\n",
        "**2. Encoder-Decoder Model**"
      ],
      "metadata": {
        "id": "xtLIk93thgUs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Data Input"
      ],
      "metadata": {
        "id": "Nu7u_GAMhgUs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Input data: Global_active_power (total daily consumption)\n",
        "feature = ddf['global_active_power']\n",
        "feature.index = ddf.reset_index()['datetime']\n",
        "feature.head()"
      ],
      "metadata": {
        "id": "cw1aBs0ChgUs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Data Scaling"
      ],
      "metadata": {
        "id": "JRBI4-fhhgUs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "LSTM uses sigmoid and tanh that are sensitive to magnitude so values need to be normalized"
      ],
      "metadata": {
        "id": "0K9t0TF1hgUt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define train/test split\n",
        "test_size = 0.25\n",
        "TRAIN_SPLIT = int(round(len(ddf) * (1-test_size)))\n",
        "TRAIN_SPLIT"
      ],
      "metadata": {
        "id": "BvsJ33W2hgUt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get data values\n",
        "univar_data = feature.values\n",
        "univar_data"
      ],
      "metadata": {
        "id": "ptttoiR0hgUt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Note!** The mean and standard deviation should *only* be computed using the training data"
      ],
      "metadata": {
        "id": "mxbIic5TMlxx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Scale data (using training data)\n",
        "univar_data_scaled = scale(univar_data, TRAIN_SPLIT)\n",
        "univar_data_scaled.shape, univar_data_scaled"
      ],
      "metadata": {
        "id": "TNU5UmzmhgUt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Train and Test Split"
      ],
      "metadata": {
        "id": "dfYefhhHhgUt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Split data into train and test\n",
        "train, test = split_data(data=univar_data_scaled, test_size=test_size, analysis='univariate')\n",
        "\n",
        "# Print shape and first 5 values for train set\n",
        "print(\"Shape train:\", train.shape, \"\\nShape test:\", test.shape, '\\n')\n",
        "print(train[:5])"
      ],
      "metadata": {
        "id": "1ss9ar62hgUt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualize train/test split\n",
        "plt.figure(figsize=(12,4))\n",
        "plt.plot(ddf.iloc[:len(train), 0])\n",
        "plt.plot(ddf.iloc[len(train):, 0])\n",
        "plt.xlabel('datetime')\n",
        "plt.ylabel(\"global_active_power\")\n",
        "plt.tick_params(axis='x', labelrotation=45, labelsize=8)\n",
        "plt.legend(['train','test']);"
      ],
      "metadata": {
        "id": "rwPdvfsEhgUt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Create Samples"
      ],
      "metadata": {
        "id": "U4yaCzuRhgUt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create samples for train and test set\n",
        "n_input = 14\n",
        "n_output = 7\n",
        "\n",
        "X_train, y_train = create_samples_univar(train, n_input=n_input, n_output=n_output)\n",
        "X_test, y_test = create_samples_univar(test, n_input=n_input, n_output=n_output)\n",
        "\n",
        "# Print shape and first 3 values for train set\n",
        "print(\"Shape X_train y_train:\", X_train.shape, y_train.shape,\n",
        "      \"\\nShape X_test y_test:\", X_test.shape, y_test.shape, '\\n')\n",
        "for i in range(2):\n",
        "    print(X_train[i], y_train[i])"
      ],
      "metadata": {
        "id": "gcEeP6EMhgUt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Sanity check if create_samples did a good job**"
      ],
      "metadata": {
        "id": "SwYa6SL6hgUu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train[-5:], test[-5:]"
      ],
      "metadata": {
        "id": "146k9DuThgUu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train[-1], y_train[-1]"
      ],
      "metadata": {
        "id": "9gh9wT33hgUu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_test[-1], y_test[-1]"
      ],
      "metadata": {
        "id": "h9_52WoDhgUu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train[0], y_train[0]"
      ],
      "metadata": {
        "id": "5QSNGlGqhgUu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_test[0], y_test[0]"
      ],
      "metadata": {
        "id": "820i9FN8hgUu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 6.2.1. LSTM Model With Univariate Input and Vector Output"
      ],
      "metadata": {
        "id": "AD29cm0xhgUu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Like other types of neural network models, the **LSTM can output a vector directly that can be interpreted as a multi-step forecast.**\n",
        "\n",
        "Data already has the correct input shape `[samples, timesteps, features]`"
      ],
      "metadata": {
        "id": "iiwnz3EehgUu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Stacked LSTM Model"
      ],
      "metadata": {
        "id": "scOQAQG1hgUu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create model\n",
        "clear_session()\n",
        "\n",
        "n_features = X_train.shape[2]\n",
        "n_input = X_train.shape[1]\n",
        "n_output = y_train.shape[1]\n",
        "\n",
        "model = Sequential()\n",
        "model.add(LSTM(100, activation='relu', return_sequences=True, input_shape=(n_input, n_features)))\n",
        "model.add(LSTM(50, activation='relu'))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(n_output))\n",
        "model.compile(optimizer='adam', loss='mse', metrics='mae') # mae: mean absolute error\n",
        "\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "4tT4W1hDhgUu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "\n",
        "# Fit model\n",
        "epochs = 50\n",
        "verbose = 0\n",
        "batch_size = 16 #default 32\n",
        "\n",
        "history = model.fit(X_train, y_train, epochs=epochs, verbose=verbose,\n",
        "                    batch_size=batch_size, validation_data=(X_test, y_test))"
      ],
      "metadata": {
        "id": "ICr2j-zDhgUu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Optionally, use EarlyStopping callback to interrupt training when the validation loss is not longer improving"
      ],
      "metadata": {
        "id": "CuWEQgWOhgUu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# %%time\n",
        "\n",
        "# # Fit model\n",
        "# callbacks = EarlyStopping(monitor=\"val_loss\", patience=5)\n",
        "# epochs = 100\n",
        "# verbose = 0\n",
        "# batch_size = 16 #default 32\n",
        "\n",
        "# history = model.fit(X_train, y_train, epochs=epochs, verbose=verbose, callbacks=callbacks,\n",
        "#                     batch_size=batch_size, validation_data=(X_test, y_test))"
      ],
      "metadata": {
        "id": "ICPIapShhgUu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Optimization Learning Curves"
      ],
      "metadata": {
        "tags": [],
        "id": "HFaoPOiGhgUu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plot_model(history)"
      ],
      "metadata": {
        "id": "yM8FJcighgUu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Loss and mae value for the model in test mode\n",
        "score = model.evaluate(X_test, y_test, verbose = 0)\n",
        "print(f'Test loss: {score[0]:.4f}')\n",
        "print(f'Test mae: {score[1]:.4f}')"
      ],
      "metadata": {
        "id": "DjfRu2fghgUv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# List all data in history\n",
        "print(history.history.keys())"
      ],
      "metadata": {
        "id": "CXapTL8JhgUv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history.history[\"loss\"][:5]"
      ],
      "metadata": {
        "id": "elgWFLSrhgUv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history.history[\"mae\"][:5]"
      ],
      "metadata": {
        "id": "0yOY3oK9hgUv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Model Prediction"
      ],
      "metadata": {
        "id": "EaOwhmb2hgUv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Reshape data for prediction into [1, n_input, 1]\n",
        "x_input = X_test[0].reshape((1, len(X_test[0]), 1))\n",
        "x_input.shape"
      ],
      "metadata": {
        "id": "GMUWpgaAhgUv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Make prediction\n",
        "yhat = model.predict(x_input, verbose=0)\n",
        "\n",
        "print(yhat.shape)\n",
        "yhat"
      ],
      "metadata": {
        "id": "wvj7Qoq1hgUv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Inverse Data Scaling**"
      ],
      "metadata": {
        "id": "Pnny6tZ9hgUv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Inverse scaling of prediction\n",
        "yhat_inv = inv_scale(univar_data, yhat, TRAIN_SPLIT)\n",
        "print(yhat_inv.shape)\n",
        "yhat_inv"
      ],
      "metadata": {
        "id": "557ng2rmhgUv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Inverse scaling of X_test, y_test\n",
        "X_test_inv = inv_scale(univar_data, X_test, TRAIN_SPLIT)\n",
        "y_test_inv = inv_scale(univar_data, y_test, TRAIN_SPLIT)\n",
        "\n",
        "X_test_inv.shape, y_test_inv.shape"
      ],
      "metadata": {
        "id": "vsvqBZfxhgUv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Plot Model Prediction"
      ],
      "metadata": {
        "id": "yxSQLJ5EhgUv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot prediction\n",
        "plt.figure(figsize=(6,3.5))\n",
        "\n",
        "past_seq = range(-len(X_test[0])+1, 1)\n",
        "future_seq = np.arange(1, len(y_test[0])+1)\n",
        "\n",
        "plt.plot(past_seq, X_test_inv[0], color='blue', marker='.', label='History')\n",
        "plt.plot(future_seq, y_test_inv[0], marker='x', label='True Future')\n",
        "plt.plot(future_seq, yhat_inv.reshape(-1,1), color='green', marker='o', label='Model Prediction')\n",
        "\n",
        "plt.xlabel('Time-Step')\n",
        "plt.ylabel('Daily Power Consumption (kW)')\n",
        "plt.xticks(range(-n_input,n_output,2))\n",
        "plt.title('Univariate Stacked LSTM model: Multi-step prediction')\n",
        "plt.legend(loc='center left', bbox_to_anchor=(1, 0.5), fontsize=10);"
      ],
      "metadata": {
        "id": "gCaJnSLShgUv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Now randomly select 3 more samples from the test set, perform model prediction and plot results\n",
        "\n",
        "for i in random.sample(range(len(X_test)), 3):\n",
        "    print(f\"Randomly selected sample: {i}\")\n",
        "\n",
        "    # Reshape data for prediction into [1, n_input, 1]\n",
        "    x_input = X_test[i].reshape((1, len(X_test[i]), 1))\n",
        "\n",
        "    # Make prediction\n",
        "    pred = model.predict(x_input, verbose=0)\n",
        "\n",
        "    # Inverse scaling of prediction\n",
        "    pred_inv = inv_scale(univar_data, pred, TRAIN_SPLIT)\n",
        "\n",
        "    # Plot prediction\n",
        "    plt.figure(figsize=(6,3.5))\n",
        "\n",
        "    past_seq = range(-len(X_test[0])+1, 1)\n",
        "    future_seq = np.arange(1, len(y_test[0])+1)\n",
        "\n",
        "    plt.plot(past_seq, X_test_inv[i], color='blue', marker='.', label='History')\n",
        "    plt.plot(future_seq, y_test_inv[i], marker='x', label='True Future')\n",
        "    plt.plot(future_seq, pred_inv.reshape(-1,1), color='green', marker='o', label='Model Prediction')\n",
        "\n",
        "    plt.xlabel('Time-Step')\n",
        "    plt.ylabel('Daily Power Consumption (kW)')\n",
        "    plt.xticks(range(-n_input,n_output,2))\n",
        "    plt.title('Univariate Stacked LSTM model: Multi-step prediction')\n",
        "    plt.legend(loc='center left', bbox_to_anchor=(1, 0.5), fontsize=10);"
      ],
      "metadata": {
        "id": "bRNJQy3xhgUv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Evaluation Metric: RMSE"
      ],
      "metadata": {
        "tags": [],
        "id": "ZAX2HCmjhgUv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Actual values\n",
        "actual = y_test_inv[0]\n",
        "\n",
        "# Predicted values\n",
        "predicted = yhat_inv.reshape(-1,1)"
      ],
      "metadata": {
        "id": "TUogLibfhgUv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "actual.shape, predicted.shape"
      ],
      "metadata": {
        "id": "8_SR_vhKhgUv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "actual"
      ],
      "metadata": {
        "id": "CiyV_TkkhgUv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predicted"
      ],
      "metadata": {
        "id": "-mYSnqvlhgUv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate RMSE score for each day\n",
        "rmse_day = []\n",
        "\n",
        "for i in range(actual.shape[0]):\n",
        "    # calculate rmse\n",
        "    rmse = mean_squared_error(actual[i], predicted[i], squared=False)\n",
        "    rmse_day.append(rmse)\n",
        "\n",
        "rmse_day"
      ],
      "metadata": {
        "id": "6tZaM1hNhgUv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Store RMSE scores of each day in df\n",
        "df_rmse = pd.DataFrame(rmse_day, columns=['Univariate Stacked LSTM'])"
      ],
      "metadata": {
        "id": "4Um1YOMzhgUv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot RMSE score for each day\n",
        "future_seq = np.arange(1, len(y_test[0])+1)\n",
        "\n",
        "plt.figure(figsize=(6,3.5))\n",
        "plt.plot(future_seq, rmse_day, marker='o', color='darkred')\n",
        "plt.xlabel('Time-Step')\n",
        "plt.ylabel('RMSE (kW)')\n",
        "plt.title('Univariate Stacked LSTM model: RMSE per Day forecast');"
      ],
      "metadata": {
        "id": "yT2xVabOhgUv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate overall RMSE score (for the respective forecast period)\n",
        "rmse_total = mean_squared_error(actual, predicted, squared=False)\n",
        "rmse_total"
      ],
      "metadata": {
        "id": "fN5B5Vp5hgUw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Store overall RMSE score in dict\n",
        "performance_rmse = {}\n",
        "performance_rmse['Univariate Stacked LSTM'] = rmse_total"
      ],
      "metadata": {
        "id": "1EExuaJKhgUw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Summarize scores\n",
        "summarize_scores('RMSE scores for Univariate Stacked LSTM [total] per day', rmse_total, rmse_day)"
      ],
      "metadata": {
        "id": "uajnEcfghgUw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 6.2.2. Encoder-Decoder LSTM Model"
      ],
      "metadata": {
        "tags": [],
        "id": "iR6NmqWThgUw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**A model specifically developed for forecasting variable length output sequences is called the Encoder-Decoder LSTM.** The model was designed for prediction problems where there are both input and output sequences, so-called sequence-to-sequence, or seq2seq problems, such as translating text from one language to another. This model can be used for multi-step time series forecasting.\n",
        "\n",
        "As its name suggests, the model is comprised of two sub-models: the encoder and the decoder.\n",
        "\n",
        "**The encoder is a model responsible for reading and interpreting the input sequence. The output of the encoder is a fixed length vector that represents the model’s interpretation of the sequence. The encoder is traditionally a Vanilla LSTM model, although other encoder models can be used** such as Stacked, Bidirectional, and CNN models."
      ],
      "metadata": {
        "id": "4ETzq17HhgUw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Data already has the correct input shape `[samples, timesteps, features]`"
      ],
      "metadata": {
        "id": "pc4tBTs_hgUw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Encoder-Decoder LSTM Model"
      ],
      "metadata": {
        "id": "SWOZuM0ghgUw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create model\n",
        "clear_session()\n",
        "\n",
        "n_features = X_train.shape[2]\n",
        "n_input = X_train.shape[1]\n",
        "n_output = y_train.shape[1]\n",
        "\n",
        "model = Sequential()\n",
        "model.add(LSTM(100, activation='relu', input_shape=(n_input, n_features)))\n",
        "model.add(RepeatVector(n_output))\n",
        "model.add(LSTM(100, activation='relu', return_sequences=True))\n",
        "model.add(TimeDistributed(Dense(50, activation='relu')))\n",
        "model.add(TimeDistributed(Dense(1)))\n",
        "model.compile(optimizer='adam', loss='mse', metrics='mae')\n",
        "\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "DlNkgwmAhgUw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "\n",
        "# Fit model\n",
        "epochs = 50\n",
        "verbose = 0\n",
        "batch_size = 16 #default 32\n",
        "\n",
        "history = model.fit(X_train, y_train, epochs=epochs, verbose=verbose,\n",
        "                    batch_size=batch_size, validation_data=(X_test, y_test))"
      ],
      "metadata": {
        "id": "dZqturJ3hgUw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Optionally, use EarlyStopping callback to interrupt training when the validation loss is not longer improving"
      ],
      "metadata": {
        "id": "yYL-MnluhgUw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# %%time\n",
        "\n",
        "# # Fit model\n",
        "# callbacks = EarlyStopping(monitor=\"val_loss\", patience=10)\n",
        "# epochs = 100\n",
        "# verbose = 0\n",
        "# batch_size = 16 #default 32\n",
        "\n",
        "# history = model.fit(X_train, y_train, epochs=epochs, verbose=verbose, callbacks=callbacks,\n",
        "#                     batch_size=batch_size, validation_data=(X_test, y_test))"
      ],
      "metadata": {
        "id": "W8JjSHg5hgUw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Optimization Learning Curves"
      ],
      "metadata": {
        "tags": [],
        "id": "_ztntsHFhgUw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plot_model(history)"
      ],
      "metadata": {
        "id": "t2s59coghgUw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Loss and mae value for the model in test mode\n",
        "score = model.evaluate(X_test, y_test, verbose = 0)\n",
        "print(f'Test loss: {score[0]:.4f}')\n",
        "print(f'Test mae: {score[1]:.4f}')"
      ],
      "metadata": {
        "id": "uN8glpPZhgUw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# List all data in history\n",
        "print(history.history.keys())"
      ],
      "metadata": {
        "id": "X8F2c-jChgUx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history.history[\"loss\"][:5]"
      ],
      "metadata": {
        "id": "vMhaIo8HhgUx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history.history[\"mae\"][:5]"
      ],
      "metadata": {
        "id": "b2eeJaf0hgUx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Model Prediction"
      ],
      "metadata": {
        "id": "NV7wNMUchgUx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Reshape data for prediction into [1, n_input, 1]\n",
        "x_input = X_test[0].reshape((1, len(X_test[0]), 1))\n",
        "x_input.shape"
      ],
      "metadata": {
        "id": "59leemyLhgUx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Make prediction\n",
        "yhat = model.predict(x_input, verbose=0)\n",
        "\n",
        "print(yhat.shape)\n",
        "yhat"
      ],
      "metadata": {
        "id": "R5-xRUd7hgUy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Inverse Data Scaling**"
      ],
      "metadata": {
        "id": "f61yyQYdhgUy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Inverse scaling of prediction\n",
        "yhat_inv = inv_scale(univar_data, yhat, TRAIN_SPLIT)\n",
        "print(yhat_inv.shape)\n",
        "yhat_inv"
      ],
      "metadata": {
        "id": "BONmp28VhgUy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Inverse scaling of X_test, y_test\n",
        "X_test_inv = inv_scale(univar_data, X_test, TRAIN_SPLIT)\n",
        "y_test_inv = inv_scale(univar_data, y_test, TRAIN_SPLIT)\n",
        "\n",
        "X_test_inv.shape, y_test_inv.shape"
      ],
      "metadata": {
        "id": "hr2F43OChgUy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Plot Model Prediction"
      ],
      "metadata": {
        "id": "sXv1tuSWhgUy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot prediction\n",
        "plt.figure(figsize=(6,3.5))\n",
        "\n",
        "past_seq = range(-len(X_test[0])+1, 1)\n",
        "future_seq = np.arange(1, len(y_test[0])+1)\n",
        "\n",
        "plt.plot(past_seq, X_test_inv[0], color='blue', marker='.', label='History')\n",
        "plt.plot(future_seq, y_test_inv[0], marker='x', label='True Future')\n",
        "plt.plot(future_seq, yhat_inv.reshape(-1,1), color='green', marker='o', label='Model Prediction')\n",
        "\n",
        "plt.xlabel('Time-Step')\n",
        "plt.ylabel('Daily Power Consumption (kW)')\n",
        "plt.xticks(range(-n_input,n_output,2))\n",
        "plt.title('Univariate Encoder-Decoder LSTM model: Multi-step prediction')\n",
        "plt.legend(loc='center left', bbox_to_anchor=(1, 0.5), fontsize=10);"
      ],
      "metadata": {
        "id": "5y8GOtm0hgUy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Now randomly select 3 more samples from the test set, perform model prediction and plot results\n",
        "\n",
        "for i in random.sample(range(len(X_test)), 3):\n",
        "    print(f\"Randomly selected sample: {i}\")\n",
        "\n",
        "    # Reshape data for prediction into [1, n_input, 1]\n",
        "    x_input = X_test[i].reshape((1, len(X_test[i]), 1))\n",
        "\n",
        "    # Make prediction\n",
        "    pred = model.predict(x_input, verbose=0)\n",
        "\n",
        "    # Inverse scaling of prediction\n",
        "    pred_inv = inv_scale(univar_data, pred, TRAIN_SPLIT)\n",
        "\n",
        "    # Plot prediction\n",
        "    plt.figure(figsize=(6,3.5))\n",
        "\n",
        "    past_seq = range(-len(X_test[0])+1, 1)\n",
        "    future_seq = np.arange(1, len(y_test[0])+1)\n",
        "\n",
        "    plt.plot(past_seq, X_test_inv[i], color='blue', marker='.', label='History')\n",
        "    plt.plot(future_seq, y_test_inv[i], marker='x', label='True Future')\n",
        "    plt.plot(future_seq, pred_inv.reshape(-1,1), color='green', marker='o', label='Model Prediction')\n",
        "\n",
        "    plt.xlabel('Time-Step')\n",
        "    plt.ylabel('Daily Power Consumption (kW)')\n",
        "    plt.xticks(range(-n_input,n_output,2))\n",
        "    plt.title('Univariate Encoder-Decoder LSTM model: Multi-step prediction')\n",
        "    plt.legend(loc='center left', bbox_to_anchor=(1, 0.5), fontsize=10);"
      ],
      "metadata": {
        "id": "M7aMYFxchgUy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Evaluation Metric: RMSE"
      ],
      "metadata": {
        "id": "32q4HvafhgUy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Actual values\n",
        "actual = y_test_inv[0]\n",
        "\n",
        "# Predicted values\n",
        "predicted = yhat_inv.reshape(-1,1)"
      ],
      "metadata": {
        "id": "fDXQOZlQhgUy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "actual.shape, predicted.shape"
      ],
      "metadata": {
        "id": "5JtJxXQahgUy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "actual"
      ],
      "metadata": {
        "id": "cC7zuSLshgUz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predicted"
      ],
      "metadata": {
        "id": "2JChkLCDhgUz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate RMSE score for each day\n",
        "rmse_day = []\n",
        "\n",
        "for i in range(actual.shape[0]):\n",
        "    # calculate rmse\n",
        "    rmse = mean_squared_error(actual[i], predicted[i], squared=False)\n",
        "    rmse_day.append(rmse)\n",
        "\n",
        "rmse_day"
      ],
      "metadata": {
        "id": "wDO1urEHhgUz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Store RMSE scores of each day in df\n",
        "df_rmse['Univariate Encoder-Decoder LSTM'] = rmse_day"
      ],
      "metadata": {
        "id": "8br76c5VhgUz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot RMSE score for each day\n",
        "future_seq = np.arange(1, len(y_test[0])+1)\n",
        "\n",
        "plt.figure(figsize=(6,3.5))\n",
        "plt.plot(future_seq, rmse_day, marker='o', color='darkred')\n",
        "plt.xlabel('Time-Step')\n",
        "plt.ylabel('RMSE (kW)')\n",
        "plt.title('Univariate Encoder-Decoder LSTM model: RMSE per Day forecast');"
      ],
      "metadata": {
        "id": "ZJPTCJmMhgUz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate overall RMSE score (for the respective forecast period)\n",
        "rmse_total = mean_squared_error(actual, predicted, squared=False)\n",
        "rmse_total"
      ],
      "metadata": {
        "id": "SCtCQrGrhgUz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Store overall RMSE score in dict\n",
        "performance_rmse.update( {'Univariate Encoder-Decoder LSTM' : rmse_total} )"
      ],
      "metadata": {
        "id": "B05wZlqfhgUz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Summarize scores\n",
        "summarize_scores('RMSE scores for Univariate Stacked LSTM [total] per day', rmse_total, rmse_day)"
      ],
      "metadata": {
        "id": "e4xNL7PHhgUz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 6.3. Part 2: Multivariate LSTM Models (multi-step prediction)"
      ],
      "metadata": {
        "tags": [],
        "id": "f3_kSh9thgUz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Number of features: >1\n",
        "* Multi-step prediction"
      ],
      "metadata": {
        "id": "oKOz7v2ohgUz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this section, each of the time series variables is used to predict the next days of daily total power consumption. Each one-dimensional time series is provided to the model as a separate sequence of input. The LSTM will in turn create an internal representation of each input sequence that will together be interpreted by the decoder. Using multivariate inputs is helpful for those problems where the output sequence is some function of the observations at prior time steps from multiple different features, not just (or including) the feature being forecasted."
      ],
      "metadata": {
        "id": "FEUcN3q_hgUz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Data Input"
      ],
      "metadata": {
        "id": "oPdACx5QhgUz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "As can be seen from the correlation heatmap, global intensity highly correlates with other features and will therefore be dropped. Voltage was already dropped before as it is a constant value"
      ],
      "metadata": {
        "id": "pTHje4TbNHjh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Select features\n",
        "features = ddf.drop(['global_intensity'], axis=1)\n",
        "features.head()"
      ],
      "metadata": {
        "tags": [],
        "id": "bLMGkjbFhgUz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "features.tail(3)"
      ],
      "metadata": {
        "id": "hZO248kehgUz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Data Scaling"
      ],
      "metadata": {
        "id": "9nn1zEw0hgUz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "LSTM uses sigmoid and tanh that are sensitive to magnitude so values need to be normalized"
      ],
      "metadata": {
        "id": "vYJ0c1r9hgUz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define train/test split\n",
        "test_size = 0.25\n",
        "TRAIN_SPLIT = int(round(len(ddf) * (1-test_size)))\n",
        "TRAIN_SPLIT"
      ],
      "metadata": {
        "id": "PnS3Qwh4hgUz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get data values\n",
        "multivar_data = features.values"
      ],
      "metadata": {
        "id": "YfiHkin8hgUz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Note!** The mean and standard deviation should *only* be computed using the training data"
      ],
      "metadata": {
        "id": "dBhNO4_lhgUz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Scale data (using training data)\n",
        "multivar_data_scaled = scale(multivar_data, TRAIN_SPLIT)\n",
        "multivar_data_scaled.shape, multivar_data_scaled[0]"
      ],
      "metadata": {
        "id": "IY_dG7rVhgUz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Train and Test Split"
      ],
      "metadata": {
        "id": "Oz1I_XzGhgU0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Split data into train and test\n",
        "train, test = split_data(data=multivar_data_scaled, test_size=test_size, analysis='multivariate')\n",
        "\n",
        "# Print shape and first 5 values for train set\n",
        "print(\"Shape train:\", train.shape, \"\\nShape test:\", test.shape, '\\n')\n",
        "print(train[:9])\n",
        "print(test[:9])"
      ],
      "metadata": {
        "id": "xSExWEeGhgU0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Create Samples"
      ],
      "metadata": {
        "id": "iHKOI73rhgU0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create samples for train and test set\n",
        "n_input = 14\n",
        "n_output = 7\n",
        "target_index = 0\n",
        "\n",
        "X_train, y_train = create_samples_multivar(train, n_input=n_input, n_output=n_output, target_index=target_index)\n",
        "X_test, y_test = create_samples_multivar(test, n_input=n_input, n_output=n_output, target_index=target_index)\n",
        "\n",
        "# Print shape and first 3 values for train set\n",
        "print(\"Shape X_train y_train:\", X_train.shape, y_train.shape,\n",
        "      \"\\nShape X_test y_test:\", X_test.shape, y_test.shape, '\\n')\n",
        "for i in range(3):\n",
        "    print(X_train[i], y_train[i])"
      ],
      "metadata": {
        "id": "30RkIMEqhgU0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Sanity check if create_samples did a good job**"
      ],
      "metadata": {
        "id": "NdESCQ3shgU0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train[-5:], test[-5:]"
      ],
      "metadata": {
        "id": "PDCJCaHThgU0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train[-1], y_train[-1]"
      ],
      "metadata": {
        "id": "cfKLBGqUhgU0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_test[-1], y_test[-1]"
      ],
      "metadata": {
        "id": "VIHmxcohhgU0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train[0], y_train[0]"
      ],
      "metadata": {
        "id": "z_A3o6AchgU0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_test[0], y_test[0]"
      ],
      "metadata": {
        "id": "rnx733I7hgU0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 6.3.1. LSTM Model With Multivariate Input and Vector Output"
      ],
      "metadata": {
        "id": "DXEL81fIhgU0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Like other types of neural network models, the **LSTM can output a vector directly that can be interpreted as a multi-step forecast.**\n",
        "\n",
        "Data already has the correct input shape `[samples, timesteps, features]`"
      ],
      "metadata": {
        "id": "bBLCnEEKhgU0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Stacked LSTM"
      ],
      "metadata": {
        "id": "qciGtRizhgU0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create model\n",
        "clear_session()\n",
        "\n",
        "n_features = X_train.shape[2]\n",
        "n_input = X_train.shape[1]\n",
        "n_output = y_train.shape[1]\n",
        "\n",
        "model = Sequential()\n",
        "model.add(LSTM(100, activation='relu', return_sequences=True, input_shape=(n_input, n_features)))\n",
        "model.add(LSTM(50, activation='relu'))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(n_output))\n",
        "model.compile(optimizer='adam', loss='mse', metrics='mae')\n",
        "\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "feXa9WrfhgU0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "\n",
        "# Fit model\n",
        "epochs = 50\n",
        "verbose = 0\n",
        "batch_size = 16 #default 32\n",
        "\n",
        "history = model.fit(X_train, y_train, epochs=epochs, verbose=verbose,\n",
        "                    batch_size=batch_size, validation_data=(X_test, y_test))"
      ],
      "metadata": {
        "id": "YTO246pZhgU0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Optionally, use EarlyStopping callback to interrupt training when the validation loss is not longer improving"
      ],
      "metadata": {
        "id": "sip9T6_IhgU0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# %%time\n",
        "\n",
        "# # Fit model\n",
        "# callbacks = EarlyStopping(monitor=\"val_loss\", patience=10)\n",
        "# epochs = 100\n",
        "# verbose = 0\n",
        "# batch_size = 16\n",
        "\n",
        "# history = model.fit(X_train, y_train, epochs=epochs, verbose=verbose, callbacks=callbacks,\n",
        "#                     batch_size=batch_size, validation_data=(X_test, y_test))"
      ],
      "metadata": {
        "id": "uVkqKfI6hgU0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Optimization Learning Curves"
      ],
      "metadata": {
        "tags": [],
        "id": "GvXSI1DrhgU0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plot_model(history)"
      ],
      "metadata": {
        "id": "pNee4G1rhgU0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Loss and mae value for the model in test mode\n",
        "score = model.evaluate(X_test, y_test, verbose = 0)\n",
        "print(f'Test loss: {score[0]:.4f}')\n",
        "print(f'Test mae: {score[1]:.4f}')"
      ],
      "metadata": {
        "id": "W6Gs6QSQhgU0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# List all data in history\n",
        "print(history.history.keys())"
      ],
      "metadata": {
        "id": "xh38c40nhgU0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history.history[\"loss\"][:5]"
      ],
      "metadata": {
        "id": "oRxuWZh8hgU0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history.history[\"mae\"][:5]"
      ],
      "metadata": {
        "id": "ZG6Q2yUohgU1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Model Prediction"
      ],
      "metadata": {
        "id": "t5mZp_lBhgU1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Reshape data for prediction into [1, n_input, n_features]\n",
        "x_input = X_test[0].reshape((1, len(X_test[0]), n_features))\n",
        "x_input.shape"
      ],
      "metadata": {
        "id": "i80gJ3xhhgU1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Make prediction\n",
        "yhat = model.predict(x_input, verbose=0)\n",
        "\n",
        "print(yhat.shape)\n",
        "yhat"
      ],
      "metadata": {
        "id": "TnolWNfWhgU1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Inverse Data Scaling**"
      ],
      "metadata": {
        "id": "ZyuRuCnGhgU1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Inverse scaling of prediction\n",
        "yhat_inv = inv_scale(multivar_data[:,0], yhat, TRAIN_SPLIT)\n",
        "print(yhat_inv.shape)\n",
        "yhat_inv"
      ],
      "metadata": {
        "id": "K_xQwx_ShgU1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Inverse scaling of X_test, y_test\n",
        "X_test_inv = inv_scale(multivar_data, X_test, TRAIN_SPLIT)\n",
        "y_test_inv = inv_scale(multivar_data[:,0], y_test, TRAIN_SPLIT)\n",
        "\n",
        "X_test_inv.shape, y_test_inv.shape"
      ],
      "metadata": {
        "id": "h6-HuzuOhgU1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Plot Model Prediction"
      ],
      "metadata": {
        "id": "8lVSoHdNhgU1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot prediction\n",
        "plt.figure(figsize=(6,3.5))\n",
        "\n",
        "past_seq = range(-len(X_test[0])+1, 1)\n",
        "future_seq = np.arange(1, len(y_test[0])+1)\n",
        "\n",
        "plt.plot(past_seq, X_test_inv[0][:,0], color='blue', marker='.', label='History')\n",
        "plt.plot(future_seq, y_test_inv[0], marker='x', label='True Future')\n",
        "plt.plot(future_seq, yhat_inv.reshape(-1,1), color='green', marker='o', label='Model Prediction')\n",
        "\n",
        "plt.xlabel('Time-Step')\n",
        "plt.ylabel('Daily Power Consumption (kW)')\n",
        "plt.xticks(range(-n_input,n_output,2))\n",
        "plt.title('Multivariate Stacked LSTM model: Multi-step prediction')\n",
        "plt.legend(loc='center left', bbox_to_anchor=(1, 0.5), fontsize=10);"
      ],
      "metadata": {
        "id": "ncliSal-hgU1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Now randomly select 3 more samples from the test set, perform model prediction and plot results\n",
        "\n",
        "for i in random.sample(range(len(X_test)), 3):\n",
        "    print(f\"Randomly selected sample: {i}\")\n",
        "\n",
        "    # Reshape data for prediction into [1, n_input, n_features]\n",
        "    x_input = X_test[i].reshape((1, len(X_test[i]), n_features))\n",
        "\n",
        "    # Make prediction\n",
        "    pred = model.predict(x_input, verbose=0)\n",
        "\n",
        "    # Inverse scaling of prediction\n",
        "    pred_inv = inv_scale(univar_data, pred, TRAIN_SPLIT)\n",
        "\n",
        "    # Plot prediction\n",
        "    plt.figure(figsize=(6,3.5))\n",
        "\n",
        "    past_seq = range(-len(X_test[0])+1, 1)\n",
        "    future_seq = np.arange(1, len(y_test[0])+1)\n",
        "\n",
        "    plt.plot(past_seq, X_test_inv[i][:,0], color='blue', marker='.', label='History')\n",
        "    plt.plot(future_seq, y_test_inv[i], marker='x', label='True Future')\n",
        "    plt.plot(future_seq, pred_inv.reshape(-1,1), color='green', marker='o', label='Model Prediction')\n",
        "\n",
        "    plt.xlabel('Time-Step')\n",
        "    plt.ylabel('Daily Power Consumption (kW)')\n",
        "    plt.xticks(range(-n_input,n_output,2))\n",
        "    plt.title('Multivariate Stacked LSTM model: Multi-step prediction')\n",
        "    plt.legend(loc='center left', bbox_to_anchor=(1, 0.5), fontsize=10);"
      ],
      "metadata": {
        "id": "kKDT2LqQhgU1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Evaluation Metric: RMSE"
      ],
      "metadata": {
        "tags": [],
        "id": "sMYLGgfbhgU1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Actual values\n",
        "actual = y_test_inv[0].reshape(-1,1)\n",
        "\n",
        "# Predicted values\n",
        "predicted = yhat_inv.reshape(-1,1)"
      ],
      "metadata": {
        "id": "h-1M_7A6hgU1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "actual.shape, predicted.shape"
      ],
      "metadata": {
        "id": "KiRH02bRhgU1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "actual"
      ],
      "metadata": {
        "id": "crtCr9uKhgU1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predicted"
      ],
      "metadata": {
        "id": "FV1c7LiHhgU1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate RMSE score for each day\n",
        "rmse_day = []\n",
        "\n",
        "for i in range(actual.shape[0]):\n",
        "    # calculate rmse\n",
        "    rmse = mean_squared_error(actual[i], predicted[i], squared=False)\n",
        "    rmse_day.append(rmse)\n",
        "\n",
        "rmse_day"
      ],
      "metadata": {
        "id": "S4qasxFghgU1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Store RMSE scores of each day in df\n",
        "df_rmse['Multivariate Stacked LSTM'] = rmse_day"
      ],
      "metadata": {
        "id": "-MQEgkFvhgU1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot RMSE score for each day\n",
        "future_seq = np.arange(1, len(y_test[0])+1)\n",
        "\n",
        "plt.figure(figsize=(6,3.5))\n",
        "plt.plot(future_seq, rmse_day, marker='o', color='darkred')\n",
        "plt.xlabel('Time-Step')\n",
        "plt.ylabel('RMSE (kW)')\n",
        "plt.title('Multivariate Stacked LSTM model: RMSE per Day forecast');"
      ],
      "metadata": {
        "id": "tUgeaP9VhgU2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate overall RMSE score (for the respective forecast period)\n",
        "rmse_total = mean_squared_error(actual, predicted, squared=False)\n",
        "rmse_total"
      ],
      "metadata": {
        "id": "saNBdCPNhgU2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Store overall RMSE score in dict\n",
        "performance_rmse.update( {'Multivariate Stacked LSTM' : rmse_total} )"
      ],
      "metadata": {
        "id": "7qtV94rwhgU2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Summarize scores\n",
        "summarize_scores('RMSE scores for Multivariate Stacked LSTM [total] per day', rmse_total, rmse_day)"
      ],
      "metadata": {
        "id": "T1q2jK8mhgU2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 6.3.2. Encoder-Decoder Model"
      ],
      "metadata": {
        "tags": [],
        "id": "9Tjo0XuYhgU2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**A model specifically developed for forecasting variable length output sequences is called the Encoder-Decoder LSTM.** The model was designed for prediction problems where there are both input and output sequences, so-called sequence-to-sequence, or seq2seq problems, such as translating text from one language to another. This model can be used for multi-step time series forecasting.\n",
        "\n",
        "As its name suggests, the model is comprised of two sub-models: the encoder and the decoder.\n",
        "\n",
        "**The encoder is a model responsible for reading and interpreting the input sequence. The output of the encoder is a fixed length vector that represents the model’s interpretation of the sequence. The encoder is traditionally a Vanilla LSTM model, although other encoder models can be used** such as Stacked, Bidirectional, and CNN models."
      ],
      "metadata": {
        "id": "i14wReeahgU3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Data already has the correct input shape `[samples, timesteps, features]`"
      ],
      "metadata": {
        "id": "gJEujTsBhgU3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Encoder-Decoder LSTM Model"
      ],
      "metadata": {
        "id": "7pdjVWeUhgU3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create model\n",
        "clear_session()\n",
        "\n",
        "n_features = X_train.shape[2]\n",
        "n_input = X_train.shape[1]\n",
        "n_output = y_train.shape[1]\n",
        "\n",
        "model = Sequential()\n",
        "model.add(LSTM(100, activation='relu', input_shape=(n_input, n_features)))\n",
        "model.add(RepeatVector(n_output))\n",
        "model.add(LSTM(100, activation='relu', return_sequences=True))\n",
        "model.add(TimeDistributed(Dense(50, activation='relu')))\n",
        "model.add(TimeDistributed(Dense(1)))\n",
        "model.compile(optimizer='adam', loss='mse', metrics='mae')\n",
        "\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "uN9I7FnzhgU3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "\n",
        "# Fit model\n",
        "epochs = 50\n",
        "verbose = 0\n",
        "batch_size = 16 #default 32\n",
        "\n",
        "history = model.fit(X_train, y_train, epochs=epochs, verbose=verbose,\n",
        "                    batch_size=batch_size, validation_data=(X_test, y_test))"
      ],
      "metadata": {
        "id": "94KDzU0bhgU3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Optionally, use EarlyStopping callback to interrupt training when the validation loss is not longer improving"
      ],
      "metadata": {
        "id": "0VBXpmHBhgU3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# %%time\n",
        "\n",
        "# # Fit model\n",
        "# callbacks = EarlyStopping(monitor=\"val_loss\", patience=5)\n",
        "# epochs = 100\n",
        "# verbose = 0\n",
        "# batch_size = 16\n",
        "\n",
        "# history = model.fit(X_train, y_train, epochs=epochs, verbose=verbose, callbacks=callbacks,\n",
        "#                     batch_size=batch_size, validation_data=(X_test, y_test))"
      ],
      "metadata": {
        "id": "Y-z1S9vXhgU3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Optimization Learning Curves"
      ],
      "metadata": {
        "tags": [],
        "id": "n3gS3yzVhgU3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plot_model(history)"
      ],
      "metadata": {
        "id": "HYzc9X9thgU3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Loss and mae value for the model in test mode\n",
        "score = model.evaluate(X_test, y_test, verbose = 0)\n",
        "print(f'Test loss: {score[0]:.4f}')\n",
        "print(f'Test mae: {score[1]:.4f}')"
      ],
      "metadata": {
        "id": "hbBmnRkXhgU3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# List all data in history\n",
        "print(history.history.keys())"
      ],
      "metadata": {
        "id": "W-UgDNPyhgU3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history.history[\"loss\"][:5]"
      ],
      "metadata": {
        "id": "8aMisIobhgU4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history.history[\"mae\"][:5]"
      ],
      "metadata": {
        "id": "5MBG4QOJhgU4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Model Prediction"
      ],
      "metadata": {
        "id": "Jt7ETySmhgU4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Reshape data for prediction into [1, n_input, n_features]\n",
        "x_input = X_test[0].reshape((1, len(X_test[0]), n_features))\n",
        "x_input.shape"
      ],
      "metadata": {
        "id": "SOJJbTJPhgU4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Make prediction\n",
        "yhat = model.predict(x_input, verbose=0)\n",
        "\n",
        "print(yhat.shape)\n",
        "yhat"
      ],
      "metadata": {
        "id": "tzbIAlbghgU4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Inverse Data Scaling**"
      ],
      "metadata": {
        "id": "sJyDcRNNhgU4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Inverse scaling of prediction\n",
        "yhat_inv = inv_scale(multivar_data[:,0], yhat, TRAIN_SPLIT)\n",
        "print(yhat_inv.shape)\n",
        "yhat_inv"
      ],
      "metadata": {
        "id": "zkbAKmnmhgU4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Inverse scaling of X_test, y_test\n",
        "X_test_inv = inv_scale(multivar_data, X_test, TRAIN_SPLIT)\n",
        "y_test_inv = inv_scale(multivar_data[:,0], y_test, TRAIN_SPLIT)\n",
        "\n",
        "X_test_inv.shape, y_test_inv.shape"
      ],
      "metadata": {
        "id": "64NqHpq7hgU4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Plot Model Prediction"
      ],
      "metadata": {
        "id": "I9Z3M715hgU4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot prediction\n",
        "plt.figure(figsize=(6,3.5))\n",
        "\n",
        "past_seq = range(-len(X_test[0])+1, 1)\n",
        "future_seq = np.arange(1, len(y_test[0])+1)\n",
        "\n",
        "plt.plot(past_seq, X_test_inv[0][:,0], color='blue', marker='.', label='History')\n",
        "plt.plot(future_seq, y_test_inv[0], marker='x', label='True Future')\n",
        "plt.plot(future_seq, yhat_inv.reshape(-1,1), color='green', marker='o', label='Model Prediction')\n",
        "\n",
        "plt.xlabel('Time-Step')\n",
        "plt.ylabel('Daily Power Consumption (kW)')\n",
        "plt.xticks(range(-n_input,n_output,2))\n",
        "plt.title('Multivariate Encoder-Decoder LSTM model: Multi-step prediction')\n",
        "plt.legend(loc='center left', bbox_to_anchor=(1, 0.5), fontsize=10);"
      ],
      "metadata": {
        "id": "hjpHfnQlhgU4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Now randomly select 3 more samples from the test set, perform model prediction and plot results\n",
        "\n",
        "for i in random.sample(range(len(X_test)), 3):\n",
        "    print(f\"Randomly selected sample: {i}\")\n",
        "\n",
        "    # Reshape data for prediction into [1, n_input, n_features]\n",
        "    x_input = X_test[i].reshape((1, len(X_test[i]), n_features))\n",
        "\n",
        "    # Make prediction\n",
        "    pred = model.predict(x_input, verbose=0)\n",
        "\n",
        "    # Inverse scaling of prediction\n",
        "    pred_inv = inv_scale(multivar_data[:,0], pred, TRAIN_SPLIT)\n",
        "\n",
        "    # Plot prediction\n",
        "    plt.figure(figsize=(6,3.5))\n",
        "\n",
        "    past_seq = range(-len(X_test[0])+1, 1)\n",
        "    future_seq = np.arange(1, len(y_test[0])+1)\n",
        "\n",
        "    plt.plot(past_seq, X_test_inv[i][:,0], color='blue', marker='.', label='History')\n",
        "    plt.plot(future_seq, y_test_inv[i], marker='x', label='True Future')\n",
        "    plt.plot(future_seq, pred_inv.reshape(-1,1), color='green', marker='o', label='Model Prediction')\n",
        "\n",
        "    plt.xlabel('Time-Step')\n",
        "    plt.ylabel('Daily Power Consumption (kW)')\n",
        "    plt.xticks(range(-n_input,n_output,2))\n",
        "    plt.title('Multivariate Encoder-Decoder LSTM model: Multi-step prediction')\n",
        "    plt.legend(loc='center left', bbox_to_anchor=(1, 0.5), fontsize=10);"
      ],
      "metadata": {
        "id": "uB7Mv-GwhgU4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Evaluation Metric: RMSE"
      ],
      "metadata": {
        "tags": [],
        "id": "pjfgvwA-hgU4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Actual values\n",
        "actual = y_test_inv[0].reshape(-1,1)\n",
        "\n",
        "# Predicted values\n",
        "predicted = yhat_inv.reshape(-1,1)"
      ],
      "metadata": {
        "id": "td8qZEZchgU4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "actual.shape, predicted.shape"
      ],
      "metadata": {
        "id": "eBOeYNtUhgU4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "actual"
      ],
      "metadata": {
        "id": "pQvAhbUZhgU4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predicted"
      ],
      "metadata": {
        "id": "6-EPfO2qhgU4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate RMSE score for each day\n",
        "rmse_day = []\n",
        "\n",
        "for i in range(actual.shape[0]):\n",
        "    # calculate rmse\n",
        "    rmse = mean_squared_error(actual[i], predicted[i], squared=False)\n",
        "    rmse_day.append(rmse)\n",
        "\n",
        "rmse_day"
      ],
      "metadata": {
        "id": "C_2WtmEWhgU4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Store RMSE scores of each day in df\n",
        "df_rmse['Multivariate Encoder-Decoder LSTM'] = rmse_day"
      ],
      "metadata": {
        "id": "qXyeRNEWhgU4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot RMSE score for each day\n",
        "future_seq = np.arange(1, len(y_test[0])+1)\n",
        "\n",
        "plt.figure(figsize=(6,3.5))\n",
        "plt.plot(future_seq, rmse_day, marker='o', color='darkred')\n",
        "plt.xlabel('Time-Step')\n",
        "plt.ylabel('RMSE (kW)')\n",
        "plt.title('Multivariate Encoder-Decoder LSTM model: RMSE per Day forecast');"
      ],
      "metadata": {
        "id": "I6bn2PpvhgU4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate overall RMSE score (for the respective forecast period)\n",
        "rmse_total = mean_squared_error(actual, predicted, squared=False)\n",
        "rmse_total"
      ],
      "metadata": {
        "id": "3JtLs_7ZhgU4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Store overall RMSE score in dict\n",
        "performance_rmse.update( {'Multivariate Encoder-Decoder LSTM' : rmse_total} )"
      ],
      "metadata": {
        "id": "zkicU2y2hgU4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Summarize scores\n",
        "summarize_scores('RMSE scores for Multivariate Encoder-Decoder LSTM [total] per day', rmse_total, rmse_day)"
      ],
      "metadata": {
        "id": "Ca2P_dUFhgU4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 6.4. Overall Model Performance Comparison"
      ],
      "metadata": {
        "id": "oYU9roCqhgU4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Lineplot - RMSE scores for each day across all models"
      ],
      "metadata": {
        "id": "g8oTFVCYhgU5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataframe with RMSE scores for each day across all models\n",
        "print(df_rmse.shape)\n",
        "df_rmse.head()"
      ],
      "metadata": {
        "id": "CsL7yPyBhgU5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Add 'Time_Step' column to df\n",
        "df_rmse['Time_Step'] = np.arange(1, len(y_test[0])+1)"
      ],
      "metadata": {
        "id": "kW5q7Uj-hgU5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert df to long (tidy) form\n",
        "dfm_rmse = df_rmse.melt('Time_Step', var_name='Models', value_name='RMSE (kW)')\n",
        "dfm_rmse.head()"
      ],
      "metadata": {
        "id": "hRuxT3rehgU5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot RMSE scores for each day across all models\n",
        "plt.figure(figsize=(6,3.5))\n",
        "\n",
        "sns.lineplot(dfm_rmse, x='Time_Step', y='RMSE (kW)', hue='Models')\n",
        "plt.title('LSTM Models: RMSE per Day forecast\\n')\n",
        "# plt.legend(loc='center left', bbox_to_anchor=(1, 0.5), fontsize=10);\n",
        "plt.legend(loc='upper left', fontsize=10);"
      ],
      "metadata": {
        "id": "FHutlHv9hgU5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Barplot - Overall RMSE scores across all models"
      ],
      "metadata": {
        "id": "PNVl0IPMhgU5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "A model is considered skillful if it achieves performance better than a naive model, which is an **overall RMSE of about 465 kilowatts across a seven day forecast.**"
      ],
      "metadata": {
        "id": "8MoYd_aGhgU5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Compile the overall RMSE scores\n",
        "rmse_values = []\n",
        "\n",
        "for name, value in performance_rmse.items():\n",
        "    rmse_values.append(value)\n",
        "    print(f'{name:12s}: {value:0.4f}')"
      ],
      "metadata": {
        "id": "M3ywo815hgU5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot the overall RMSE scores (for the respective forecast period)\n",
        "x = np.arange(len(performance_rmse))\n",
        "\n",
        "plt.figure(figsize=(5,4))\n",
        "plt.bar(x, rmse_values, width=0.5, color='blue')\n",
        "plt.ylabel('RMSE (kW)')\n",
        "plt.title(f'LSTM Models:\\n\\n Overall RMSE for a {n_output}-Day forecast period')\n",
        "plt.xticks(ticks=x, labels=performance_rmse.keys(), rotation=45, ha='right');"
      ],
      "metadata": {
        "id": "isCqAtSFhgU5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Documentation**\n",
        "* Under the current conditions employed (e.g., number of input/output steps, model definitions), univariate models performed slightly better than multivariate models"
      ],
      "metadata": {
        "id": "LgXj55DMhgU5"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "apTfHZ4ghgU5"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}