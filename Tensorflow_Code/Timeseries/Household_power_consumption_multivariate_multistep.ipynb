{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/shuchimishra/Tensorflow_projects/blob/main/Tensorflow_Code/Timeseries/Household_power_consumption_multivariate_multistep.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Household Power Consumption Dataset**\n",
        "The Household Power Consumption dataset is a multivariate time series dataset that describes the electricity consumption for a single household over four years.\n",
        "\n",
        "The data was collected between December 2006 and November 2010 and observations of power consumption within the household were collected every minute.\n",
        "\n",
        "It is a multivariate series comprised of seven variables (besides the date and time); they are:\n",
        "\n",
        "global_active_power: The total active power consumed by the household (kilowatts).\n",
        "\n",
        "global_reactive_power: The total reactive power consumed by the household (kilowatts).\n",
        "\n",
        "voltage: Average voltage (volts).\n",
        "\n",
        "global_intensity: Average current intensity (amps).\n",
        "\n",
        "sub_metering_1: Active energy for kitchen (watt-hours of active energy).\n",
        "\n",
        "sub_metering_2: Active energy for laundry (watt-hours of active energy).\n",
        "\n",
        "sub_metering_3: Active energy for climate control systems (watt-hours of active energy).\n",
        "\n",
        "Active and reactive energy refer to the technical details of alternative current.\n",
        "\n",
        "In general terms, the active energy is the real power consumed by the household, whereas the reactive energy is the unused power in the lines.\n",
        "\n",
        "We can see that the dataset provides the active power as well as some division of the active power by main circuit in the house, specifically the kitchen, laundry, and climate control. These are not all the circuits in the household.\n",
        "\n",
        "The remaining watt-hours can be calculated from the active energy by first converting the active energy to watt-hours then subtracting the other sub-metered active energy in watt-hours, as follows:\n",
        "\n",
        "sub_metering_remainder = (global_active_power * 1000 / 60) - (sub_metering_1 + sub_metering_2 + sub_metering_3)"
      ],
      "metadata": {
        "id": "9Px0HMObCMy2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Imports"
      ],
      "metadata": {
        "id": "uE84m2VQ2u-D"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "PmW6XBmN9JTF"
      },
      "outputs": [],
      "source": [
        "import urllib\n",
        "import os\n",
        "import zipfile\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "from tensorflow import keras\n",
        "import matplotlib.pyplot as plt\n",
        "import zipfile\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Copy data"
      ],
      "metadata": {
        "id": "HxJJ8Dvf207D"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Approach 1: Upload"
      ],
      "metadata": {
        "id": "snOdmC1799l3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DtHnvjh6eJcq",
        "outputId": "ec1cd3e4-fb31-4ff7-ae8e-570c9a7df50b"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir data\n",
        "!cp '/content/drive/MyDrive/Data Science & Machine Learning/Tensorflow Certification/Repository/Tensorflow_projects/Data/Household Power Consumption/cleaned/household_power_consumption.csv' './data/'"
      ],
      "metadata": {
        "id": "s-3yeqhjeIf6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0ecb0091-dba5-427d-8dbb-391421899fd6"
      },
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mkdir: cannot create directory ‘data’: File exists\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "datafile = \"./data/household_power_consumption.csv\""
      ],
      "metadata": {
        "id": "UTs9fJCw-K3a"
      },
      "execution_count": 75,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(datafile, sep=',', infer_datetime_format=True, index_col='datetime', parse_dates=['datetime'])"
      ],
      "metadata": {
        "id": "JFLJEn3p-GsL",
        "outputId": "ce9b05ee-ed5a-4e7e-e26a-1656efd72b1a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-76-b63c19fe3de2>:1: FutureWarning: The argument 'infer_datetime_format' is deprecated and will be removed in a future version. A strict version of it is now the default, see https://pandas.pydata.org/pdeps/0004-consistent-to-datetime-parsing.html. You can safely remove this argument.\n",
            "  df = pd.read_csv(datafile, sep=',', infer_datetime_format=True, index_col='datetime', parse_dates=['datetime'])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "1ERrNpiSciYR"
      },
      "source": [
        "## Approach 2: UCI-Copy Data\n",
        "\n",
        " Download Data Set: UCI Machine Learning repository as a single 20 megabyte .zip file:\n",
        "\n",
        "[household_power_consumption.zip](https://archive.ics.uci.edu/ml/machine-learning-databases/00235/household_power_consumption.zip)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://archive.ics.uci.edu/ml/machine-learning-databases/00235/household_power_consumption.zip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "90oPhQcWDFtn",
        "outputId": "67b374bc-56b5-456c-a717-955b49e1b4c7"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2024-04-13 23:22:36--  https://archive.ics.uci.edu/ml/machine-learning-databases/00235/household_power_consumption.zip\n",
            "Resolving archive.ics.uci.edu (archive.ics.uci.edu)... 128.195.10.252\n",
            "Connecting to archive.ics.uci.edu (archive.ics.uci.edu)|128.195.10.252|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified\n",
            "Saving to: ‘household_power_consumption.zip’\n",
            "\n",
            "household_power_con     [    <=>             ]  19.68M  23.9MB/s    in 0.8s    \n",
            "\n",
            "2024-04-13 23:22:37 (23.9 MB/s) - ‘household_power_consumption.zip’ saved [20640916]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "zip_ref = './household_power_consumption.zip'\n",
        "datafile = \"./data/household_power_consumption.txt\"\n",
        "\n",
        "file = zipfile.ZipFile(zip_ref, 'r')\n",
        "file.extractall('./data')\n",
        "file.close()"
      ],
      "metadata": {
        "id": "ar19oo32DND9"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "JzCdQJwlciYR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "790ec272-dda9-4b74-e663-9676c733432e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-14-6f90a0c86db3>:1: FutureWarning: The argument 'infer_datetime_format' is deprecated and will be removed in a future version. A strict version of it is now the default, see https://pandas.pydata.org/pdeps/0004-consistent-to-datetime-parsing.html. You can safely remove this argument.\n",
            "  df = pd.read_csv(datafile, sep=';', infer_datetime_format=True, index_col='datetime', parse_dates={'datetime':[0,1]}, header=0, low_memory=False)\n",
            "<ipython-input-14-6f90a0c86db3>:1: UserWarning: Parsing dates in %d/%m/%Y %H:%M:%S format when dayfirst=False (the default) was specified. Pass `dayfirst=True` or specify a format to silence this warning.\n",
            "  df = pd.read_csv(datafile, sep=';', infer_datetime_format=True, index_col='datetime', parse_dates={'datetime':[0,1]}, header=0, low_memory=False)\n"
          ]
        }
      ],
      "source": [
        "df = pd.read_csv(datafile, sep=';', infer_datetime_format=True, index_col='datetime', parse_dates={'datetime':[0,1]}, header=0, low_memory=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Helper Function"
      ],
      "metadata": {
        "id": "-kgraHITVqSD"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 77,
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "rTn_FyJAciYV"
      },
      "outputs": [],
      "source": [
        "# Auxiliary plotting function\n",
        "def plot_series(x, y, format=\"-\", start=0, end=None, title=None, xlabel=None, ylabel=None, legend=None ):\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    if type(y) is tuple:\n",
        "        for y_curr in y:\n",
        "            plt.plot(x[start:end], y_curr[start:end], format)\n",
        "    else:\n",
        "        plt.plot(x[start:end], y[start:end], format)\n",
        "    plt.xlabel(xlabel)\n",
        "    plt.ylabel(ylabel)\n",
        "    if legend:\n",
        "        plt.legend(legend)\n",
        "    plt.title(title)\n",
        "    plt.grid(True)\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Running the function will first return the overall RMSE regardless of day, then an array of RMSE scores for each day.\n",
        "# evaluate one or more weekly forecasts against expected values\n",
        "def evaluate_forecasts(actual, predicted):\n",
        "\n",
        "\tscores = []\n",
        "\n",
        "\t# calculate an RMSE score for each day\n",
        "\tfor i in range(actual.shape[1]):\n",
        "\n",
        "\t\t# calculate mse\n",
        "\t\tmse = mean_squared_error(actual[:, i], predicted[:, i])\n",
        "\n",
        "\t\t# calculate rmse\n",
        "\t\trmse = sqrt(mse)\n",
        "\n",
        "\t\t# store the rmse in list\n",
        "\t\tscores.append(rmse)\n",
        "\n",
        "\t# calculate overall RMSE\n",
        "\ts = 0\n",
        "\tfor row in range(actual.shape[0]):\n",
        "\t\tfor col in range(actual.shape[1]):\n",
        "\n",
        "\t\t\ts = s + (actual[row, col] - predicted[row, col])**2\n",
        "\toverall_score = sqrt(s / (actual.shape[0] * actual.shape[1]))\n",
        "\n",
        "\treturn overall_score, scores"
      ],
      "metadata": {
        "id": "h_PHjgv_AE5n"
      },
      "execution_count": 78,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from numpy import nan\n",
        "\n",
        "# fill missing values with a value at the same time one day ago\n",
        "def fill_missing(values):\n",
        "  one_day = 60 * 24 #granulatiy of data is minutes\n",
        "  for row in range(values.shape[0]):\n",
        "    for col in range(values.shape[1]):\n",
        "      if isnan(values[row, col]):\n",
        "        print(\"replacing missing value of \",values[row, col],\"at position [\",row, col,\"] with :\",values[row - one_day, col])\n",
        "        values[row, col] = values[row - one_day, col] #if given day has 'nan' , then replace the value with previous day's reading"
      ],
      "metadata": {
        "id": "v6OVv0COGD21"
      },
      "execution_count": 79,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Insights"
      ],
      "metadata": {
        "id": "m_loND3-9vne"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "C82WFSFe9u_m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 80,
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AA1JoqNkciYS",
        "outputId": "c9bbf927-bad0-446e-ea2d-485be07baa4e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "DatetimeIndex: 86400 entries, 2006-12-16 17:24:00 to 2007-02-14 17:23:00\n",
            "Data columns (total 7 columns):\n",
            " #   Column                 Non-Null Count  Dtype  \n",
            "---  ------                 --------------  -----  \n",
            " 0   Global_active_power    86400 non-null  float64\n",
            " 1   Global_reactive_power  86400 non-null  float64\n",
            " 2   Voltage                86400 non-null  float64\n",
            " 3   Global_intensity       86400 non-null  float64\n",
            " 4   Sub_metering_1         86400 non-null  float64\n",
            " 5   Sub_metering_2         86400 non-null  float64\n",
            " 6   Sub_metering_3         86400 non-null  float64\n",
            "dtypes: float64(7)\n",
            "memory usage: 5.3 MB\n"
          ]
        }
      ],
      "source": [
        "df.info()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.head(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 237
        },
        "id": "fBHKiRsB4_TM",
        "outputId": "d758f021-289f-401c-dfeb-aae6d8896975"
      },
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                     Global_active_power  Global_reactive_power  Voltage  \\\n",
              "datetime                                                                   \n",
              "2006-12-16 17:24:00                4.216                  0.418   234.84   \n",
              "2006-12-16 17:25:00                5.360                  0.436   233.63   \n",
              "2006-12-16 17:26:00                5.374                  0.498   233.29   \n",
              "2006-12-16 17:27:00                5.388                  0.502   233.74   \n",
              "2006-12-16 17:28:00                3.666                  0.528   235.68   \n",
              "\n",
              "                     Global_intensity  Sub_metering_1  Sub_metering_2  \\\n",
              "datetime                                                                \n",
              "2006-12-16 17:24:00              18.4             0.0             1.0   \n",
              "2006-12-16 17:25:00              23.0             0.0             1.0   \n",
              "2006-12-16 17:26:00              23.0             0.0             2.0   \n",
              "2006-12-16 17:27:00              23.0             0.0             1.0   \n",
              "2006-12-16 17:28:00              15.8             0.0             1.0   \n",
              "\n",
              "                     Sub_metering_3  \n",
              "datetime                             \n",
              "2006-12-16 17:24:00            17.0  \n",
              "2006-12-16 17:25:00            16.0  \n",
              "2006-12-16 17:26:00            17.0  \n",
              "2006-12-16 17:27:00            17.0  \n",
              "2006-12-16 17:28:00            17.0  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-7abf7449-0577-4625-b0b6-466cc8619bd3\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Global_active_power</th>\n",
              "      <th>Global_reactive_power</th>\n",
              "      <th>Voltage</th>\n",
              "      <th>Global_intensity</th>\n",
              "      <th>Sub_metering_1</th>\n",
              "      <th>Sub_metering_2</th>\n",
              "      <th>Sub_metering_3</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>datetime</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2006-12-16 17:24:00</th>\n",
              "      <td>4.216</td>\n",
              "      <td>0.418</td>\n",
              "      <td>234.84</td>\n",
              "      <td>18.4</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>17.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2006-12-16 17:25:00</th>\n",
              "      <td>5.360</td>\n",
              "      <td>0.436</td>\n",
              "      <td>233.63</td>\n",
              "      <td>23.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>16.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2006-12-16 17:26:00</th>\n",
              "      <td>5.374</td>\n",
              "      <td>0.498</td>\n",
              "      <td>233.29</td>\n",
              "      <td>23.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>17.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2006-12-16 17:27:00</th>\n",
              "      <td>5.388</td>\n",
              "      <td>0.502</td>\n",
              "      <td>233.74</td>\n",
              "      <td>23.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>17.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2006-12-16 17:28:00</th>\n",
              "      <td>3.666</td>\n",
              "      <td>0.528</td>\n",
              "      <td>235.68</td>\n",
              "      <td>15.8</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>17.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-7abf7449-0577-4625-b0b6-466cc8619bd3')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-7abf7449-0577-4625-b0b6-466cc8619bd3 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-7abf7449-0577-4625-b0b6-466cc8619bd3');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-658e27cd-ab89-46e6-9553-9d4232505726\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-658e27cd-ab89-46e6-9553-9d4232505726')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-658e27cd-ab89-46e6-9553-9d4232505726 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 86400,\n  \"fields\": [\n    {\n      \"column\": \"datetime\",\n      \"properties\": {\n        \"dtype\": \"date\",\n        \"min\": \"2006-12-16 17:24:00\",\n        \"max\": \"2007-02-14 17:23:00\",\n        \"num_unique_values\": 86400,\n        \"samples\": [\n          \"2007-01-15 20:48:00\",\n          \"2007-02-09 02:41:00\",\n          \"2006-12-20 23:00:00\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Global_active_power\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1.335541718985206,\n        \"min\": 0.194,\n        \"max\": 9.272,\n        \"num_unique_values\": 3347,\n        \"samples\": [\n          5.406,\n          5.626,\n          3.904\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Global_reactive_power\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.1176214630431444,\n        \"min\": 0.0,\n        \"max\": 0.874,\n        \"num_unique_values\": 377,\n        \"samples\": [\n          0.656,\n          0.466,\n          0.632\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Voltage\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 3.498535931183726,\n        \"min\": 224.68,\n        \"max\": 251.7,\n        \"num_unique_values\": 2174,\n        \"samples\": [\n          238.73,\n          248.19,\n          237.56\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Global_intensity\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 5.629462938587408,\n        \"min\": 0.8,\n        \"max\": 40.4,\n        \"num_unique_values\": 189,\n        \"samples\": [\n          37.4,\n          36.2,\n          13.6\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Sub_metering_1\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 6.682567482882876,\n        \"min\": 0.0,\n        \"max\": 77.0,\n        \"num_unique_values\": 60,\n        \"samples\": [\n          0.0,\n          36.0,\n          14.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Sub_metering_2\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 7.5676794757081645,\n        \"min\": 0.0,\n        \"max\": 78.0,\n        \"num_unique_values\": 77,\n        \"samples\": [\n          37.0,\n          40.0,\n          9.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Sub_metering_3\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 8.67190930406459,\n        \"min\": 0.0,\n        \"max\": 20.0,\n        \"num_unique_values\": 21,\n        \"samples\": [\n          17.0,\n          12.0,\n          6.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 81
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Transformation"
      ],
      "metadata": {
        "id": "-7aak3-G9l2D"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Missing data"
      ],
      "metadata": {
        "id": "WP8mjkh4F2qK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from numpy import nan\n",
        "\n",
        "# # mark all missing values\n",
        "df.replace('?', nan, inplace=True)\n",
        "\n",
        "# make dataset numeric\n",
        "df = df.astype('float32')"
      ],
      "metadata": {
        "id": "0hDOvN9OF8ET"
      },
      "execution_count": 82,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Check if any values are missing"
      ],
      "metadata": {
        "id": "mOqQJY5QNJ4h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.isnull().sum()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ceCmyOYTNIjn",
        "outputId": "7c832974-e0ac-48a7-a2c7-5194492f7a98"
      },
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Global_active_power      0\n",
              "Global_reactive_power    0\n",
              "Voltage                  0\n",
              "Global_intensity         0\n",
              "Sub_metering_1           0\n",
              "Sub_metering_2           0\n",
              "Sub_metering_3           0\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 83
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "A very simple approach would be to copy the observation from the same time the day before. We can implement this in a function named fill_missing() that will take the NumPy array of the data and copy values from exactly 24 hours ago."
      ],
      "metadata": {
        "id": "pcXS3GitHI82"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from math import isnan\n",
        "\n",
        "# fill missing\n",
        "fill_missing(df.values)"
      ],
      "metadata": {
        "id": "1wLVODmUGZfi"
      },
      "execution_count": 84,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we can create a new column that contains the remainder of the sub-metering, using the calculation from the previous section.The remaining watt-hours can be calculated from the active energy by first converting the active energy to watt-hours then subtracting the other sub-metered active energy in watt-hours, as follows:\n",
        "\n",
        "sub_metering_remainder = (global_active_power * 1000 / 60) - (sub_metering_1 + sub_metering_2 + sub_metering_3)"
      ],
      "metadata": {
        "id": "X_ON-0-PGlMy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# add a column for for the remainder of sub metering\n",
        "values = df.values\n",
        "df['sub_metering_4'] = (values[:,0] * 1000 / 60) - (values[:,4] + values[:,5] + values[:,6]) #this operation can only be done using series"
      ],
      "metadata": {
        "id": "cziokOR_Go9e"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Convert data to daily grain"
      ],
      "metadata": {
        "id": "xATop-s0Qpa4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "As we notice here , data here is in hourly grain. We should transform the data to daily grain in order to be able to make daily forecasts."
      ],
      "metadata": {
        "id": "c-GVc_FV7hJQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#resample data to daily\n",
        "daily_groups = df.resample('D') #D=daily\n",
        "print(daily_groups)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cS6hm01H7tN_",
        "outputId": "c925d7fb-04f9-41d1-bb1c-db18dc7ffae3"
      },
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DatetimeIndexResampler [freq=<Day>, axis=0, closed=left, label=left, convention=start, origin=start_day]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dailyDF = daily_groups.sum()\n",
        "\n",
        "# summarize\n",
        "print(dailyDF.shape)\n",
        "display(dailyDF.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 254
        },
        "id": "WqR-PrIb7-4D",
        "outputId": "932d5568-c785-466d-81ab-7d9e98379994"
      },
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(61, 7)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "            Global_active_power  Global_reactive_power       Voltage  \\\n",
              "datetime                                                               \n",
              "2006-12-16          1209.176025              34.922001   93552.53125   \n",
              "2006-12-17          3390.459961             226.005997  345725.31250   \n",
              "2006-12-18          2203.825928             161.792007  347373.62500   \n",
              "2006-12-19          1666.193970             150.942001  348479.00000   \n",
              "2006-12-20          2225.748047             160.998001  348923.62500   \n",
              "\n",
              "            Global_intensity  Sub_metering_1  Sub_metering_2  Sub_metering_3  \n",
              "datetime                                                                      \n",
              "2006-12-16       5180.799805             0.0           546.0          4926.0  \n",
              "2006-12-17      14398.599609          2033.0          4187.0         13341.0  \n",
              "2006-12-18       9247.200195          1063.0          2621.0         14018.0  \n",
              "2006-12-19       7094.000000           839.0          7602.0          6197.0  \n",
              "2006-12-20       9313.000000             0.0          2648.0         14063.0  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-28ef059b-9904-4f8c-9ec0-76bf8b46b548\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Global_active_power</th>\n",
              "      <th>Global_reactive_power</th>\n",
              "      <th>Voltage</th>\n",
              "      <th>Global_intensity</th>\n",
              "      <th>Sub_metering_1</th>\n",
              "      <th>Sub_metering_2</th>\n",
              "      <th>Sub_metering_3</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>datetime</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2006-12-16</th>\n",
              "      <td>1209.176025</td>\n",
              "      <td>34.922001</td>\n",
              "      <td>93552.53125</td>\n",
              "      <td>5180.799805</td>\n",
              "      <td>0.0</td>\n",
              "      <td>546.0</td>\n",
              "      <td>4926.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2006-12-17</th>\n",
              "      <td>3390.459961</td>\n",
              "      <td>226.005997</td>\n",
              "      <td>345725.31250</td>\n",
              "      <td>14398.599609</td>\n",
              "      <td>2033.0</td>\n",
              "      <td>4187.0</td>\n",
              "      <td>13341.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2006-12-18</th>\n",
              "      <td>2203.825928</td>\n",
              "      <td>161.792007</td>\n",
              "      <td>347373.62500</td>\n",
              "      <td>9247.200195</td>\n",
              "      <td>1063.0</td>\n",
              "      <td>2621.0</td>\n",
              "      <td>14018.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2006-12-19</th>\n",
              "      <td>1666.193970</td>\n",
              "      <td>150.942001</td>\n",
              "      <td>348479.00000</td>\n",
              "      <td>7094.000000</td>\n",
              "      <td>839.0</td>\n",
              "      <td>7602.0</td>\n",
              "      <td>6197.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2006-12-20</th>\n",
              "      <td>2225.748047</td>\n",
              "      <td>160.998001</td>\n",
              "      <td>348923.62500</td>\n",
              "      <td>9313.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2648.0</td>\n",
              "      <td>14063.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-28ef059b-9904-4f8c-9ec0-76bf8b46b548')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-28ef059b-9904-4f8c-9ec0-76bf8b46b548 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-28ef059b-9904-4f8c-9ec0-76bf8b46b548');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-e64780fa-0852-4ad7-b506-8b8775907bf8\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-e64780fa-0852-4ad7-b506-8b8775907bf8')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-e64780fa-0852-4ad7-b506-8b8775907bf8 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"display(dailyDF\",\n  \"rows\": 5,\n  \"fields\": [\n    {\n      \"column\": \"datetime\",\n      \"properties\": {\n        \"dtype\": \"date\",\n        \"min\": \"2006-12-16 00:00:00\",\n        \"max\": \"2006-12-20 00:00:00\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"2006-12-17 00:00:00\",\n          \"2006-12-20 00:00:00\",\n          \"2006-12-18 00:00:00\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Global_active_power\",\n      \"properties\": {\n        \"dtype\": \"float32\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          3390.4599609375,\n          2225.748046875,\n          2203.825927734375\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Global_reactive_power\",\n      \"properties\": {\n        \"dtype\": \"float32\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          226.00599670410156,\n          160.9980010986328,\n          161.79200744628906\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Voltage\",\n      \"properties\": {\n        \"dtype\": \"float32\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          345725.3125,\n          348923.625,\n          347373.625\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Global_intensity\",\n      \"properties\": {\n        \"dtype\": \"float32\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          14398.599609375,\n          9313.0,\n          9247.2001953125\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Sub_metering_1\",\n      \"properties\": {\n        \"dtype\": \"float32\",\n        \"num_unique_values\": 4,\n        \"samples\": [\n          2033.0,\n          839.0,\n          0.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Sub_metering_2\",\n      \"properties\": {\n        \"dtype\": \"float32\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          4187.0,\n          2648.0,\n          2621.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Sub_metering_3\",\n      \"properties\": {\n        \"dtype\": \"float32\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          13341.0,\n          14063.0,\n          14018.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training - Validation Split"
      ],
      "metadata": {
        "id": "sHD7D8xPSZwF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We will use the first three years of data for training predictive models and the final year for evaluating models.\n",
        "\n",
        "The data in a given dataset will be divided into standard weeks. These are weeks that begin on a Sunday and end on a Saturday.\n",
        "\n",
        "This is a realistic and useful way for using the chosen framing of the model, where the power consumption for the week ahead can be predicted. It is also helpful with modeling, where models can be used to predict a specific day (e.g. Wednesday) or the entire sequence.\n",
        "\n",
        "We will split the data into standard weeks, working backwards from the test dataset."
      ],
      "metadata": {
        "id": "S1EcZUuDPE94"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(dailyDF)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8I_6ZFSFBUot",
        "outputId": "ded59d79-8d07-42c3-acf5-97a115bf21b1"
      },
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "            Global_active_power  Global_reactive_power       Voltage  \\\n",
            "datetime                                                               \n",
            "2006-12-16          1209.176025              34.922001   93552.53125   \n",
            "2006-12-17          3390.459961             226.005997  345725.31250   \n",
            "2006-12-18          2203.825928             161.792007  347373.62500   \n",
            "2006-12-19          1666.193970             150.942001  348479.00000   \n",
            "2006-12-20          2225.748047             160.998001  348923.62500   \n",
            "...                         ...                    ...           ...   \n",
            "2007-02-10          2829.327881             192.973999  345653.03125   \n",
            "2007-02-11          3571.228027             204.313995  344888.84375   \n",
            "2007-02-12          1877.609985             136.703995  345741.84375   \n",
            "2007-02-13          1414.546021             134.677994  347280.28125   \n",
            "2007-02-14          1741.764038             143.328003  251928.81250   \n",
            "\n",
            "            Global_intensity  Sub_metering_1  Sub_metering_2  Sub_metering_3  \n",
            "datetime                                                                      \n",
            "2006-12-16       5180.799805             0.0           546.0          4926.0  \n",
            "2006-12-17      14398.599609          2033.0          4187.0         13341.0  \n",
            "2006-12-18       9247.200195          1063.0          2621.0         14018.0  \n",
            "2006-12-19       7094.000000           839.0          7602.0          6197.0  \n",
            "2006-12-20       9313.000000             0.0          2648.0         14063.0  \n",
            "...                      ...             ...             ...             ...  \n",
            "2007-02-10      11957.400391          5071.0          2831.0         14405.0  \n",
            "2007-02-11      15158.599609          2430.0          4765.0         13114.0  \n",
            "2007-02-12       7925.000000          2227.0           399.0         11517.0  \n",
            "2007-02-13       5967.000000             0.0          2828.0          6256.0  \n",
            "2007-02-14       7302.399902          2229.0          3631.0         10250.0  \n",
            "\n",
            "[61 rows x 7 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "As we can see, the last record in data is of 2010-11-26. Assuming the week starts as Sunday. So, let's try to pull earliest data of 2010 year in Sunday which is 2010-01-03. This is our testing set.\n",
        "\n",
        "All remaining data i.e, 2006-12-16 till 2010-01-02 is our training data."
      ],
      "metadata": {
        "id": "h9dgi3yKT3Ep"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 101,
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "ykcfsicrciYU"
      },
      "outputs": [],
      "source": [
        "# Number of features in the dataset. We use all features as predictors to predict all features of future time steps.\n",
        "num_features = len(dailyDF.columns)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "series_val = dailyDF[\"2007-01-07\":\"2007-02-14\"]\n",
        "series_train = dailyDF[\"2006-12-16\":\"2010-01-06\"]\n",
        "\n",
        "# series_val = dailyDF[\"2010-01-03\":\"2010-11-26\"]\n",
        "# series_train = dailyDF[\"2006-12-16\":\"2010-01-02\"]"
      ],
      "metadata": {
        "id": "e8yH1KLAUoas"
      },
      "execution_count": 88,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "SPLIT_TIME = np.array(series_val).shape[0]"
      ],
      "metadata": {
        "id": "pGepIJM18EeG"
      },
      "execution_count": 90,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Normalization"
      ],
      "metadata": {
        "id": "mnKCEvq6SOK9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data = np.array(series_train)\n",
        "train_mean = data.mean()\n",
        "train_std = data.std()"
      ],
      "metadata": {
        "id": "0x8KJlD_ZLhY"
      },
      "execution_count": 91,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "series_val = (series_val - train_mean)/train_std\n",
        "series_train = (series_train - train_mean)/train_std"
      ],
      "metadata": {
        "id": "xHEqZWpxSUHr"
      },
      "execution_count": 92,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Global Parameters"
      ],
      "metadata": {
        "id": "mRts1kwkZ9u4"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 93,
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "9TrGE7unciYV"
      },
      "outputs": [],
      "source": [
        "# Hyper-Parameters\n",
        "BATCH_SIZE = 32 # Batch size\n",
        "N_PAST = 7 # Number of past time steps based on which future observations should be predicted\n",
        "N_FUTURE = 7 # Number of future time steps which are to be predicted.\n",
        "SHIFT = 1 # By how many positions the window slides to create a new window of observations."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Batching of dataset"
      ],
      "metadata": {
        "id": "cPjf_FAQbpCE"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 94,
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "fR7hzrl5ciYV"
      },
      "outputs": [],
      "source": [
        "\n",
        "# This is multi step prediction.\n",
        "# window size = n_past + n_future\n",
        "# n_past --> no. of previous observations used to make forecast\n",
        "# n_future --> horizon for which we make forecast\n",
        "\n",
        "def windowed_dataset(series, batch_size, n_past=10, n_future=10, shift=1):\n",
        "\n",
        "    # Generate a TF Dataset from the series values\n",
        "    ds = tf.data.Dataset.from_tensor_slices(series)\n",
        "\n",
        "    # Window the data but only take those with the specified size\n",
        "    ds = ds.window(size=n_past + n_future, shift=shift, drop_remainder=True)\n",
        "\n",
        "    # Flatten the windows by putting its elements in a single batch\n",
        "    ds = ds.flat_map(lambda w: w.batch(n_past + n_future))\n",
        "\n",
        "    # Create tuples with features and labels\n",
        "    ds = ds.map(lambda w: (w[:n_past], w[n_past:])) #(window[:-1], window[-1])\n",
        "\n",
        "    # Create batches of windows\n",
        "    dataset = ds.batch(batch_size).prefetch(1)\n",
        "\n",
        "    return dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 95,
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "dc8AIWcBciYV"
      },
      "outputs": [],
      "source": [
        "# Windowed train and validation datasets.\n",
        "train_set = windowed_dataset(series_train, BATCH_SIZE, N_PAST, N_FUTURE, SHIFT)\n",
        "valid_set = windowed_dataset(series_val, BATCH_SIZE, N_PAST, N_FUTURE, SHIFT)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 98,
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lfkPBXdEciYV",
        "outputId": "54b72fff-01b3-42b5-dbfb-2173f8962a6d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of feature: (32, 7, 7)\n",
            "Shape of label: (32, 7, 7)\n",
            "Shape of feature: (26, 7, 7)\n",
            "Shape of label: (26, 7, 7)\n"
          ]
        }
      ],
      "source": [
        "# Print the data shape\n",
        "for window in train_set.take(1):\n",
        "    print(f'Shape of feature: {window[0].shape}')\n",
        "    print(f'Shape of label: {window[1].shape}')\n",
        "\n",
        "for window in valid_set.take(1):\n",
        "    print(f'Shape of feature: {window[0].shape}')\n",
        "    print(f'Shape of label: {window[1].shape}')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Build Model"
      ],
      "metadata": {
        "id": "cRF6UwsPcvU_"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "05OG_UadciYV",
        "outputId": "d126e3e1-e408-47e0-9b03-e9a3cbc70a04"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_1 (InputLayer)        [(None, 7, 8)]            0         \n",
            "                                                                 \n",
            " bidirectional (Bidirection  (None, 7, 256)            140288    \n",
            " al)                                                             \n",
            "                                                                 \n",
            " bidirectional_1 (Bidirecti  (None, 7, 128)            164352    \n",
            " onal)                                                           \n",
            "                                                                 \n",
            " bidirectional_2 (Bidirecti  (None, 64)                41216     \n",
            " onal)                                                           \n",
            "                                                                 \n",
            " dense (Dense)               (None, 56)                3640      \n",
            "                                                                 \n",
            " reshape (Reshape)           (None, 7, 8)              0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 349496 (1.33 MB)\n",
            "Trainable params: 349496 (1.33 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "# Code to define your model.\n",
        "inputs = tf.keras.layers.Input(shape=[N_PAST, num_features])\n",
        "# x = normalizer(inputs)\n",
        "x = tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(128, return_sequences=True))(inputs)\n",
        "x = tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(64, return_sequences=True))(x)\n",
        "#tf.keras.layers.Dropout(0.2),\n",
        "x = tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(32))(x)\n",
        "#tf.keras.layers.Dropout(0.2),\n",
        "x = tf.keras.layers.Dense(num_features* N_FUTURE)(x)\n",
        "outputs = tf.keras.layers.Reshape([N_FUTURE, num_features])(x)\n",
        "\n",
        "model = tf.keras.Model(inputs,outputs)\n",
        "\n",
        "# Model Summary\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EtSCmjQfXyKi"
      },
      "source": [
        "## Tune the Learning Rate\n",
        "\n",
        "As usual, you will want to pick an optimal learning rate."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Get initial weights\n",
        "init_weights = model.get_weights()"
      ],
      "metadata": {
        "id": "qQnq8UZQKhdx"
      },
      "execution_count": 99,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Set the learning rate scheduler\n",
        "lr_schedule = tf.keras.callbacks.LearningRateScheduler(\n",
        "    lambda epoch: 1e-3 * 10**(epoch/20))\n",
        "\n",
        "# Initialize the optimizer\n",
        "optimizer=tf.keras.optimizers.SGD(momentum=0.9)\n",
        "\n",
        "# Set the training parameters\n",
        "model.compile(loss=tf.keras.losses.Huber(),\n",
        "              optimizer=optimizer)\n",
        "\n",
        "# Train the model\n",
        "history = model.fit(train_set, epochs=100, callbacks=[lr_schedule])"
      ],
      "metadata": {
        "id": "UBvI9QhMKtKR",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 599
        },
        "outputId": "bdf2d310-1906-440e-898c-55d9f638a470"
      },
      "execution_count": 100,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "in user code:\n\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 1401, in train_function  *\n        return step_function(self, iterator)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 1384, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 1373, in run_step  **\n        outputs = model.train_step(data)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 1150, in train_step\n        y_pred = self(x, training=True)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\", line 70, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/input_spec.py\", line 298, in assert_input_compatibility\n        raise ValueError(\n\n    ValueError: Input 0 of layer \"model\" is incompatible with the layer: expected shape=(None, 7, 8), found shape=(None, None, 7)\n",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-100-69fd4bb8701d>\u001b[0m in \u001b[0;36m<cell line: 13>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;31m# Train the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_set\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlr_schedule\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     68\u001b[0m             \u001b[0;31m# To get the full stack trace, call:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m             \u001b[0;31m# `tf.debugging.disable_traceback_filtering()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\u001b[0m in \u001b[0;36mtf__train_function\u001b[0;34m(iterator)\u001b[0m\n\u001b[1;32m     13\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m                     \u001b[0mdo_return\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m                     \u001b[0mretval_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep_function\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfscope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m                 \u001b[0;32mexcept\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m                     \u001b[0mdo_return\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: in user code:\n\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 1401, in train_function  *\n        return step_function(self, iterator)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 1384, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 1373, in run_step  **\n        outputs = model.train_step(data)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 1150, in train_step\n        y_pred = self(x, training=True)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\", line 70, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/input_spec.py\", line 298, in assert_input_compatibility\n        raise ValueError(\n\n    ValueError: Input 0 of layer \"model\" is incompatible with the layer: expected shape=(None, 7, 8), found shape=(None, None, 7)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "id": "vVcKmg7Q_7rD",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 558
        },
        "outputId": "0da97d7b-940c-4bdb-9e13-d50d31177cb2"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1e-05, 1000.0, 0.0, 1.0)"
            ]
          },
          "metadata": {},
          "execution_count": 53
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x600 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "# # Define the learning rate array\n",
        "lrs = 1e-5 * (10 ** (np.arange(100) / 20))\n",
        "\n",
        "# Set the figure size\n",
        "plt.figure(figsize=(10, 6))\n",
        "\n",
        "# Set the grid\n",
        "plt.grid(True)\n",
        "\n",
        "# Plot the loss in log scale\n",
        "plt.semilogx(lrs, history.history[\"loss\"])\n",
        "\n",
        "# Increase the tickmarks size\n",
        "plt.tick_params('both', length=10, width=1, which='both')\n",
        "\n",
        "# Set the plot boundaries\n",
        "plt.axis([1e-5, 1e3, 0, 1])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i-Pn-n60X3uV"
      },
      "source": [
        "## Train the Model Completely(for longer epoch)\n",
        "\n",
        "Now you can proceed to reset and train the model. It is set for 100 epochs in the cell below but feel free to increase it if you want. Laurence got his results in the lectures after 500."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Reset states generated by Keras\n",
        "tf.keras.backend.clear_session()\n",
        "\n",
        "# Reset the weights\n",
        "model.set_weights(init_weights)"
      ],
      "metadata": {
        "id": "wcQZ9K9lLeQS"
      },
      "execution_count": 137,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize learning rate\n",
        "lr = 6e-5\n",
        "\n",
        "# Initialize the optimizer\n",
        "optimizer = tf.keras.optimizers.SGD(momentum=0.9, learning_rate=lr)\n",
        "\n",
        "\n",
        "# Set the training parameters\n",
        "model.compile(loss=tf.keras.losses.Huber(), optimizer=optimizer, metrics=['mae','mse'])\n",
        "\n",
        "#callback\n",
        "RLP = tf.keras.callbacks.ReduceLROnPlateau(\n",
        "    monitor=\"val_mae\",\n",
        "    patience=3,\n",
        "    verbose=2,\n",
        "    mode=\"auto\"\n",
        ")\n",
        "\n",
        "ES = tf.keras.callbacks.EarlyStopping(\n",
        "    monitor=\"val_mae\",\n",
        "    patience=15,\n",
        "    verbose=2,\n",
        "    mode=\"auto\",\n",
        "    start_from_epoch=10\n",
        ")\n",
        "\n",
        "# Train the model\n",
        "history = model.fit(train_set, epochs=500, validation_data=valid_set, verbose = 2, callbacks=[ES])"
      ],
      "metadata": {
        "id": "gaMjfgokLpwg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "db890fe5-0b92-4cb3-fd27-90af5e8f4553"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/500\n",
            "35/35 - 16s - loss: 0.0024 - mae: 0.0269 - mse: 0.0069 - val_loss: 0.0122 - val_mae: 0.0369 - val_mse: 0.0416 - 16s/epoch - 467ms/step\n",
            "Epoch 2/500\n",
            "35/35 - 3s - loss: 0.0024 - mae: 0.0269 - mse: 0.0069 - val_loss: 0.0122 - val_mae: 0.0369 - val_mse: 0.0416 - 3s/epoch - 96ms/step\n",
            "Epoch 3/500\n",
            "35/35 - 3s - loss: 0.0024 - mae: 0.0268 - mse: 0.0069 - val_loss: 0.0122 - val_mae: 0.0369 - val_mse: 0.0416 - 3s/epoch - 80ms/step\n",
            "Epoch 4/500\n",
            "35/35 - 2s - loss: 0.0024 - mae: 0.0268 - mse: 0.0069 - val_loss: 0.0122 - val_mae: 0.0369 - val_mse: 0.0416 - 2s/epoch - 53ms/step\n",
            "Epoch 5/500\n",
            "35/35 - 2s - loss: 0.0024 - mae: 0.0268 - mse: 0.0069 - val_loss: 0.0122 - val_mae: 0.0368 - val_mse: 0.0416 - 2s/epoch - 53ms/step\n",
            "Epoch 6/500\n",
            "35/35 - 2s - loss: 0.0024 - mae: 0.0268 - mse: 0.0069 - val_loss: 0.0122 - val_mae: 0.0368 - val_mse: 0.0416 - 2s/epoch - 53ms/step\n",
            "Epoch 7/500\n",
            "35/35 - 3s - loss: 0.0024 - mae: 0.0268 - mse: 0.0069 - val_loss: 0.0122 - val_mae: 0.0368 - val_mse: 0.0416 - 3s/epoch - 91ms/step\n",
            "Epoch 8/500\n",
            "35/35 - 2s - loss: 0.0024 - mae: 0.0268 - mse: 0.0069 - val_loss: 0.0122 - val_mae: 0.0368 - val_mse: 0.0416 - 2s/epoch - 47ms/step\n",
            "Epoch 9/500\n",
            "35/35 - 2s - loss: 0.0024 - mae: 0.0268 - mse: 0.0069 - val_loss: 0.0122 - val_mae: 0.0368 - val_mse: 0.0416 - 2s/epoch - 48ms/step\n",
            "Epoch 10/500\n",
            "35/35 - 2s - loss: 0.0024 - mae: 0.0268 - mse: 0.0069 - val_loss: 0.0122 - val_mae: 0.0368 - val_mse: 0.0416 - 2s/epoch - 49ms/step\n",
            "Epoch 11/500\n",
            "35/35 - 2s - loss: 0.0024 - mae: 0.0268 - mse: 0.0069 - val_loss: 0.0122 - val_mae: 0.0368 - val_mse: 0.0416 - 2s/epoch - 50ms/step\n",
            "Epoch 12/500\n",
            "35/35 - 2s - loss: 0.0024 - mae: 0.0268 - mse: 0.0069 - val_loss: 0.0122 - val_mae: 0.0368 - val_mse: 0.0416 - 2s/epoch - 48ms/step\n",
            "Epoch 13/500\n",
            "35/35 - 3s - loss: 0.0024 - mae: 0.0268 - mse: 0.0069 - val_loss: 0.0122 - val_mae: 0.0368 - val_mse: 0.0416 - 3s/epoch - 98ms/step\n",
            "Epoch 14/500\n",
            "35/35 - 3s - loss: 0.0024 - mae: 0.0268 - mse: 0.0069 - val_loss: 0.0122 - val_mae: 0.0368 - val_mse: 0.0416 - 3s/epoch - 77ms/step\n",
            "Epoch 15/500\n",
            "35/35 - 2s - loss: 0.0024 - mae: 0.0268 - mse: 0.0069 - val_loss: 0.0122 - val_mae: 0.0368 - val_mse: 0.0416 - 2s/epoch - 52ms/step\n",
            "Epoch 16/500\n",
            "35/35 - 2s - loss: 0.0023 - mae: 0.0268 - mse: 0.0069 - val_loss: 0.0122 - val_mae: 0.0368 - val_mse: 0.0416 - 2s/epoch - 48ms/step\n",
            "Epoch 17/500\n",
            "35/35 - 2s - loss: 0.0023 - mae: 0.0268 - mse: 0.0069 - val_loss: 0.0122 - val_mae: 0.0368 - val_mse: 0.0416 - 2s/epoch - 52ms/step\n",
            "Epoch 18/500\n",
            "35/35 - 4s - loss: 0.0023 - mae: 0.0268 - mse: 0.0069 - val_loss: 0.0122 - val_mae: 0.0368 - val_mse: 0.0416 - 4s/epoch - 102ms/step\n",
            "Epoch 19/500\n",
            "35/35 - 2s - loss: 0.0023 - mae: 0.0268 - mse: 0.0069 - val_loss: 0.0122 - val_mae: 0.0368 - val_mse: 0.0416 - 2s/epoch - 52ms/step\n",
            "Epoch 20/500\n",
            "35/35 - 2s - loss: 0.0023 - mae: 0.0268 - mse: 0.0069 - val_loss: 0.0122 - val_mae: 0.0368 - val_mse: 0.0416 - 2s/epoch - 52ms/step\n",
            "Epoch 21/500\n",
            "35/35 - 2s - loss: 0.0023 - mae: 0.0268 - mse: 0.0069 - val_loss: 0.0122 - val_mae: 0.0368 - val_mse: 0.0416 - 2s/epoch - 52ms/step\n",
            "Epoch 22/500\n",
            "35/35 - 2s - loss: 0.0023 - mae: 0.0268 - mse: 0.0069 - val_loss: 0.0122 - val_mae: 0.0368 - val_mse: 0.0416 - 2s/epoch - 49ms/step\n",
            "Epoch 23/500\n",
            "35/35 - 4s - loss: 0.0023 - mae: 0.0268 - mse: 0.0069 - val_loss: 0.0122 - val_mae: 0.0368 - val_mse: 0.0416 - 4s/epoch - 115ms/step\n",
            "Epoch 24/500\n",
            "35/35 - 3s - loss: 0.0023 - mae: 0.0268 - mse: 0.0069 - val_loss: 0.0122 - val_mae: 0.0368 - val_mse: 0.0416 - 3s/epoch - 76ms/step\n",
            "Epoch 25/500\n",
            "35/35 - 2s - loss: 0.0023 - mae: 0.0267 - mse: 0.0069 - val_loss: 0.0122 - val_mae: 0.0368 - val_mse: 0.0416 - 2s/epoch - 56ms/step\n",
            "Epoch 26/500\n",
            "35/35 - 2s - loss: 0.0023 - mae: 0.0267 - mse: 0.0069 - val_loss: 0.0122 - val_mae: 0.0368 - val_mse: 0.0416 - 2s/epoch - 48ms/step\n",
            "Epoch 27/500\n",
            "35/35 - 2s - loss: 0.0023 - mae: 0.0267 - mse: 0.0069 - val_loss: 0.0122 - val_mae: 0.0367 - val_mse: 0.0416 - 2s/epoch - 53ms/step\n",
            "Epoch 28/500\n",
            "35/35 - 3s - loss: 0.0023 - mae: 0.0267 - mse: 0.0069 - val_loss: 0.0122 - val_mae: 0.0367 - val_mse: 0.0416 - 3s/epoch - 97ms/step\n",
            "Epoch 29/500\n",
            "35/35 - 2s - loss: 0.0023 - mae: 0.0267 - mse: 0.0069 - val_loss: 0.0122 - val_mae: 0.0367 - val_mse: 0.0416 - 2s/epoch - 51ms/step\n",
            "Epoch 30/500\n",
            "35/35 - 2s - loss: 0.0023 - mae: 0.0267 - mse: 0.0069 - val_loss: 0.0122 - val_mae: 0.0367 - val_mse: 0.0416 - 2s/epoch - 52ms/step\n",
            "Epoch 31/500\n",
            "35/35 - 2s - loss: 0.0023 - mae: 0.0267 - mse: 0.0069 - val_loss: 0.0122 - val_mae: 0.0367 - val_mse: 0.0416 - 2s/epoch - 52ms/step\n",
            "Epoch 32/500\n",
            "35/35 - 2s - loss: 0.0023 - mae: 0.0267 - mse: 0.0069 - val_loss: 0.0122 - val_mae: 0.0367 - val_mse: 0.0416 - 2s/epoch - 49ms/step\n",
            "Epoch 33/500\n",
            "35/35 - 3s - loss: 0.0023 - mae: 0.0267 - mse: 0.0069 - val_loss: 0.0122 - val_mae: 0.0367 - val_mse: 0.0416 - 3s/epoch - 87ms/step\n",
            "Epoch 34/500\n",
            "35/35 - 3s - loss: 0.0023 - mae: 0.0267 - mse: 0.0069 - val_loss: 0.0122 - val_mae: 0.0367 - val_mse: 0.0416 - 3s/epoch - 88ms/step\n",
            "Epoch 35/500\n",
            "35/35 - 2s - loss: 0.0023 - mae: 0.0267 - mse: 0.0069 - val_loss: 0.0122 - val_mae: 0.0367 - val_mse: 0.0416 - 2s/epoch - 53ms/step\n",
            "Epoch 36/500\n",
            "35/35 - 2s - loss: 0.0023 - mae: 0.0267 - mse: 0.0069 - val_loss: 0.0122 - val_mae: 0.0367 - val_mse: 0.0416 - 2s/epoch - 55ms/step\n",
            "Epoch 37/500\n",
            "35/35 - 3s - loss: 0.0023 - mae: 0.0267 - mse: 0.0069 - val_loss: 0.0122 - val_mae: 0.0367 - val_mse: 0.0416 - 3s/epoch - 85ms/step\n",
            "Epoch 38/500\n",
            "35/35 - 3s - loss: 0.0023 - mae: 0.0267 - mse: 0.0069 - val_loss: 0.0122 - val_mae: 0.0367 - val_mse: 0.0416 - 3s/epoch - 77ms/step\n",
            "Epoch 39/500\n",
            "35/35 - 2s - loss: 0.0023 - mae: 0.0267 - mse: 0.0069 - val_loss: 0.0122 - val_mae: 0.0367 - val_mse: 0.0416 - 2s/epoch - 49ms/step\n",
            "Epoch 40/500\n",
            "35/35 - 2s - loss: 0.0023 - mae: 0.0267 - mse: 0.0069 - val_loss: 0.0122 - val_mae: 0.0367 - val_mse: 0.0416 - 2s/epoch - 49ms/step\n",
            "Epoch 41/500\n",
            "35/35 - 2s - loss: 0.0023 - mae: 0.0267 - mse: 0.0069 - val_loss: 0.0122 - val_mae: 0.0367 - val_mse: 0.0416 - 2s/epoch - 52ms/step\n",
            "Epoch 42/500\n",
            "35/35 - 3s - loss: 0.0023 - mae: 0.0267 - mse: 0.0069 - val_loss: 0.0122 - val_mae: 0.0367 - val_mse: 0.0416 - 3s/epoch - 89ms/step\n",
            "Epoch 43/500\n",
            "35/35 - 3s - loss: 0.0023 - mae: 0.0267 - mse: 0.0069 - val_loss: 0.0122 - val_mae: 0.0367 - val_mse: 0.0416 - 3s/epoch - 85ms/step\n",
            "Epoch 44/500\n",
            "35/35 - 2s - loss: 0.0023 - mae: 0.0267 - mse: 0.0069 - val_loss: 0.0122 - val_mae: 0.0367 - val_mse: 0.0416 - 2s/epoch - 51ms/step\n",
            "Epoch 45/500\n",
            "35/35 - 2s - loss: 0.0023 - mae: 0.0267 - mse: 0.0069 - val_loss: 0.0122 - val_mae: 0.0367 - val_mse: 0.0416 - 2s/epoch - 51ms/step\n",
            "Epoch 46/500\n",
            "35/35 - 2s - loss: 0.0023 - mae: 0.0267 - mse: 0.0069 - val_loss: 0.0122 - val_mae: 0.0367 - val_mse: 0.0416 - 2s/epoch - 52ms/step\n",
            "Epoch 47/500\n",
            "35/35 - 2s - loss: 0.0023 - mae: 0.0267 - mse: 0.0069 - val_loss: 0.0122 - val_mae: 0.0367 - val_mse: 0.0416 - 2s/epoch - 51ms/step\n",
            "Epoch 48/500\n",
            "35/35 - 2s - loss: 0.0023 - mae: 0.0266 - mse: 0.0069 - val_loss: 0.0122 - val_mae: 0.0367 - val_mse: 0.0416 - 2s/epoch - 59ms/step\n",
            "Epoch 49/500\n",
            "35/35 - 4s - loss: 0.0023 - mae: 0.0266 - mse: 0.0069 - val_loss: 0.0122 - val_mae: 0.0367 - val_mse: 0.0416 - 4s/epoch - 105ms/step\n",
            "Epoch 50/500\n",
            "35/35 - 2s - loss: 0.0023 - mae: 0.0266 - mse: 0.0069 - val_loss: 0.0122 - val_mae: 0.0366 - val_mse: 0.0416 - 2s/epoch - 61ms/step\n",
            "Epoch 51/500\n",
            "35/35 - 2s - loss: 0.0023 - mae: 0.0266 - mse: 0.0069 - val_loss: 0.0122 - val_mae: 0.0366 - val_mse: 0.0416 - 2s/epoch - 49ms/step\n",
            "Epoch 52/500\n",
            "35/35 - 2s - loss: 0.0023 - mae: 0.0266 - mse: 0.0069 - val_loss: 0.0122 - val_mae: 0.0366 - val_mse: 0.0416 - 2s/epoch - 51ms/step\n",
            "Epoch 53/500\n",
            "35/35 - 2s - loss: 0.0023 - mae: 0.0266 - mse: 0.0069 - val_loss: 0.0122 - val_mae: 0.0366 - val_mse: 0.0416 - 2s/epoch - 48ms/step\n",
            "Epoch 54/500\n",
            "35/35 - 2s - loss: 0.0023 - mae: 0.0266 - mse: 0.0069 - val_loss: 0.0122 - val_mae: 0.0366 - val_mse: 0.0416 - 2s/epoch - 59ms/step\n",
            "Epoch 55/500\n",
            "35/35 - 4s - loss: 0.0023 - mae: 0.0266 - mse: 0.0069 - val_loss: 0.0122 - val_mae: 0.0366 - val_mse: 0.0416 - 4s/epoch - 105ms/step\n",
            "Epoch 56/500\n",
            "35/35 - 2s - loss: 0.0023 - mae: 0.0266 - mse: 0.0069 - val_loss: 0.0122 - val_mae: 0.0366 - val_mse: 0.0416 - 2s/epoch - 52ms/step\n",
            "Epoch 57/500\n",
            "35/35 - 2s - loss: 0.0023 - mae: 0.0266 - mse: 0.0069 - val_loss: 0.0122 - val_mae: 0.0366 - val_mse: 0.0416 - 2s/epoch - 52ms/step\n",
            "Epoch 58/500\n",
            "35/35 - 2s - loss: 0.0023 - mae: 0.0266 - mse: 0.0069 - val_loss: 0.0122 - val_mae: 0.0366 - val_mse: 0.0416 - 2s/epoch - 54ms/step\n",
            "Epoch 59/500\n",
            "35/35 - 2s - loss: 0.0023 - mae: 0.0266 - mse: 0.0069 - val_loss: 0.0122 - val_mae: 0.0366 - val_mse: 0.0416 - 2s/epoch - 53ms/step\n",
            "Epoch 60/500\n",
            "35/35 - 2s - loss: 0.0023 - mae: 0.0266 - mse: 0.0069 - val_loss: 0.0122 - val_mae: 0.0366 - val_mse: 0.0416 - 2s/epoch - 48ms/step\n",
            "Epoch 61/500\n",
            "35/35 - 4s - loss: 0.0023 - mae: 0.0266 - mse: 0.0069 - val_loss: 0.0122 - val_mae: 0.0366 - val_mse: 0.0415 - 4s/epoch - 104ms/step\n",
            "Epoch 62/500\n",
            "35/35 - 2s - loss: 0.0023 - mae: 0.0266 - mse: 0.0069 - val_loss: 0.0122 - val_mae: 0.0366 - val_mse: 0.0415 - 2s/epoch - 52ms/step\n",
            "Epoch 63/500\n",
            "35/35 - 2s - loss: 0.0023 - mae: 0.0266 - mse: 0.0069 - val_loss: 0.0122 - val_mae: 0.0366 - val_mse: 0.0415 - 2s/epoch - 48ms/step\n",
            "Epoch 64/500\n",
            "35/35 - 2s - loss: 0.0023 - mae: 0.0266 - mse: 0.0069 - val_loss: 0.0122 - val_mae: 0.0366 - val_mse: 0.0415 - 2s/epoch - 49ms/step\n",
            "Epoch 65/500\n",
            "35/35 - 2s - loss: 0.0023 - mae: 0.0266 - mse: 0.0069 - val_loss: 0.0122 - val_mae: 0.0366 - val_mse: 0.0415 - 2s/epoch - 51ms/step\n",
            "Epoch 66/500\n",
            "35/35 - 2s - loss: 0.0023 - mae: 0.0266 - mse: 0.0069 - val_loss: 0.0122 - val_mae: 0.0366 - val_mse: 0.0415 - 2s/epoch - 53ms/step\n",
            "Epoch 67/500\n",
            "35/35 - 3s - loss: 0.0023 - mae: 0.0266 - mse: 0.0069 - val_loss: 0.0122 - val_mae: 0.0366 - val_mse: 0.0415 - 3s/epoch - 80ms/step\n",
            "Epoch 68/500\n",
            "35/35 - 2s - loss: 0.0023 - mae: 0.0266 - mse: 0.0069 - val_loss: 0.0122 - val_mae: 0.0366 - val_mse: 0.0415 - 2s/epoch - 49ms/step\n",
            "Epoch 69/500\n",
            "35/35 - 2s - loss: 0.0023 - mae: 0.0266 - mse: 0.0069 - val_loss: 0.0121 - val_mae: 0.0366 - val_mse: 0.0415 - 2s/epoch - 53ms/step\n",
            "Epoch 70/500\n",
            "35/35 - 2s - loss: 0.0023 - mae: 0.0266 - mse: 0.0069 - val_loss: 0.0121 - val_mae: 0.0366 - val_mse: 0.0415 - 2s/epoch - 51ms/step\n",
            "Epoch 71/500\n",
            "35/35 - 2s - loss: 0.0023 - mae: 0.0265 - mse: 0.0069 - val_loss: 0.0121 - val_mae: 0.0366 - val_mse: 0.0415 - 2s/epoch - 53ms/step\n",
            "Epoch 72/500\n",
            "35/35 - 2s - loss: 0.0023 - mae: 0.0265 - mse: 0.0069 - val_loss: 0.0121 - val_mae: 0.0365 - val_mse: 0.0415 - 2s/epoch - 53ms/step\n",
            "Epoch 73/500\n",
            "35/35 - 3s - loss: 0.0023 - mae: 0.0265 - mse: 0.0069 - val_loss: 0.0121 - val_mae: 0.0365 - val_mse: 0.0415 - 3s/epoch - 98ms/step\n",
            "Epoch 74/500\n",
            "35/35 - 2s - loss: 0.0023 - mae: 0.0265 - mse: 0.0069 - val_loss: 0.0121 - val_mae: 0.0365 - val_mse: 0.0415 - 2s/epoch - 51ms/step\n",
            "Epoch 75/500\n",
            "35/35 - 2s - loss: 0.0023 - mae: 0.0265 - mse: 0.0069 - val_loss: 0.0121 - val_mae: 0.0365 - val_mse: 0.0415 - 2s/epoch - 53ms/step\n",
            "Epoch 76/500\n",
            "35/35 - 2s - loss: 0.0023 - mae: 0.0265 - mse: 0.0069 - val_loss: 0.0121 - val_mae: 0.0365 - val_mse: 0.0415 - 2s/epoch - 51ms/step\n",
            "Epoch 77/500\n",
            "35/35 - 2s - loss: 0.0023 - mae: 0.0265 - mse: 0.0069 - val_loss: 0.0121 - val_mae: 0.0365 - val_mse: 0.0415 - 2s/epoch - 52ms/step\n",
            "Epoch 78/500\n",
            "35/35 - 3s - loss: 0.0023 - mae: 0.0265 - mse: 0.0069 - val_loss: 0.0121 - val_mae: 0.0365 - val_mse: 0.0415 - 3s/epoch - 85ms/step\n",
            "Epoch 79/500\n",
            "35/35 - 3s - loss: 0.0023 - mae: 0.0265 - mse: 0.0069 - val_loss: 0.0121 - val_mae: 0.0365 - val_mse: 0.0415 - 3s/epoch - 93ms/step\n",
            "Epoch 80/500\n",
            "35/35 - 2s - loss: 0.0023 - mae: 0.0265 - mse: 0.0069 - val_loss: 0.0121 - val_mae: 0.0365 - val_mse: 0.0415 - 2s/epoch - 47ms/step\n",
            "Epoch 81/500\n",
            "35/35 - 2s - loss: 0.0023 - mae: 0.0265 - mse: 0.0069 - val_loss: 0.0121 - val_mae: 0.0365 - val_mse: 0.0415 - 2s/epoch - 49ms/step\n",
            "Epoch 82/500\n",
            "35/35 - 2s - loss: 0.0023 - mae: 0.0265 - mse: 0.0069 - val_loss: 0.0121 - val_mae: 0.0365 - val_mse: 0.0415 - 2s/epoch - 52ms/step\n",
            "Epoch 83/500\n",
            "35/35 - 2s - loss: 0.0023 - mae: 0.0265 - mse: 0.0069 - val_loss: 0.0121 - val_mae: 0.0365 - val_mse: 0.0415 - 2s/epoch - 52ms/step\n",
            "Epoch 84/500\n",
            "35/35 - 4s - loss: 0.0023 - mae: 0.0265 - mse: 0.0069 - val_loss: 0.0121 - val_mae: 0.0365 - val_mse: 0.0415 - 4s/epoch - 105ms/step\n",
            "Epoch 85/500\n",
            "35/35 - 2s - loss: 0.0023 - mae: 0.0265 - mse: 0.0069 - val_loss: 0.0121 - val_mae: 0.0365 - val_mse: 0.0415 - 2s/epoch - 49ms/step\n",
            "Epoch 86/500\n",
            "35/35 - 2s - loss: 0.0023 - mae: 0.0265 - mse: 0.0069 - val_loss: 0.0121 - val_mae: 0.0365 - val_mse: 0.0415 - 2s/epoch - 54ms/step\n",
            "Epoch 87/500\n",
            "35/35 - 2s - loss: 0.0023 - mae: 0.0265 - mse: 0.0069 - val_loss: 0.0121 - val_mae: 0.0365 - val_mse: 0.0415 - 2s/epoch - 49ms/step\n",
            "Epoch 88/500\n",
            "35/35 - 2s - loss: 0.0023 - mae: 0.0265 - mse: 0.0069 - val_loss: 0.0121 - val_mae: 0.0365 - val_mse: 0.0415 - 2s/epoch - 53ms/step\n",
            "Epoch 89/500\n",
            "35/35 - 4s - loss: 0.0023 - mae: 0.0265 - mse: 0.0069 - val_loss: 0.0121 - val_mae: 0.0365 - val_mse: 0.0415 - 4s/epoch - 102ms/step\n",
            "Epoch 90/500\n",
            "35/35 - 2s - loss: 0.0023 - mae: 0.0265 - mse: 0.0069 - val_loss: 0.0121 - val_mae: 0.0365 - val_mse: 0.0415 - 2s/epoch - 49ms/step\n",
            "Epoch 91/500\n",
            "35/35 - 2s - loss: 0.0023 - mae: 0.0265 - mse: 0.0069 - val_loss: 0.0121 - val_mae: 0.0365 - val_mse: 0.0415 - 2s/epoch - 49ms/step\n",
            "Epoch 92/500\n",
            "35/35 - 2s - loss: 0.0023 - mae: 0.0265 - mse: 0.0069 - val_loss: 0.0121 - val_mae: 0.0365 - val_mse: 0.0415 - 2s/epoch - 48ms/step\n",
            "Epoch 93/500\n",
            "35/35 - 2s - loss: 0.0023 - mae: 0.0265 - mse: 0.0069 - val_loss: 0.0121 - val_mae: 0.0365 - val_mse: 0.0415 - 2s/epoch - 56ms/step\n",
            "Epoch 94/500\n",
            "35/35 - 3s - loss: 0.0023 - mae: 0.0264 - mse: 0.0069 - val_loss: 0.0121 - val_mae: 0.0365 - val_mse: 0.0415 - 3s/epoch - 93ms/step\n",
            "Epoch 95/500\n",
            "35/35 - 3s - loss: 0.0023 - mae: 0.0264 - mse: 0.0069 - val_loss: 0.0121 - val_mae: 0.0364 - val_mse: 0.0415 - 3s/epoch - 72ms/step\n",
            "Epoch 96/500\n",
            "35/35 - 2s - loss: 0.0023 - mae: 0.0264 - mse: 0.0069 - val_loss: 0.0121 - val_mae: 0.0364 - val_mse: 0.0415 - 2s/epoch - 50ms/step\n",
            "Epoch 97/500\n",
            "35/35 - 2s - loss: 0.0023 - mae: 0.0264 - mse: 0.0069 - val_loss: 0.0121 - val_mae: 0.0364 - val_mse: 0.0415 - 2s/epoch - 51ms/step\n",
            "Epoch 98/500\n",
            "35/35 - 2s - loss: 0.0023 - mae: 0.0264 - mse: 0.0069 - val_loss: 0.0121 - val_mae: 0.0364 - val_mse: 0.0415 - 2s/epoch - 49ms/step\n",
            "Epoch 99/500\n",
            "35/35 - 2s - loss: 0.0023 - mae: 0.0264 - mse: 0.0069 - val_loss: 0.0121 - val_mae: 0.0364 - val_mse: 0.0415 - 2s/epoch - 48ms/step\n",
            "Epoch 100/500\n",
            "35/35 - 4s - loss: 0.0023 - mae: 0.0264 - mse: 0.0069 - val_loss: 0.0121 - val_mae: 0.0364 - val_mse: 0.0415 - 4s/epoch - 107ms/step\n",
            "Epoch 101/500\n",
            "35/35 - 2s - loss: 0.0023 - mae: 0.0264 - mse: 0.0069 - val_loss: 0.0121 - val_mae: 0.0364 - val_mse: 0.0415 - 2s/epoch - 62ms/step\n",
            "Epoch 102/500\n",
            "35/35 - 2s - loss: 0.0023 - mae: 0.0264 - mse: 0.0069 - val_loss: 0.0121 - val_mae: 0.0364 - val_mse: 0.0415 - 2s/epoch - 48ms/step\n",
            "Epoch 103/500\n",
            "35/35 - 2s - loss: 0.0023 - mae: 0.0264 - mse: 0.0069 - val_loss: 0.0121 - val_mae: 0.0364 - val_mse: 0.0415 - 2s/epoch - 54ms/step\n",
            "Epoch 104/500\n",
            "35/35 - 2s - loss: 0.0023 - mae: 0.0264 - mse: 0.0069 - val_loss: 0.0121 - val_mae: 0.0364 - val_mse: 0.0415 - 2s/epoch - 51ms/step\n",
            "Epoch 105/500\n",
            "35/35 - 3s - loss: 0.0023 - mae: 0.0264 - mse: 0.0069 - val_loss: 0.0121 - val_mae: 0.0364 - val_mse: 0.0415 - 3s/epoch - 72ms/step\n",
            "Epoch 106/500\n",
            "35/35 - 4s - loss: 0.0023 - mae: 0.0264 - mse: 0.0069 - val_loss: 0.0121 - val_mae: 0.0364 - val_mse: 0.0415 - 4s/epoch - 106ms/step\n",
            "Epoch 107/500\n",
            "35/35 - 2s - loss: 0.0023 - mae: 0.0264 - mse: 0.0069 - val_loss: 0.0121 - val_mae: 0.0364 - val_mse: 0.0415 - 2s/epoch - 52ms/step\n",
            "Epoch 108/500\n",
            "35/35 - 2s - loss: 0.0023 - mae: 0.0264 - mse: 0.0069 - val_loss: 0.0121 - val_mae: 0.0364 - val_mse: 0.0415 - 2s/epoch - 48ms/step\n",
            "Epoch 109/500\n",
            "35/35 - 2s - loss: 0.0023 - mae: 0.0264 - mse: 0.0069 - val_loss: 0.0121 - val_mae: 0.0364 - val_mse: 0.0415 - 2s/epoch - 54ms/step\n",
            "Epoch 110/500\n",
            "35/35 - 3s - loss: 0.0023 - mae: 0.0264 - mse: 0.0069 - val_loss: 0.0121 - val_mae: 0.0364 - val_mse: 0.0415 - 3s/epoch - 84ms/step\n",
            "Epoch 111/500\n",
            "35/35 - 3s - loss: 0.0023 - mae: 0.0264 - mse: 0.0069 - val_loss: 0.0121 - val_mae: 0.0364 - val_mse: 0.0415 - 3s/epoch - 92ms/step\n",
            "Epoch 112/500\n",
            "35/35 - 2s - loss: 0.0023 - mae: 0.0264 - mse: 0.0069 - val_loss: 0.0121 - val_mae: 0.0364 - val_mse: 0.0415 - 2s/epoch - 52ms/step\n",
            "Epoch 113/500\n",
            "35/35 - 2s - loss: 0.0023 - mae: 0.0264 - mse: 0.0069 - val_loss: 0.0121 - val_mae: 0.0364 - val_mse: 0.0415 - 2s/epoch - 53ms/step\n",
            "Epoch 114/500\n",
            "35/35 - 2s - loss: 0.0023 - mae: 0.0264 - mse: 0.0069 - val_loss: 0.0121 - val_mae: 0.0364 - val_mse: 0.0415 - 2s/epoch - 55ms/step\n",
            "Epoch 115/500\n",
            "35/35 - 2s - loss: 0.0023 - mae: 0.0264 - mse: 0.0069 - val_loss: 0.0121 - val_mae: 0.0364 - val_mse: 0.0415 - 2s/epoch - 59ms/step\n",
            "Epoch 116/500\n",
            "35/35 - 4s - loss: 0.0023 - mae: 0.0264 - mse: 0.0069 - val_loss: 0.0121 - val_mae: 0.0364 - val_mse: 0.0415 - 4s/epoch - 105ms/step\n",
            "Epoch 117/500\n",
            "35/35 - 2s - loss: 0.0023 - mae: 0.0263 - mse: 0.0069 - val_loss: 0.0121 - val_mae: 0.0364 - val_mse: 0.0415 - 2s/epoch - 57ms/step\n",
            "Epoch 118/500\n",
            "35/35 - 2s - loss: 0.0023 - mae: 0.0263 - mse: 0.0069 - val_loss: 0.0121 - val_mae: 0.0363 - val_mse: 0.0415 - 2s/epoch - 48ms/step\n",
            "Epoch 119/500\n",
            "35/35 - 2s - loss: 0.0023 - mae: 0.0263 - mse: 0.0069 - val_loss: 0.0121 - val_mae: 0.0363 - val_mse: 0.0415 - 2s/epoch - 52ms/step\n",
            "Epoch 120/500\n",
            "35/35 - 2s - loss: 0.0023 - mae: 0.0263 - mse: 0.0069 - val_loss: 0.0121 - val_mae: 0.0363 - val_mse: 0.0415 - 2s/epoch - 50ms/step\n",
            "Epoch 121/500\n",
            "35/35 - 3s - loss: 0.0023 - mae: 0.0263 - mse: 0.0069 - val_loss: 0.0121 - val_mae: 0.0363 - val_mse: 0.0415 - 3s/epoch - 94ms/step\n",
            "Epoch 122/500\n",
            "35/35 - 2s - loss: 0.0023 - mae: 0.0263 - mse: 0.0069 - val_loss: 0.0121 - val_mae: 0.0363 - val_mse: 0.0415 - 2s/epoch - 54ms/step\n",
            "Epoch 123/500\n",
            "35/35 - 2s - loss: 0.0023 - mae: 0.0263 - mse: 0.0069 - val_loss: 0.0121 - val_mae: 0.0363 - val_mse: 0.0415 - 2s/epoch - 52ms/step\n",
            "Epoch 124/500\n",
            "35/35 - 2s - loss: 0.0023 - mae: 0.0263 - mse: 0.0069 - val_loss: 0.0121 - val_mae: 0.0363 - val_mse: 0.0415 - 2s/epoch - 48ms/step\n",
            "Epoch 125/500\n",
            "35/35 - 2s - loss: 0.0023 - mae: 0.0263 - mse: 0.0069 - val_loss: 0.0121 - val_mae: 0.0363 - val_mse: 0.0415 - 2s/epoch - 52ms/step\n",
            "Epoch 126/500\n",
            "35/35 - 3s - loss: 0.0023 - mae: 0.0263 - mse: 0.0069 - val_loss: 0.0121 - val_mae: 0.0363 - val_mse: 0.0415 - 3s/epoch - 80ms/step\n",
            "Epoch 127/500\n",
            "35/35 - 3s - loss: 0.0023 - mae: 0.0263 - mse: 0.0069 - val_loss: 0.0121 - val_mae: 0.0363 - val_mse: 0.0415 - 3s/epoch - 93ms/step\n",
            "Epoch 128/500\n",
            "35/35 - 2s - loss: 0.0023 - mae: 0.0263 - mse: 0.0069 - val_loss: 0.0121 - val_mae: 0.0363 - val_mse: 0.0415 - 2s/epoch - 55ms/step\n",
            "Epoch 129/500\n",
            "35/35 - 2s - loss: 0.0023 - mae: 0.0263 - mse: 0.0069 - val_loss: 0.0121 - val_mae: 0.0363 - val_mse: 0.0415 - 2s/epoch - 47ms/step\n",
            "Epoch 130/500\n",
            "35/35 - 2s - loss: 0.0023 - mae: 0.0263 - mse: 0.0069 - val_loss: 0.0121 - val_mae: 0.0363 - val_mse: 0.0415 - 2s/epoch - 52ms/step\n",
            "Epoch 131/500\n",
            "35/35 - 2s - loss: 0.0023 - mae: 0.0263 - mse: 0.0069 - val_loss: 0.0121 - val_mae: 0.0363 - val_mse: 0.0415 - 2s/epoch - 48ms/step\n",
            "Epoch 132/500\n",
            "35/35 - 3s - loss: 0.0023 - mae: 0.0263 - mse: 0.0069 - val_loss: 0.0121 - val_mae: 0.0363 - val_mse: 0.0415 - 3s/epoch - 87ms/step\n",
            "Epoch 133/500\n",
            "35/35 - 3s - loss: 0.0023 - mae: 0.0263 - mse: 0.0069 - val_loss: 0.0121 - val_mae: 0.0363 - val_mse: 0.0415 - 3s/epoch - 85ms/step\n",
            "Epoch 134/500\n",
            "35/35 - 2s - loss: 0.0023 - mae: 0.0263 - mse: 0.0069 - val_loss: 0.0121 - val_mae: 0.0363 - val_mse: 0.0415 - 2s/epoch - 49ms/step\n",
            "Epoch 135/500\n",
            "35/35 - 2s - loss: 0.0023 - mae: 0.0263 - mse: 0.0069 - val_loss: 0.0121 - val_mae: 0.0363 - val_mse: 0.0415 - 2s/epoch - 48ms/step\n",
            "Epoch 136/500\n",
            "35/35 - 2s - loss: 0.0023 - mae: 0.0263 - mse: 0.0069 - val_loss: 0.0121 - val_mae: 0.0363 - val_mse: 0.0415 - 2s/epoch - 49ms/step\n",
            "Epoch 137/500\n",
            "35/35 - 2s - loss: 0.0023 - mae: 0.0263 - mse: 0.0069 - val_loss: 0.0121 - val_mae: 0.0363 - val_mse: 0.0415 - 2s/epoch - 53ms/step\n",
            "Epoch 138/500\n",
            "35/35 - 3s - loss: 0.0023 - mae: 0.0263 - mse: 0.0069 - val_loss: 0.0121 - val_mae: 0.0363 - val_mse: 0.0415 - 3s/epoch - 83ms/step\n",
            "Epoch 139/500\n",
            "35/35 - 2s - loss: 0.0023 - mae: 0.0263 - mse: 0.0069 - val_loss: 0.0121 - val_mae: 0.0363 - val_mse: 0.0414 - 2s/epoch - 49ms/step\n",
            "Epoch 140/500\n",
            "35/35 - 2s - loss: 0.0023 - mae: 0.0262 - mse: 0.0069 - val_loss: 0.0121 - val_mae: 0.0363 - val_mse: 0.0414 - 2s/epoch - 52ms/step\n",
            "Epoch 141/500\n",
            "35/35 - 2s - loss: 0.0023 - mae: 0.0262 - mse: 0.0069 - val_loss: 0.0121 - val_mae: 0.0363 - val_mse: 0.0414 - 2s/epoch - 47ms/step\n",
            "Epoch 142/500\n",
            "35/35 - 2s - loss: 0.0023 - mae: 0.0262 - mse: 0.0069 - val_loss: 0.0121 - val_mae: 0.0362 - val_mse: 0.0414 - 2s/epoch - 52ms/step\n",
            "Epoch 143/500\n",
            "35/35 - 2s - loss: 0.0023 - mae: 0.0262 - mse: 0.0069 - val_loss: 0.0121 - val_mae: 0.0362 - val_mse: 0.0414 - 2s/epoch - 48ms/step\n",
            "Epoch 144/500\n",
            "35/35 - 4s - loss: 0.0023 - mae: 0.0262 - mse: 0.0069 - val_loss: 0.0121 - val_mae: 0.0362 - val_mse: 0.0414 - 4s/epoch - 104ms/step\n",
            "Epoch 145/500\n",
            "35/35 - 2s - loss: 0.0023 - mae: 0.0262 - mse: 0.0069 - val_loss: 0.0121 - val_mae: 0.0362 - val_mse: 0.0414 - 2s/epoch - 54ms/step\n",
            "Epoch 146/500\n",
            "35/35 - 2s - loss: 0.0023 - mae: 0.0262 - mse: 0.0068 - val_loss: 0.0121 - val_mae: 0.0362 - val_mse: 0.0414 - 2s/epoch - 54ms/step\n",
            "Epoch 147/500\n",
            "35/35 - 2s - loss: 0.0023 - mae: 0.0262 - mse: 0.0068 - val_loss: 0.0121 - val_mae: 0.0362 - val_mse: 0.0414 - 2s/epoch - 53ms/step\n",
            "Epoch 148/500\n",
            "35/35 - 2s - loss: 0.0023 - mae: 0.0262 - mse: 0.0068 - val_loss: 0.0121 - val_mae: 0.0362 - val_mse: 0.0414 - 2s/epoch - 53ms/step\n",
            "Epoch 149/500\n",
            "35/35 - 4s - loss: 0.0023 - mae: 0.0262 - mse: 0.0068 - val_loss: 0.0121 - val_mae: 0.0362 - val_mse: 0.0414 - 4s/epoch - 102ms/step\n",
            "Epoch 150/500\n",
            "35/35 - 2s - loss: 0.0023 - mae: 0.0262 - mse: 0.0068 - val_loss: 0.0121 - val_mae: 0.0362 - val_mse: 0.0414 - 2s/epoch - 52ms/step\n",
            "Epoch 151/500\n",
            "35/35 - 2s - loss: 0.0023 - mae: 0.0262 - mse: 0.0068 - val_loss: 0.0121 - val_mae: 0.0362 - val_mse: 0.0414 - 2s/epoch - 51ms/step\n",
            "Epoch 152/500\n",
            "35/35 - 2s - loss: 0.0023 - mae: 0.0262 - mse: 0.0068 - val_loss: 0.0121 - val_mae: 0.0362 - val_mse: 0.0414 - 2s/epoch - 54ms/step\n",
            "Epoch 153/500\n",
            "35/35 - 2s - loss: 0.0023 - mae: 0.0262 - mse: 0.0068 - val_loss: 0.0121 - val_mae: 0.0362 - val_mse: 0.0414 - 2s/epoch - 48ms/step\n",
            "Epoch 154/500\n",
            "35/35 - 2s - loss: 0.0023 - mae: 0.0262 - mse: 0.0068 - val_loss: 0.0121 - val_mae: 0.0362 - val_mse: 0.0414 - 2s/epoch - 47ms/step\n",
            "Epoch 155/500\n",
            "35/35 - 3s - loss: 0.0023 - mae: 0.0262 - mse: 0.0068 - val_loss: 0.0121 - val_mae: 0.0362 - val_mse: 0.0414 - 3s/epoch - 91ms/step\n",
            "Epoch 156/500\n",
            "35/35 - 2s - loss: 0.0023 - mae: 0.0262 - mse: 0.0068 - val_loss: 0.0121 - val_mae: 0.0362 - val_mse: 0.0414 - 2s/epoch - 52ms/step\n",
            "Epoch 157/500\n",
            "35/35 - 2s - loss: 0.0023 - mae: 0.0262 - mse: 0.0068 - val_loss: 0.0121 - val_mae: 0.0362 - val_mse: 0.0414 - 2s/epoch - 54ms/step\n",
            "Epoch 158/500\n",
            "35/35 - 2s - loss: 0.0023 - mae: 0.0262 - mse: 0.0068 - val_loss: 0.0121 - val_mae: 0.0362 - val_mse: 0.0414 - 2s/epoch - 51ms/step\n",
            "Epoch 159/500\n",
            "35/35 - 2s - loss: 0.0023 - mae: 0.0262 - mse: 0.0068 - val_loss: 0.0121 - val_mae: 0.0362 - val_mse: 0.0414 - 2s/epoch - 47ms/step\n",
            "Epoch 160/500\n",
            "35/35 - 2s - loss: 0.0023 - mae: 0.0262 - mse: 0.0068 - val_loss: 0.0121 - val_mae: 0.0362 - val_mse: 0.0414 - 2s/epoch - 71ms/step\n",
            "Epoch 161/500\n",
            "35/35 - 4s - loss: 0.0023 - mae: 0.0262 - mse: 0.0068 - val_loss: 0.0121 - val_mae: 0.0362 - val_mse: 0.0414 - 4s/epoch - 108ms/step\n",
            "Epoch 162/500\n",
            "35/35 - 2s - loss: 0.0023 - mae: 0.0262 - mse: 0.0068 - val_loss: 0.0121 - val_mae: 0.0362 - val_mse: 0.0414 - 2s/epoch - 50ms/step\n",
            "Epoch 163/500\n",
            "35/35 - 2s - loss: 0.0023 - mae: 0.0262 - mse: 0.0068 - val_loss: 0.0121 - val_mae: 0.0362 - val_mse: 0.0414 - 2s/epoch - 55ms/step\n",
            "Epoch 164/500\n",
            "35/35 - 2s - loss: 0.0023 - mae: 0.0261 - mse: 0.0068 - val_loss: 0.0121 - val_mae: 0.0362 - val_mse: 0.0414 - 2s/epoch - 50ms/step\n",
            "Epoch 165/500\n",
            "35/35 - 2s - loss: 0.0023 - mae: 0.0261 - mse: 0.0068 - val_loss: 0.0121 - val_mae: 0.0361 - val_mse: 0.0414 - 2s/epoch - 66ms/step\n",
            "Epoch 166/500\n",
            "35/35 - 4s - loss: 0.0023 - mae: 0.0261 - mse: 0.0068 - val_loss: 0.0121 - val_mae: 0.0361 - val_mse: 0.0414 - 4s/epoch - 104ms/step\n",
            "Epoch 167/500\n",
            "35/35 - 2s - loss: 0.0023 - mae: 0.0261 - mse: 0.0068 - val_loss: 0.0121 - val_mae: 0.0361 - val_mse: 0.0414 - 2s/epoch - 52ms/step\n",
            "Epoch 168/500\n",
            "35/35 - 2s - loss: 0.0023 - mae: 0.0261 - mse: 0.0068 - val_loss: 0.0121 - val_mae: 0.0361 - val_mse: 0.0414 - 2s/epoch - 53ms/step\n",
            "Epoch 169/500\n",
            "35/35 - 2s - loss: 0.0023 - mae: 0.0261 - mse: 0.0068 - val_loss: 0.0121 - val_mae: 0.0361 - val_mse: 0.0414 - 2s/epoch - 51ms/step\n",
            "Epoch 170/500\n",
            "35/35 - 3s - loss: 0.0023 - mae: 0.0261 - mse: 0.0068 - val_loss: 0.0121 - val_mae: 0.0361 - val_mse: 0.0414 - 3s/epoch - 73ms/step\n",
            "Epoch 171/500\n",
            "35/35 - 2s - loss: 0.0023 - mae: 0.0261 - mse: 0.0068 - val_loss: 0.0121 - val_mae: 0.0361 - val_mse: 0.0414 - 2s/epoch - 48ms/step\n",
            "Epoch 172/500\n",
            "35/35 - 2s - loss: 0.0023 - mae: 0.0261 - mse: 0.0068 - val_loss: 0.0121 - val_mae: 0.0361 - val_mse: 0.0414 - 2s/epoch - 53ms/step\n",
            "Epoch 173/500\n",
            "35/35 - 2s - loss: 0.0023 - mae: 0.0261 - mse: 0.0068 - val_loss: 0.0121 - val_mae: 0.0361 - val_mse: 0.0414 - 2s/epoch - 49ms/step\n",
            "Epoch 174/500\n",
            "35/35 - 2s - loss: 0.0023 - mae: 0.0261 - mse: 0.0068 - val_loss: 0.0121 - val_mae: 0.0361 - val_mse: 0.0414 - 2s/epoch - 53ms/step\n",
            "Epoch 175/500\n",
            "35/35 - 2s - loss: 0.0023 - mae: 0.0261 - mse: 0.0068 - val_loss: 0.0121 - val_mae: 0.0361 - val_mse: 0.0414 - 2s/epoch - 51ms/step\n",
            "Epoch 176/500\n",
            "35/35 - 4s - loss: 0.0023 - mae: 0.0261 - mse: 0.0068 - val_loss: 0.0121 - val_mae: 0.0361 - val_mse: 0.0414 - 4s/epoch - 104ms/step\n",
            "Epoch 177/500\n",
            "35/35 - 2s - loss: 0.0023 - mae: 0.0261 - mse: 0.0068 - val_loss: 0.0121 - val_mae: 0.0361 - val_mse: 0.0414 - 2s/epoch - 49ms/step\n",
            "Epoch 178/500\n",
            "35/35 - 2s - loss: 0.0023 - mae: 0.0261 - mse: 0.0068 - val_loss: 0.0121 - val_mae: 0.0361 - val_mse: 0.0414 - 2s/epoch - 52ms/step\n",
            "Epoch 179/500\n",
            "35/35 - 2s - loss: 0.0023 - mae: 0.0261 - mse: 0.0068 - val_loss: 0.0121 - val_mae: 0.0361 - val_mse: 0.0414 - 2s/epoch - 50ms/step\n",
            "Epoch 180/500\n",
            "35/35 - 2s - loss: 0.0023 - mae: 0.0261 - mse: 0.0068 - val_loss: 0.0121 - val_mae: 0.0361 - val_mse: 0.0414 - 2s/epoch - 52ms/step\n",
            "Epoch 181/500\n",
            "35/35 - 3s - loss: 0.0023 - mae: 0.0261 - mse: 0.0068 - val_loss: 0.0121 - val_mae: 0.0361 - val_mse: 0.0414 - 3s/epoch - 84ms/step\n",
            "Epoch 182/500\n",
            "35/35 - 3s - loss: 0.0023 - mae: 0.0261 - mse: 0.0068 - val_loss: 0.0121 - val_mae: 0.0361 - val_mse: 0.0414 - 3s/epoch - 88ms/step\n",
            "Epoch 183/500\n",
            "35/35 - 2s - loss: 0.0023 - mae: 0.0261 - mse: 0.0068 - val_loss: 0.0121 - val_mae: 0.0361 - val_mse: 0.0414 - 2s/epoch - 53ms/step\n",
            "Epoch 184/500\n",
            "35/35 - 2s - loss: 0.0023 - mae: 0.0261 - mse: 0.0068 - val_loss: 0.0121 - val_mae: 0.0361 - val_mse: 0.0414 - 2s/epoch - 59ms/step\n",
            "Epoch 185/500\n",
            "35/35 - 2s - loss: 0.0023 - mae: 0.0261 - mse: 0.0068 - val_loss: 0.0121 - val_mae: 0.0361 - val_mse: 0.0414 - 2s/epoch - 52ms/step\n",
            "Epoch 186/500\n",
            "35/35 - 3s - loss: 0.0023 - mae: 0.0261 - mse: 0.0068 - val_loss: 0.0121 - val_mae: 0.0361 - val_mse: 0.0414 - 3s/epoch - 88ms/step\n",
            "Epoch 187/500\n",
            "35/35 - 3s - loss: 0.0023 - mae: 0.0261 - mse: 0.0068 - val_loss: 0.0121 - val_mae: 0.0361 - val_mse: 0.0414 - 3s/epoch - 88ms/step\n",
            "Epoch 188/500\n",
            "35/35 - 2s - loss: 0.0023 - mae: 0.0260 - mse: 0.0068 - val_loss: 0.0121 - val_mae: 0.0361 - val_mse: 0.0414 - 2s/epoch - 53ms/step\n",
            "Epoch 189/500\n",
            "35/35 - 2s - loss: 0.0023 - mae: 0.0260 - mse: 0.0068 - val_loss: 0.0121 - val_mae: 0.0360 - val_mse: 0.0414 - 2s/epoch - 52ms/step\n",
            "Epoch 190/500\n",
            "35/35 - 2s - loss: 0.0023 - mae: 0.0260 - mse: 0.0068 - val_loss: 0.0121 - val_mae: 0.0360 - val_mse: 0.0414 - 2s/epoch - 56ms/step\n",
            "Epoch 191/500\n",
            "35/35 - 2s - loss: 0.0023 - mae: 0.0260 - mse: 0.0068 - val_loss: 0.0121 - val_mae: 0.0360 - val_mse: 0.0414 - 2s/epoch - 48ms/step\n",
            "Epoch 192/500\n",
            "35/35 - 2s - loss: 0.0023 - mae: 0.0260 - mse: 0.0068 - val_loss: 0.0121 - val_mae: 0.0360 - val_mse: 0.0414 - 2s/epoch - 60ms/step\n",
            "Epoch 193/500\n",
            "35/35 - 4s - loss: 0.0023 - mae: 0.0260 - mse: 0.0068 - val_loss: 0.0121 - val_mae: 0.0360 - val_mse: 0.0414 - 4s/epoch - 106ms/step\n",
            "Epoch 194/500\n",
            "35/35 - 2s - loss: 0.0023 - mae: 0.0260 - mse: 0.0068 - val_loss: 0.0121 - val_mae: 0.0360 - val_mse: 0.0414 - 2s/epoch - 52ms/step\n",
            "Epoch 195/500\n",
            "35/35 - 2s - loss: 0.0023 - mae: 0.0260 - mse: 0.0068 - val_loss: 0.0121 - val_mae: 0.0360 - val_mse: 0.0414 - 2s/epoch - 51ms/step\n",
            "Epoch 196/500\n",
            "35/35 - 2s - loss: 0.0023 - mae: 0.0260 - mse: 0.0068 - val_loss: 0.0121 - val_mae: 0.0360 - val_mse: 0.0414 - 2s/epoch - 50ms/step\n",
            "Epoch 197/500\n",
            "35/35 - 2s - loss: 0.0023 - mae: 0.0260 - mse: 0.0068 - val_loss: 0.0121 - val_mae: 0.0360 - val_mse: 0.0414 - 2s/epoch - 49ms/step\n",
            "Epoch 198/500\n",
            "35/35 - 3s - loss: 0.0023 - mae: 0.0260 - mse: 0.0068 - val_loss: 0.0121 - val_mae: 0.0360 - val_mse: 0.0414 - 3s/epoch - 95ms/step\n",
            "Epoch 199/500\n",
            "35/35 - 2s - loss: 0.0023 - mae: 0.0260 - mse: 0.0068 - val_loss: 0.0121 - val_mae: 0.0360 - val_mse: 0.0414 - 2s/epoch - 47ms/step\n",
            "Epoch 200/500\n",
            "35/35 - 2s - loss: 0.0023 - mae: 0.0260 - mse: 0.0068 - val_loss: 0.0121 - val_mae: 0.0360 - val_mse: 0.0414 - 2s/epoch - 55ms/step\n",
            "Epoch 201/500\n",
            "35/35 - 2s - loss: 0.0023 - mae: 0.0260 - mse: 0.0068 - val_loss: 0.0121 - val_mae: 0.0360 - val_mse: 0.0414 - 2s/epoch - 49ms/step\n",
            "Epoch 202/500\n",
            "35/35 - 2s - loss: 0.0023 - mae: 0.0260 - mse: 0.0068 - val_loss: 0.0121 - val_mae: 0.0360 - val_mse: 0.0414 - 2s/epoch - 50ms/step\n",
            "Epoch 203/500\n",
            "35/35 - 3s - loss: 0.0023 - mae: 0.0260 - mse: 0.0068 - val_loss: 0.0121 - val_mae: 0.0360 - val_mse: 0.0414 - 3s/epoch - 94ms/step\n",
            "Epoch 204/500\n",
            "35/35 - 2s - loss: 0.0023 - mae: 0.0260 - mse: 0.0068 - val_loss: 0.0121 - val_mae: 0.0360 - val_mse: 0.0414 - 2s/epoch - 54ms/step\n",
            "Epoch 205/500\n",
            "35/35 - 2s - loss: 0.0023 - mae: 0.0260 - mse: 0.0068 - val_loss: 0.0121 - val_mae: 0.0360 - val_mse: 0.0414 - 2s/epoch - 53ms/step\n",
            "Epoch 206/500\n",
            "35/35 - 2s - loss: 0.0023 - mae: 0.0260 - mse: 0.0068 - val_loss: 0.0121 - val_mae: 0.0360 - val_mse: 0.0414 - 2s/epoch - 52ms/step\n",
            "Epoch 207/500\n",
            "35/35 - 2s - loss: 0.0023 - mae: 0.0260 - mse: 0.0068 - val_loss: 0.0121 - val_mae: 0.0360 - val_mse: 0.0414 - 2s/epoch - 53ms/step\n",
            "Epoch 208/500\n",
            "35/35 - 3s - loss: 0.0023 - mae: 0.0260 - mse: 0.0068 - val_loss: 0.0121 - val_mae: 0.0360 - val_mse: 0.0414 - 3s/epoch - 91ms/step\n",
            "Epoch 209/500\n",
            "35/35 - 2s - loss: 0.0023 - mae: 0.0260 - mse: 0.0068 - val_loss: 0.0121 - val_mae: 0.0360 - val_mse: 0.0414 - 2s/epoch - 52ms/step\n",
            "Epoch 210/500\n",
            "35/35 - 2s - loss: 0.0023 - mae: 0.0260 - mse: 0.0068 - val_loss: 0.0121 - val_mae: 0.0360 - val_mse: 0.0414 - 2s/epoch - 48ms/step\n",
            "Epoch 211/500\n",
            "35/35 - 2s - loss: 0.0023 - mae: 0.0260 - mse: 0.0068 - val_loss: 0.0121 - val_mae: 0.0360 - val_mse: 0.0414 - 2s/epoch - 52ms/step\n",
            "Epoch 212/500\n",
            "35/35 - 2s - loss: 0.0023 - mae: 0.0259 - mse: 0.0068 - val_loss: 0.0121 - val_mae: 0.0360 - val_mse: 0.0414 - 2s/epoch - 54ms/step\n",
            "Epoch 213/500\n",
            "35/35 - 3s - loss: 0.0023 - mae: 0.0259 - mse: 0.0068 - val_loss: 0.0121 - val_mae: 0.0359 - val_mse: 0.0414 - 3s/epoch - 80ms/step\n",
            "Epoch 214/500\n",
            "35/35 - 3s - loss: 0.0023 - mae: 0.0259 - mse: 0.0068 - val_loss: 0.0121 - val_mae: 0.0359 - val_mse: 0.0414 - 3s/epoch - 96ms/step\n",
            "Epoch 215/500\n",
            "35/35 - 2s - loss: 0.0023 - mae: 0.0259 - mse: 0.0068 - val_loss: 0.0121 - val_mae: 0.0359 - val_mse: 0.0414 - 2s/epoch - 52ms/step\n",
            "Epoch 216/500\n",
            "35/35 - 2s - loss: 0.0023 - mae: 0.0259 - mse: 0.0068 - val_loss: 0.0121 - val_mae: 0.0359 - val_mse: 0.0414 - 2s/epoch - 53ms/step\n",
            "Epoch 217/500\n",
            "35/35 - 2s - loss: 0.0023 - mae: 0.0259 - mse: 0.0068 - val_loss: 0.0121 - val_mae: 0.0359 - val_mse: 0.0414 - 2s/epoch - 49ms/step\n",
            "Epoch 218/500\n",
            "35/35 - 2s - loss: 0.0023 - mae: 0.0259 - mse: 0.0068 - val_loss: 0.0121 - val_mae: 0.0359 - val_mse: 0.0414 - 2s/epoch - 50ms/step\n",
            "Epoch 219/500\n",
            "35/35 - 2s - loss: 0.0023 - mae: 0.0259 - mse: 0.0068 - val_loss: 0.0121 - val_mae: 0.0359 - val_mse: 0.0414 - 2s/epoch - 49ms/step\n",
            "Epoch 220/500\n",
            "35/35 - 4s - loss: 0.0023 - mae: 0.0259 - mse: 0.0068 - val_loss: 0.0121 - val_mae: 0.0359 - val_mse: 0.0414 - 4s/epoch - 103ms/step\n",
            "Epoch 221/500\n",
            "35/35 - 2s - loss: 0.0023 - mae: 0.0259 - mse: 0.0068 - val_loss: 0.0121 - val_mae: 0.0359 - val_mse: 0.0413 - 2s/epoch - 48ms/step\n",
            "Epoch 222/500\n",
            "35/35 - 2s - loss: 0.0023 - mae: 0.0259 - mse: 0.0068 - val_loss: 0.0121 - val_mae: 0.0359 - val_mse: 0.0413 - 2s/epoch - 52ms/step\n",
            "Epoch 223/500\n",
            "35/35 - 2s - loss: 0.0023 - mae: 0.0259 - mse: 0.0068 - val_loss: 0.0121 - val_mae: 0.0359 - val_mse: 0.0413 - 2s/epoch - 48ms/step\n",
            "Epoch 224/500\n",
            "35/35 - 2s - loss: 0.0023 - mae: 0.0259 - mse: 0.0068 - val_loss: 0.0121 - val_mae: 0.0359 - val_mse: 0.0413 - 2s/epoch - 54ms/step\n",
            "Epoch 225/500\n",
            "35/35 - 3s - loss: 0.0023 - mae: 0.0259 - mse: 0.0068 - val_loss: 0.0121 - val_mae: 0.0359 - val_mse: 0.0413 - 3s/epoch - 96ms/step\n",
            "Epoch 226/500\n",
            "35/35 - 3s - loss: 0.0023 - mae: 0.0259 - mse: 0.0068 - val_loss: 0.0121 - val_mae: 0.0359 - val_mse: 0.0413 - 3s/epoch - 75ms/step\n",
            "Epoch 227/500\n",
            "35/35 - 2s - loss: 0.0023 - mae: 0.0259 - mse: 0.0068 - val_loss: 0.0121 - val_mae: 0.0359 - val_mse: 0.0413 - 2s/epoch - 51ms/step\n",
            "Epoch 228/500\n",
            "35/35 - 2s - loss: 0.0023 - mae: 0.0259 - mse: 0.0068 - val_loss: 0.0121 - val_mae: 0.0359 - val_mse: 0.0413 - 2s/epoch - 52ms/step\n",
            "Epoch 229/500\n",
            "35/35 - 2s - loss: 0.0023 - mae: 0.0259 - mse: 0.0068 - val_loss: 0.0121 - val_mae: 0.0359 - val_mse: 0.0413 - 2s/epoch - 53ms/step\n",
            "Epoch 230/500\n",
            "35/35 - 3s - loss: 0.0023 - mae: 0.0259 - mse: 0.0068 - val_loss: 0.0121 - val_mae: 0.0359 - val_mse: 0.0413 - 3s/epoch - 91ms/step\n",
            "Epoch 231/500\n",
            "35/35 - 2s - loss: 0.0023 - mae: 0.0259 - mse: 0.0068 - val_loss: 0.0121 - val_mae: 0.0359 - val_mse: 0.0413 - 2s/epoch - 52ms/step\n",
            "Epoch 232/500\n",
            "35/35 - 2s - loss: 0.0023 - mae: 0.0259 - mse: 0.0068 - val_loss: 0.0121 - val_mae: 0.0359 - val_mse: 0.0413 - 2s/epoch - 54ms/step\n",
            "Epoch 233/500\n",
            "35/35 - 2s - loss: 0.0023 - mae: 0.0259 - mse: 0.0068 - val_loss: 0.0121 - val_mae: 0.0359 - val_mse: 0.0413 - 2s/epoch - 53ms/step\n",
            "Epoch 234/500\n",
            "35/35 - 2s - loss: 0.0023 - mae: 0.0259 - mse: 0.0068 - val_loss: 0.0121 - val_mae: 0.0359 - val_mse: 0.0413 - 2s/epoch - 52ms/step\n",
            "Epoch 235/500\n",
            "35/35 - 3s - loss: 0.0023 - mae: 0.0259 - mse: 0.0068 - val_loss: 0.0121 - val_mae: 0.0359 - val_mse: 0.0413 - 3s/epoch - 95ms/step\n",
            "Epoch 236/500\n",
            "35/35 - 3s - loss: 0.0023 - mae: 0.0259 - mse: 0.0068 - val_loss: 0.0121 - val_mae: 0.0359 - val_mse: 0.0413 - 3s/epoch - 82ms/step\n",
            "Epoch 237/500\n",
            "35/35 - 2s - loss: 0.0023 - mae: 0.0258 - mse: 0.0068 - val_loss: 0.0121 - val_mae: 0.0359 - val_mse: 0.0413 - 2s/epoch - 55ms/step\n",
            "Epoch 238/500\n",
            "35/35 - 2s - loss: 0.0023 - mae: 0.0258 - mse: 0.0068 - val_loss: 0.0121 - val_mae: 0.0358 - val_mse: 0.0413 - 2s/epoch - 49ms/step\n",
            "Epoch 239/500\n",
            "35/35 - 2s - loss: 0.0023 - mae: 0.0258 - mse: 0.0068 - val_loss: 0.0121 - val_mae: 0.0358 - val_mse: 0.0413 - 2s/epoch - 51ms/step\n",
            "Epoch 240/500\n",
            "35/35 - 3s - loss: 0.0023 - mae: 0.0258 - mse: 0.0068 - val_loss: 0.0121 - val_mae: 0.0358 - val_mse: 0.0413 - 3s/epoch - 83ms/step\n",
            "Epoch 241/500\n",
            "35/35 - 3s - loss: 0.0023 - mae: 0.0258 - mse: 0.0068 - val_loss: 0.0121 - val_mae: 0.0358 - val_mse: 0.0413 - 3s/epoch - 96ms/step\n",
            "Epoch 242/500\n",
            "35/35 - 2s - loss: 0.0023 - mae: 0.0258 - mse: 0.0068 - val_loss: 0.0121 - val_mae: 0.0358 - val_mse: 0.0413 - 2s/epoch - 51ms/step\n",
            "Epoch 243/500\n",
            "35/35 - 2s - loss: 0.0023 - mae: 0.0258 - mse: 0.0068 - val_loss: 0.0121 - val_mae: 0.0358 - val_mse: 0.0413 - 2s/epoch - 53ms/step\n",
            "Epoch 244/500\n",
            "35/35 - 2s - loss: 0.0023 - mae: 0.0258 - mse: 0.0068 - val_loss: 0.0121 - val_mae: 0.0358 - val_mse: 0.0413 - 2s/epoch - 51ms/step\n",
            "Epoch 245/500\n",
            "35/35 - 4s - loss: 0.0023 - mae: 0.0258 - mse: 0.0068 - val_loss: 0.0121 - val_mae: 0.0358 - val_mse: 0.0413 - 4s/epoch - 101ms/step\n",
            "Epoch 246/500\n",
            "35/35 - 2s - loss: 0.0023 - mae: 0.0258 - mse: 0.0068 - val_loss: 0.0121 - val_mae: 0.0358 - val_mse: 0.0413 - 2s/epoch - 49ms/step\n",
            "Epoch 247/500\n",
            "35/35 - 2s - loss: 0.0023 - mae: 0.0258 - mse: 0.0068 - val_loss: 0.0121 - val_mae: 0.0358 - val_mse: 0.0413 - 2s/epoch - 51ms/step\n",
            "Epoch 248/500\n",
            "35/35 - 2s - loss: 0.0023 - mae: 0.0258 - mse: 0.0068 - val_loss: 0.0121 - val_mae: 0.0358 - val_mse: 0.0413 - 2s/epoch - 52ms/step\n",
            "Epoch 249/500\n",
            "35/35 - 2s - loss: 0.0023 - mae: 0.0258 - mse: 0.0068 - val_loss: 0.0121 - val_mae: 0.0358 - val_mse: 0.0413 - 2s/epoch - 49ms/step\n",
            "Epoch 250/500\n",
            "35/35 - 2s - loss: 0.0023 - mae: 0.0258 - mse: 0.0068 - val_loss: 0.0121 - val_mae: 0.0358 - val_mse: 0.0413 - 2s/epoch - 52ms/step\n",
            "Epoch 251/500\n",
            "35/35 - 3s - loss: 0.0023 - mae: 0.0258 - mse: 0.0068 - val_loss: 0.0121 - val_mae: 0.0358 - val_mse: 0.0413 - 3s/epoch - 98ms/step\n",
            "Epoch 252/500\n",
            "35/35 - 2s - loss: 0.0023 - mae: 0.0258 - mse: 0.0068 - val_loss: 0.0121 - val_mae: 0.0358 - val_mse: 0.0413 - 2s/epoch - 55ms/step\n",
            "Epoch 253/500\n",
            "35/35 - 2s - loss: 0.0023 - mae: 0.0258 - mse: 0.0068 - val_loss: 0.0121 - val_mae: 0.0358 - val_mse: 0.0413 - 2s/epoch - 53ms/step\n",
            "Epoch 254/500\n",
            "35/35 - 2s - loss: 0.0023 - mae: 0.0258 - mse: 0.0068 - val_loss: 0.0121 - val_mae: 0.0358 - val_mse: 0.0413 - 2s/epoch - 49ms/step\n",
            "Epoch 255/500\n",
            "35/35 - 2s - loss: 0.0023 - mae: 0.0258 - mse: 0.0068 - val_loss: 0.0121 - val_mae: 0.0358 - val_mse: 0.0413 - 2s/epoch - 49ms/step\n",
            "Epoch 256/500\n",
            "35/35 - 3s - loss: 0.0023 - mae: 0.0258 - mse: 0.0068 - val_loss: 0.0121 - val_mae: 0.0358 - val_mse: 0.0413 - 3s/epoch - 90ms/step\n",
            "Epoch 257/500\n",
            "35/35 - 2s - loss: 0.0023 - mae: 0.0258 - mse: 0.0068 - val_loss: 0.0121 - val_mae: 0.0358 - val_mse: 0.0413 - 2s/epoch - 48ms/step\n",
            "Epoch 258/500\n",
            "35/35 - 2s - loss: 0.0023 - mae: 0.0258 - mse: 0.0068 - val_loss: 0.0121 - val_mae: 0.0358 - val_mse: 0.0413 - 2s/epoch - 51ms/step\n",
            "Epoch 259/500\n",
            "35/35 - 2s - loss: 0.0023 - mae: 0.0258 - mse: 0.0068 - val_loss: 0.0121 - val_mae: 0.0358 - val_mse: 0.0413 - 2s/epoch - 51ms/step\n",
            "Epoch 260/500\n",
            "35/35 - 2s - loss: 0.0023 - mae: 0.0258 - mse: 0.0068 - val_loss: 0.0121 - val_mae: 0.0358 - val_mse: 0.0413 - 2s/epoch - 53ms/step\n",
            "Epoch 261/500\n",
            "35/35 - 4s - loss: 0.0023 - mae: 0.0258 - mse: 0.0068 - val_loss: 0.0121 - val_mae: 0.0358 - val_mse: 0.0413 - 4s/epoch - 102ms/step\n",
            "Epoch 262/500\n",
            "35/35 - 3s - loss: 0.0023 - mae: 0.0257 - mse: 0.0068 - val_loss: 0.0121 - val_mae: 0.0357 - val_mse: 0.0413 - 3s/epoch - 75ms/step\n",
            "Epoch 263/500\n",
            "35/35 - 2s - loss: 0.0023 - mae: 0.0257 - mse: 0.0068 - val_loss: 0.0121 - val_mae: 0.0357 - val_mse: 0.0413 - 2s/epoch - 53ms/step\n",
            "Epoch 264/500\n",
            "35/35 - 2s - loss: 0.0023 - mae: 0.0257 - mse: 0.0068 - val_loss: 0.0121 - val_mae: 0.0357 - val_mse: 0.0413 - 2s/epoch - 48ms/step\n",
            "Epoch 265/500\n",
            "35/35 - 2s - loss: 0.0023 - mae: 0.0257 - mse: 0.0068 - val_loss: 0.0121 - val_mae: 0.0357 - val_mse: 0.0413 - 2s/epoch - 48ms/step\n",
            "Epoch 266/500\n",
            "35/35 - 2s - loss: 0.0023 - mae: 0.0257 - mse: 0.0068 - val_loss: 0.0121 - val_mae: 0.0357 - val_mse: 0.0413 - 2s/epoch - 49ms/step\n",
            "Epoch 267/500\n",
            "35/35 - 3s - loss: 0.0023 - mae: 0.0257 - mse: 0.0068 - val_loss: 0.0121 - val_mae: 0.0357 - val_mse: 0.0413 - 3s/epoch - 89ms/step\n",
            "Epoch 268/500\n",
            "35/35 - 3s - loss: 0.0023 - mae: 0.0257 - mse: 0.0068 - val_loss: 0.0121 - val_mae: 0.0357 - val_mse: 0.0413 - 3s/epoch - 85ms/step\n",
            "Epoch 269/500\n",
            "35/35 - 2s - loss: 0.0023 - mae: 0.0257 - mse: 0.0068 - val_loss: 0.0121 - val_mae: 0.0357 - val_mse: 0.0413 - 2s/epoch - 49ms/step\n",
            "Epoch 270/500\n",
            "35/35 - 2s - loss: 0.0023 - mae: 0.0257 - mse: 0.0068 - val_loss: 0.0121 - val_mae: 0.0357 - val_mse: 0.0413 - 2s/epoch - 52ms/step\n",
            "Epoch 271/500\n",
            "35/35 - 2s - loss: 0.0023 - mae: 0.0257 - mse: 0.0068 - val_loss: 0.0121 - val_mae: 0.0357 - val_mse: 0.0413 - 2s/epoch - 48ms/step\n",
            "Epoch 272/500\n",
            "35/35 - 3s - loss: 0.0023 - mae: 0.0257 - mse: 0.0068 - val_loss: 0.0121 - val_mae: 0.0357 - val_mse: 0.0413 - 3s/epoch - 91ms/step\n",
            "Epoch 273/500\n",
            "35/35 - 3s - loss: 0.0023 - mae: 0.0257 - mse: 0.0068 - val_loss: 0.0121 - val_mae: 0.0357 - val_mse: 0.0413 - 3s/epoch - 84ms/step\n",
            "Epoch 274/500\n",
            "35/35 - 2s - loss: 0.0023 - mae: 0.0257 - mse: 0.0068 - val_loss: 0.0121 - val_mae: 0.0357 - val_mse: 0.0413 - 2s/epoch - 48ms/step\n",
            "Epoch 275/500\n",
            "35/35 - 2s - loss: 0.0023 - mae: 0.0257 - mse: 0.0068 - val_loss: 0.0121 - val_mae: 0.0357 - val_mse: 0.0413 - 2s/epoch - 47ms/step\n",
            "Epoch 276/500\n",
            "35/35 - 2s - loss: 0.0023 - mae: 0.0257 - mse: 0.0068 - val_loss: 0.0121 - val_mae: 0.0357 - val_mse: 0.0413 - 2s/epoch - 50ms/step\n",
            "Epoch 277/500\n",
            "35/35 - 2s - loss: 0.0023 - mae: 0.0257 - mse: 0.0068 - val_loss: 0.0121 - val_mae: 0.0357 - val_mse: 0.0413 - 2s/epoch - 52ms/step\n",
            "Epoch 278/500\n",
            "35/35 - 3s - loss: 0.0023 - mae: 0.0257 - mse: 0.0068 - val_loss: 0.0121 - val_mae: 0.0357 - val_mse: 0.0413 - 3s/epoch - 93ms/step\n",
            "Epoch 279/500\n",
            "35/35 - 2s - loss: 0.0023 - mae: 0.0257 - mse: 0.0068 - val_loss: 0.0121 - val_mae: 0.0357 - val_mse: 0.0413 - 2s/epoch - 52ms/step\n",
            "Epoch 280/500\n",
            "35/35 - 2s - loss: 0.0023 - mae: 0.0257 - mse: 0.0068 - val_loss: 0.0121 - val_mae: 0.0357 - val_mse: 0.0413 - 2s/epoch - 55ms/step\n",
            "Epoch 281/500\n",
            "35/35 - 2s - loss: 0.0023 - mae: 0.0257 - mse: 0.0068 - val_loss: 0.0121 - val_mae: 0.0357 - val_mse: 0.0413 - 2s/epoch - 50ms/step\n",
            "Epoch 282/500\n",
            "35/35 - 2s - loss: 0.0023 - mae: 0.0257 - mse: 0.0068 - val_loss: 0.0121 - val_mae: 0.0357 - val_mse: 0.0413 - 2s/epoch - 52ms/step\n",
            "Epoch 283/500\n",
            "35/35 - 4s - loss: 0.0023 - mae: 0.0257 - mse: 0.0068 - val_loss: 0.0121 - val_mae: 0.0357 - val_mse: 0.0413 - 4s/epoch - 104ms/step\n",
            "Epoch 284/500\n",
            "35/35 - 2s - loss: 0.0023 - mae: 0.0257 - mse: 0.0068 - val_loss: 0.0121 - val_mae: 0.0357 - val_mse: 0.0413 - 2s/epoch - 53ms/step\n",
            "Epoch 285/500\n",
            "35/35 - 2s - loss: 0.0023 - mae: 0.0257 - mse: 0.0068 - val_loss: 0.0121 - val_mae: 0.0357 - val_mse: 0.0413 - 2s/epoch - 55ms/step\n",
            "Epoch 286/500\n",
            "35/35 - 2s - loss: 0.0023 - mae: 0.0257 - mse: 0.0068 - val_loss: 0.0121 - val_mae: 0.0357 - val_mse: 0.0413 - 2s/epoch - 52ms/step\n",
            "Epoch 287/500\n",
            "35/35 - 2s - loss: 0.0023 - mae: 0.0256 - mse: 0.0068 - val_loss: 0.0121 - val_mae: 0.0356 - val_mse: 0.0413 - 2s/epoch - 50ms/step\n",
            "Epoch 288/500\n",
            "35/35 - 4s - loss: 0.0023 - mae: 0.0256 - mse: 0.0068 - val_loss: 0.0121 - val_mae: 0.0356 - val_mse: 0.0413 - 4s/epoch - 106ms/step\n",
            "Epoch 289/500\n",
            "35/35 - 2s - loss: 0.0023 - mae: 0.0256 - mse: 0.0068 - val_loss: 0.0121 - val_mae: 0.0356 - val_mse: 0.0413 - 2s/epoch - 48ms/step\n",
            "Epoch 290/500\n",
            "35/35 - 2s - loss: 0.0023 - mae: 0.0256 - mse: 0.0068 - val_loss: 0.0121 - val_mae: 0.0356 - val_mse: 0.0413 - 2s/epoch - 50ms/step\n",
            "Epoch 291/500\n",
            "35/35 - 2s - loss: 0.0023 - mae: 0.0256 - mse: 0.0068 - val_loss: 0.0121 - val_mae: 0.0356 - val_mse: 0.0413 - 2s/epoch - 48ms/step\n",
            "Epoch 292/500\n",
            "35/35 - 2s - loss: 0.0023 - mae: 0.0256 - mse: 0.0068 - val_loss: 0.0121 - val_mae: 0.0356 - val_mse: 0.0413 - 2s/epoch - 52ms/step\n",
            "Epoch 293/500\n",
            "35/35 - 2s - loss: 0.0023 - mae: 0.0256 - mse: 0.0068 - val_loss: 0.0121 - val_mae: 0.0356 - val_mse: 0.0413 - 2s/epoch - 56ms/step\n",
            "Epoch 294/500\n",
            "35/35 - 3s - loss: 0.0023 - mae: 0.0256 - mse: 0.0068 - val_loss: 0.0121 - val_mae: 0.0356 - val_mse: 0.0413 - 3s/epoch - 91ms/step\n",
            "Epoch 295/500\n",
            "35/35 - 2s - loss: 0.0023 - mae: 0.0256 - mse: 0.0068 - val_loss: 0.0121 - val_mae: 0.0356 - val_mse: 0.0413 - 2s/epoch - 54ms/step\n",
            "Epoch 296/500\n",
            "35/35 - 2s - loss: 0.0023 - mae: 0.0256 - mse: 0.0068 - val_loss: 0.0121 - val_mae: 0.0356 - val_mse: 0.0413 - 2s/epoch - 52ms/step\n",
            "Epoch 297/500\n",
            "35/35 - 2s - loss: 0.0023 - mae: 0.0256 - mse: 0.0068 - val_loss: 0.0121 - val_mae: 0.0356 - val_mse: 0.0413 - 2s/epoch - 49ms/step\n",
            "Epoch 298/500\n",
            "35/35 - 2s - loss: 0.0023 - mae: 0.0256 - mse: 0.0068 - val_loss: 0.0121 - val_mae: 0.0356 - val_mse: 0.0413 - 2s/epoch - 52ms/step\n",
            "Epoch 299/500\n",
            "35/35 - 3s - loss: 0.0023 - mae: 0.0256 - mse: 0.0068 - val_loss: 0.0121 - val_mae: 0.0356 - val_mse: 0.0413 - 3s/epoch - 77ms/step\n",
            "Epoch 300/500\n",
            "35/35 - 2s - loss: 0.0023 - mae: 0.0256 - mse: 0.0068 - val_loss: 0.0121 - val_mae: 0.0356 - val_mse: 0.0413 - 2s/epoch - 49ms/step\n",
            "Epoch 301/500\n",
            "35/35 - 2s - loss: 0.0023 - mae: 0.0256 - mse: 0.0068 - val_loss: 0.0121 - val_mae: 0.0356 - val_mse: 0.0413 - 2s/epoch - 49ms/step\n",
            "Epoch 302/500\n",
            "35/35 - 2s - loss: 0.0023 - mae: 0.0256 - mse: 0.0068 - val_loss: 0.0121 - val_mae: 0.0356 - val_mse: 0.0413 - 2s/epoch - 47ms/step\n",
            "Epoch 303/500\n",
            "35/35 - 2s - loss: 0.0023 - mae: 0.0256 - mse: 0.0068 - val_loss: 0.0121 - val_mae: 0.0356 - val_mse: 0.0413 - 2s/epoch - 51ms/step\n",
            "Epoch 304/500\n",
            "35/35 - 2s - loss: 0.0023 - mae: 0.0256 - mse: 0.0068 - val_loss: 0.0121 - val_mae: 0.0356 - val_mse: 0.0413 - 2s/epoch - 52ms/step\n",
            "Epoch 305/500\n",
            "35/35 - 4s - loss: 0.0023 - mae: 0.0256 - mse: 0.0068 - val_loss: 0.0121 - val_mae: 0.0356 - val_mse: 0.0413 - 4s/epoch - 105ms/step\n",
            "Epoch 306/500\n",
            "35/35 - 2s - loss: 0.0023 - mae: 0.0256 - mse: 0.0068 - val_loss: 0.0121 - val_mae: 0.0356 - val_mse: 0.0412 - 2s/epoch - 53ms/step\n",
            "Epoch 307/500\n",
            "35/35 - 2s - loss: 0.0023 - mae: 0.0256 - mse: 0.0068 - val_loss: 0.0121 - val_mae: 0.0356 - val_mse: 0.0412 - 2s/epoch - 51ms/step\n",
            "Epoch 308/500\n",
            "35/35 - 2s - loss: 0.0023 - mae: 0.0256 - mse: 0.0067 - val_loss: 0.0121 - val_mae: 0.0356 - val_mse: 0.0412 - 2s/epoch - 52ms/step\n",
            "Epoch 309/500\n",
            "35/35 - 2s - loss: 0.0023 - mae: 0.0256 - mse: 0.0067 - val_loss: 0.0121 - val_mae: 0.0356 - val_mse: 0.0412 - 2s/epoch - 48ms/step\n",
            "Epoch 310/500\n",
            "35/35 - 4s - loss: 0.0023 - mae: 0.0256 - mse: 0.0067 - val_loss: 0.0121 - val_mae: 0.0356 - val_mse: 0.0412 - 4s/epoch - 105ms/step\n",
            "Epoch 311/500\n",
            "35/35 - 2s - loss: 0.0023 - mae: 0.0256 - mse: 0.0067 - val_loss: 0.0121 - val_mae: 0.0356 - val_mse: 0.0412 - 2s/epoch - 71ms/step\n",
            "Epoch 312/500\n",
            "35/35 - 2s - loss: 0.0023 - mae: 0.0255 - mse: 0.0067 - val_loss: 0.0121 - val_mae: 0.0356 - val_mse: 0.0412 - 2s/epoch - 52ms/step\n",
            "Epoch 313/500\n",
            "35/35 - 2s - loss: 0.0023 - mae: 0.0255 - mse: 0.0067 - val_loss: 0.0121 - val_mae: 0.0355 - val_mse: 0.0412 - 2s/epoch - 52ms/step\n",
            "Epoch 314/500\n",
            "35/35 - 2s - loss: 0.0023 - mae: 0.0255 - mse: 0.0067 - val_loss: 0.0121 - val_mae: 0.0355 - val_mse: 0.0412 - 2s/epoch - 51ms/step\n",
            "Epoch 315/500\n",
            "35/35 - 2s - loss: 0.0023 - mae: 0.0255 - mse: 0.0067 - val_loss: 0.0121 - val_mae: 0.0355 - val_mse: 0.0412 - 2s/epoch - 52ms/step\n",
            "Epoch 316/500\n",
            "35/35 - 3s - loss: 0.0023 - mae: 0.0255 - mse: 0.0067 - val_loss: 0.0121 - val_mae: 0.0355 - val_mse: 0.0412 - 3s/epoch - 90ms/step\n",
            "Epoch 317/500\n",
            "35/35 - 3s - loss: 0.0023 - mae: 0.0255 - mse: 0.0067 - val_loss: 0.0121 - val_mae: 0.0355 - val_mse: 0.0412 - 3s/epoch - 88ms/step\n",
            "Epoch 318/500\n",
            "35/35 - 2s - loss: 0.0023 - mae: 0.0255 - mse: 0.0067 - val_loss: 0.0121 - val_mae: 0.0355 - val_mse: 0.0412 - 2s/epoch - 49ms/step\n",
            "Epoch 319/500\n",
            "35/35 - 2s - loss: 0.0023 - mae: 0.0255 - mse: 0.0067 - val_loss: 0.0121 - val_mae: 0.0355 - val_mse: 0.0412 - 2s/epoch - 51ms/step\n",
            "Epoch 320/500\n",
            "35/35 - 2s - loss: 0.0023 - mae: 0.0255 - mse: 0.0067 - val_loss: 0.0121 - val_mae: 0.0355 - val_mse: 0.0412 - 2s/epoch - 53ms/step\n",
            "Epoch 321/500\n",
            "35/35 - 2s - loss: 0.0023 - mae: 0.0255 - mse: 0.0067 - val_loss: 0.0121 - val_mae: 0.0355 - val_mse: 0.0412 - 2s/epoch - 53ms/step\n",
            "Epoch 322/500\n",
            "35/35 - 3s - loss: 0.0023 - mae: 0.0255 - mse: 0.0067 - val_loss: 0.0121 - val_mae: 0.0355 - val_mse: 0.0412 - 3s/epoch - 88ms/step\n",
            "Epoch 323/500\n",
            "35/35 - 3s - loss: 0.0023 - mae: 0.0255 - mse: 0.0067 - val_loss: 0.0121 - val_mae: 0.0355 - val_mse: 0.0412 - 3s/epoch - 87ms/step\n",
            "Epoch 324/500\n",
            "35/35 - 2s - loss: 0.0023 - mae: 0.0255 - mse: 0.0067 - val_loss: 0.0121 - val_mae: 0.0355 - val_mse: 0.0412 - 2s/epoch - 54ms/step\n",
            "Epoch 325/500\n",
            "35/35 - 2s - loss: 0.0023 - mae: 0.0255 - mse: 0.0067 - val_loss: 0.0121 - val_mae: 0.0355 - val_mse: 0.0412 - 2s/epoch - 52ms/step\n",
            "Epoch 326/500\n",
            "35/35 - 2s - loss: 0.0023 - mae: 0.0255 - mse: 0.0067 - val_loss: 0.0121 - val_mae: 0.0355 - val_mse: 0.0412 - 2s/epoch - 51ms/step\n",
            "Epoch 327/500\n",
            "35/35 - 3s - loss: 0.0023 - mae: 0.0255 - mse: 0.0067 - val_loss: 0.0121 - val_mae: 0.0355 - val_mse: 0.0412 - 3s/epoch - 86ms/step\n",
            "Epoch 328/500\n",
            "35/35 - 3s - loss: 0.0023 - mae: 0.0255 - mse: 0.0067 - val_loss: 0.0121 - val_mae: 0.0355 - val_mse: 0.0412 - 3s/epoch - 85ms/step\n",
            "Epoch 329/500\n",
            "35/35 - 2s - loss: 0.0023 - mae: 0.0255 - mse: 0.0067 - val_loss: 0.0121 - val_mae: 0.0355 - val_mse: 0.0412 - 2s/epoch - 56ms/step\n",
            "Epoch 330/500\n",
            "35/35 - 2s - loss: 0.0023 - mae: 0.0255 - mse: 0.0067 - val_loss: 0.0121 - val_mae: 0.0355 - val_mse: 0.0412 - 2s/epoch - 47ms/step\n",
            "Epoch 331/500\n",
            "35/35 - 2s - loss: 0.0023 - mae: 0.0255 - mse: 0.0067 - val_loss: 0.0121 - val_mae: 0.0355 - val_mse: 0.0412 - 2s/epoch - 52ms/step\n",
            "Epoch 332/500\n",
            "35/35 - 4s - loss: 0.0023 - mae: 0.0255 - mse: 0.0067 - val_loss: 0.0121 - val_mae: 0.0355 - val_mse: 0.0412 - 4s/epoch - 103ms/step\n",
            "Epoch 333/500\n",
            "35/35 - 2s - loss: 0.0023 - mae: 0.0255 - mse: 0.0067 - val_loss: 0.0121 - val_mae: 0.0355 - val_mse: 0.0412 - 2s/epoch - 49ms/step\n",
            "Epoch 334/500\n",
            "35/35 - 2s - loss: 0.0023 - mae: 0.0255 - mse: 0.0067 - val_loss: 0.0121 - val_mae: 0.0355 - val_mse: 0.0412 - 2s/epoch - 52ms/step\n",
            "Epoch 335/500\n",
            "35/35 - 2s - loss: 0.0023 - mae: 0.0255 - mse: 0.0067 - val_loss: 0.0121 - val_mae: 0.0355 - val_mse: 0.0412 - 2s/epoch - 52ms/step\n",
            "Epoch 336/500\n",
            "35/35 - 2s - loss: 0.0023 - mae: 0.0255 - mse: 0.0067 - val_loss: 0.0121 - val_mae: 0.0355 - val_mse: 0.0412 - 2s/epoch - 51ms/step\n",
            "Epoch 337/500\n",
            "35/35 - 2s - loss: 0.0023 - mae: 0.0255 - mse: 0.0067 - val_loss: 0.0121 - val_mae: 0.0355 - val_mse: 0.0412 - 2s/epoch - 47ms/step\n",
            "Epoch 338/500\n",
            "35/35 - 3s - loss: 0.0023 - mae: 0.0254 - mse: 0.0067 - val_loss: 0.0121 - val_mae: 0.0355 - val_mse: 0.0412 - 3s/epoch - 97ms/step\n",
            "Epoch 339/500\n",
            "35/35 - 2s - loss: 0.0023 - mae: 0.0254 - mse: 0.0067 - val_loss: 0.0121 - val_mae: 0.0354 - val_mse: 0.0412 - 2s/epoch - 52ms/step\n",
            "Epoch 340/500\n",
            "35/35 - 2s - loss: 0.0023 - mae: 0.0254 - mse: 0.0067 - val_loss: 0.0121 - val_mae: 0.0354 - val_mse: 0.0412 - 2s/epoch - 49ms/step\n",
            "Epoch 341/500\n",
            "35/35 - 2s - loss: 0.0023 - mae: 0.0254 - mse: 0.0067 - val_loss: 0.0121 - val_mae: 0.0354 - val_mse: 0.0412 - 2s/epoch - 53ms/step\n",
            "Epoch 342/500\n",
            "35/35 - 2s - loss: 0.0023 - mae: 0.0254 - mse: 0.0067 - val_loss: 0.0120 - val_mae: 0.0354 - val_mse: 0.0412 - 2s/epoch - 52ms/step\n",
            "Epoch 343/500\n",
            "35/35 - 3s - loss: 0.0023 - mae: 0.0254 - mse: 0.0067 - val_loss: 0.0120 - val_mae: 0.0354 - val_mse: 0.0412 - 3s/epoch - 93ms/step\n",
            "Epoch 344/500\n",
            "35/35 - 2s - loss: 0.0023 - mae: 0.0254 - mse: 0.0067 - val_loss: 0.0120 - val_mae: 0.0354 - val_mse: 0.0412 - 2s/epoch - 53ms/step\n",
            "Epoch 345/500\n",
            "35/35 - 2s - loss: 0.0023 - mae: 0.0254 - mse: 0.0067 - val_loss: 0.0120 - val_mae: 0.0354 - val_mse: 0.0412 - 2s/epoch - 55ms/step\n",
            "Epoch 346/500\n",
            "35/35 - 2s - loss: 0.0023 - mae: 0.0254 - mse: 0.0067 - val_loss: 0.0120 - val_mae: 0.0354 - val_mse: 0.0412 - 2s/epoch - 49ms/step\n",
            "Epoch 347/500\n",
            "35/35 - 2s - loss: 0.0023 - mae: 0.0254 - mse: 0.0067 - val_loss: 0.0120 - val_mae: 0.0354 - val_mse: 0.0412 - 2s/epoch - 49ms/step\n",
            "Epoch 348/500\n",
            "35/35 - 3s - loss: 0.0023 - mae: 0.0254 - mse: 0.0067 - val_loss: 0.0120 - val_mae: 0.0354 - val_mse: 0.0412 - 3s/epoch - 76ms/step\n",
            "Epoch 349/500\n",
            "35/35 - 2s - loss: 0.0023 - mae: 0.0254 - mse: 0.0067 - val_loss: 0.0120 - val_mae: 0.0354 - val_mse: 0.0412 - 2s/epoch - 52ms/step\n",
            "Epoch 350/500\n",
            "35/35 - 2s - loss: 0.0023 - mae: 0.0254 - mse: 0.0067 - val_loss: 0.0120 - val_mae: 0.0354 - val_mse: 0.0412 - 2s/epoch - 52ms/step\n",
            "Epoch 351/500\n",
            "35/35 - 2s - loss: 0.0023 - mae: 0.0254 - mse: 0.0067 - val_loss: 0.0120 - val_mae: 0.0354 - val_mse: 0.0412 - 2s/epoch - 48ms/step\n",
            "Epoch 352/500\n",
            "35/35 - 2s - loss: 0.0023 - mae: 0.0254 - mse: 0.0067 - val_loss: 0.0120 - val_mae: 0.0354 - val_mse: 0.0412 - 2s/epoch - 51ms/step\n",
            "Epoch 353/500\n",
            "35/35 - 2s - loss: 0.0023 - mae: 0.0254 - mse: 0.0067 - val_loss: 0.0120 - val_mae: 0.0354 - val_mse: 0.0412 - 2s/epoch - 53ms/step\n",
            "Epoch 354/500\n",
            "35/35 - 3s - loss: 0.0023 - mae: 0.0254 - mse: 0.0067 - val_loss: 0.0120 - val_mae: 0.0354 - val_mse: 0.0412 - 3s/epoch - 79ms/step\n",
            "Epoch 355/500\n",
            "35/35 - 2s - loss: 0.0023 - mae: 0.0254 - mse: 0.0067 - val_loss: 0.0120 - val_mae: 0.0354 - val_mse: 0.0412 - 2s/epoch - 51ms/step\n",
            "Epoch 356/500\n",
            "35/35 - 2s - loss: 0.0023 - mae: 0.0254 - mse: 0.0067 - val_loss: 0.0120 - val_mae: 0.0354 - val_mse: 0.0412 - 2s/epoch - 55ms/step\n",
            "Epoch 357/500\n",
            "35/35 - 2s - loss: 0.0023 - mae: 0.0254 - mse: 0.0067 - val_loss: 0.0120 - val_mae: 0.0354 - val_mse: 0.0412 - 2s/epoch - 52ms/step\n",
            "Epoch 358/500\n",
            "35/35 - 2s - loss: 0.0023 - mae: 0.0254 - mse: 0.0067 - val_loss: 0.0120 - val_mae: 0.0354 - val_mse: 0.0412 - 2s/epoch - 48ms/step\n",
            "Epoch 359/500\n",
            "35/35 - 3s - loss: 0.0023 - mae: 0.0254 - mse: 0.0067 - val_loss: 0.0120 - val_mae: 0.0354 - val_mse: 0.0412 - 3s/epoch - 92ms/step\n",
            "Epoch 360/500\n",
            "35/35 - 2s - loss: 0.0023 - mae: 0.0254 - mse: 0.0067 - val_loss: 0.0120 - val_mae: 0.0354 - val_mse: 0.0412 - 2s/epoch - 57ms/step\n",
            "Epoch 361/500\n",
            "35/35 - 2s - loss: 0.0023 - mae: 0.0254 - mse: 0.0067 - val_loss: 0.0120 - val_mae: 0.0354 - val_mse: 0.0412 - 2s/epoch - 49ms/step\n",
            "Epoch 362/500\n",
            "35/35 - 2s - loss: 0.0023 - mae: 0.0254 - mse: 0.0067 - val_loss: 0.0120 - val_mae: 0.0354 - val_mse: 0.0412 - 2s/epoch - 53ms/step\n",
            "Epoch 363/500\n",
            "35/35 - 2s - loss: 0.0023 - mae: 0.0254 - mse: 0.0067 - val_loss: 0.0120 - val_mae: 0.0354 - val_mse: 0.0412 - 2s/epoch - 54ms/step\n",
            "Epoch 364/500\n",
            "35/35 - 3s - loss: 0.0023 - mae: 0.0253 - mse: 0.0067 - val_loss: 0.0120 - val_mae: 0.0354 - val_mse: 0.0412 - 3s/epoch - 94ms/step\n",
            "Epoch 365/500\n",
            "35/35 - 3s - loss: 0.0022 - mae: 0.0253 - mse: 0.0067 - val_loss: 0.0120 - val_mae: 0.0353 - val_mse: 0.0412 - 3s/epoch - 77ms/step\n",
            "Epoch 366/500\n",
            "35/35 - 2s - loss: 0.0022 - mae: 0.0253 - mse: 0.0067 - val_loss: 0.0120 - val_mae: 0.0353 - val_mse: 0.0412 - 2s/epoch - 51ms/step\n",
            "Epoch 367/500\n",
            "35/35 - 2s - loss: 0.0022 - mae: 0.0253 - mse: 0.0067 - val_loss: 0.0120 - val_mae: 0.0353 - val_mse: 0.0412 - 2s/epoch - 53ms/step\n",
            "Epoch 368/500\n",
            "35/35 - 2s - loss: 0.0022 - mae: 0.0253 - mse: 0.0067 - val_loss: 0.0120 - val_mae: 0.0353 - val_mse: 0.0412 - 2s/epoch - 52ms/step\n",
            "Epoch 369/500\n",
            "35/35 - 2s - loss: 0.0022 - mae: 0.0253 - mse: 0.0067 - val_loss: 0.0120 - val_mae: 0.0353 - val_mse: 0.0412 - 2s/epoch - 55ms/step\n",
            "Epoch 370/500\n",
            "35/35 - 3s - loss: 0.0022 - mae: 0.0253 - mse: 0.0067 - val_loss: 0.0120 - val_mae: 0.0353 - val_mse: 0.0412 - 3s/epoch - 84ms/step\n",
            "Epoch 371/500\n",
            "35/35 - 2s - loss: 0.0022 - mae: 0.0253 - mse: 0.0067 - val_loss: 0.0120 - val_mae: 0.0353 - val_mse: 0.0412 - 2s/epoch - 53ms/step\n",
            "Epoch 372/500\n",
            "35/35 - 2s - loss: 0.0022 - mae: 0.0253 - mse: 0.0067 - val_loss: 0.0120 - val_mae: 0.0353 - val_mse: 0.0412 - 2s/epoch - 52ms/step\n",
            "Epoch 373/500\n",
            "35/35 - 2s - loss: 0.0022 - mae: 0.0253 - mse: 0.0067 - val_loss: 0.0120 - val_mae: 0.0353 - val_mse: 0.0412 - 2s/epoch - 49ms/step\n",
            "Epoch 374/500\n",
            "35/35 - 2s - loss: 0.0022 - mae: 0.0253 - mse: 0.0067 - val_loss: 0.0120 - val_mae: 0.0353 - val_mse: 0.0412 - 2s/epoch - 55ms/step\n",
            "Epoch 375/500\n",
            "35/35 - 4s - loss: 0.0022 - mae: 0.0253 - mse: 0.0067 - val_loss: 0.0120 - val_mae: 0.0353 - val_mse: 0.0412 - 4s/epoch - 101ms/step\n",
            "Epoch 376/500\n",
            "35/35 - 3s - loss: 0.0022 - mae: 0.0253 - mse: 0.0067 - val_loss: 0.0120 - val_mae: 0.0353 - val_mse: 0.0412 - 3s/epoch - 72ms/step\n",
            "Epoch 377/500\n",
            "35/35 - 2s - loss: 0.0022 - mae: 0.0253 - mse: 0.0067 - val_loss: 0.0120 - val_mae: 0.0353 - val_mse: 0.0412 - 2s/epoch - 51ms/step\n",
            "Epoch 378/500\n",
            "35/35 - 2s - loss: 0.0022 - mae: 0.0253 - mse: 0.0067 - val_loss: 0.0120 - val_mae: 0.0353 - val_mse: 0.0412 - 2s/epoch - 52ms/step\n",
            "Epoch 379/500\n",
            "35/35 - 2s - loss: 0.0022 - mae: 0.0253 - mse: 0.0067 - val_loss: 0.0120 - val_mae: 0.0353 - val_mse: 0.0412 - 2s/epoch - 48ms/step\n",
            "Epoch 380/500\n",
            "35/35 - 2s - loss: 0.0022 - mae: 0.0253 - mse: 0.0067 - val_loss: 0.0120 - val_mae: 0.0353 - val_mse: 0.0412 - 2s/epoch - 50ms/step\n",
            "Epoch 381/500\n",
            "35/35 - 3s - loss: 0.0022 - mae: 0.0253 - mse: 0.0067 - val_loss: 0.0120 - val_mae: 0.0353 - val_mse: 0.0412 - 3s/epoch - 93ms/step\n",
            "Epoch 382/500\n",
            "35/35 - 2s - loss: 0.0022 - mae: 0.0253 - mse: 0.0067 - val_loss: 0.0120 - val_mae: 0.0353 - val_mse: 0.0412 - 2s/epoch - 53ms/step\n",
            "Epoch 383/500\n",
            "35/35 - 2s - loss: 0.0022 - mae: 0.0253 - mse: 0.0067 - val_loss: 0.0120 - val_mae: 0.0353 - val_mse: 0.0412 - 2s/epoch - 53ms/step\n",
            "Epoch 384/500\n",
            "35/35 - 2s - loss: 0.0022 - mae: 0.0253 - mse: 0.0067 - val_loss: 0.0120 - val_mae: 0.0353 - val_mse: 0.0412 - 2s/epoch - 50ms/step\n",
            "Epoch 385/500\n",
            "35/35 - 2s - loss: 0.0022 - mae: 0.0253 - mse: 0.0067 - val_loss: 0.0120 - val_mae: 0.0353 - val_mse: 0.0412 - 2s/epoch - 48ms/step\n",
            "Epoch 386/500\n",
            "35/35 - 2s - loss: 0.0022 - mae: 0.0253 - mse: 0.0067 - val_loss: 0.0120 - val_mae: 0.0353 - val_mse: 0.0412 - 2s/epoch - 51ms/step\n",
            "Epoch 387/500\n",
            "35/35 - 4s - loss: 0.0022 - mae: 0.0253 - mse: 0.0067 - val_loss: 0.0120 - val_mae: 0.0353 - val_mse: 0.0412 - 4s/epoch - 106ms/step\n",
            "Epoch 388/500\n",
            "35/35 - 2s - loss: 0.0022 - mae: 0.0253 - mse: 0.0067 - val_loss: 0.0120 - val_mae: 0.0353 - val_mse: 0.0412 - 2s/epoch - 50ms/step\n",
            "Epoch 389/500\n",
            "35/35 - 2s - loss: 0.0022 - mae: 0.0253 - mse: 0.0067 - val_loss: 0.0120 - val_mae: 0.0353 - val_mse: 0.0412 - 2s/epoch - 48ms/step\n",
            "Epoch 390/500\n",
            "35/35 - 2s - loss: 0.0022 - mae: 0.0252 - mse: 0.0067 - val_loss: 0.0120 - val_mae: 0.0353 - val_mse: 0.0412 - 2s/epoch - 47ms/step\n",
            "Epoch 391/500\n",
            "35/35 - 2s - loss: 0.0022 - mae: 0.0252 - mse: 0.0067 - val_loss: 0.0120 - val_mae: 0.0352 - val_mse: 0.0412 - 2s/epoch - 48ms/step\n",
            "Epoch 392/500\n",
            "35/35 - 2s - loss: 0.0022 - mae: 0.0252 - mse: 0.0067 - val_loss: 0.0120 - val_mae: 0.0352 - val_mse: 0.0412 - 2s/epoch - 50ms/step\n",
            "Epoch 393/500\n",
            "35/35 - 4s - loss: 0.0022 - mae: 0.0252 - mse: 0.0067 - val_loss: 0.0120 - val_mae: 0.0352 - val_mse: 0.0412 - 4s/epoch - 102ms/step\n",
            "Epoch 394/500\n",
            "35/35 - 2s - loss: 0.0022 - mae: 0.0252 - mse: 0.0067 - val_loss: 0.0120 - val_mae: 0.0352 - val_mse: 0.0412 - 2s/epoch - 71ms/step\n",
            "Epoch 395/500\n",
            "35/35 - 2s - loss: 0.0022 - mae: 0.0252 - mse: 0.0067 - val_loss: 0.0120 - val_mae: 0.0352 - val_mse: 0.0412 - 2s/epoch - 52ms/step\n",
            "Epoch 396/500\n",
            "35/35 - 2s - loss: 0.0022 - mae: 0.0252 - mse: 0.0067 - val_loss: 0.0120 - val_mae: 0.0352 - val_mse: 0.0411 - 2s/epoch - 48ms/step\n",
            "Epoch 397/500\n",
            "35/35 - 2s - loss: 0.0022 - mae: 0.0252 - mse: 0.0067 - val_loss: 0.0120 - val_mae: 0.0352 - val_mse: 0.0411 - 2s/epoch - 52ms/step\n",
            "Epoch 398/500\n",
            "35/35 - 2s - loss: 0.0022 - mae: 0.0252 - mse: 0.0067 - val_loss: 0.0120 - val_mae: 0.0352 - val_mse: 0.0411 - 2s/epoch - 55ms/step\n",
            "Epoch 399/500\n",
            "35/35 - 4s - loss: 0.0022 - mae: 0.0252 - mse: 0.0067 - val_loss: 0.0120 - val_mae: 0.0352 - val_mse: 0.0411 - 4s/epoch - 103ms/step\n",
            "Epoch 400/500\n",
            "35/35 - 2s - loss: 0.0022 - mae: 0.0252 - mse: 0.0067 - val_loss: 0.0120 - val_mae: 0.0352 - val_mse: 0.0411 - 2s/epoch - 51ms/step\n",
            "Epoch 401/500\n",
            "35/35 - 2s - loss: 0.0022 - mae: 0.0252 - mse: 0.0067 - val_loss: 0.0120 - val_mae: 0.0352 - val_mse: 0.0411 - 2s/epoch - 52ms/step\n",
            "Epoch 402/500\n",
            "35/35 - 2s - loss: 0.0022 - mae: 0.0252 - mse: 0.0067 - val_loss: 0.0120 - val_mae: 0.0352 - val_mse: 0.0411 - 2s/epoch - 58ms/step\n",
            "Epoch 403/500\n",
            "35/35 - 2s - loss: 0.0022 - mae: 0.0252 - mse: 0.0067 - val_loss: 0.0120 - val_mae: 0.0352 - val_mse: 0.0411 - 2s/epoch - 54ms/step\n",
            "Epoch 404/500\n",
            "35/35 - 3s - loss: 0.0022 - mae: 0.0252 - mse: 0.0067 - val_loss: 0.0120 - val_mae: 0.0352 - val_mse: 0.0411 - 3s/epoch - 94ms/step\n",
            "Epoch 405/500\n",
            "35/35 - 2s - loss: 0.0022 - mae: 0.0252 - mse: 0.0067 - val_loss: 0.0120 - val_mae: 0.0352 - val_mse: 0.0411 - 2s/epoch - 55ms/step\n",
            "Epoch 406/500\n",
            "35/35 - 2s - loss: 0.0022 - mae: 0.0252 - mse: 0.0067 - val_loss: 0.0120 - val_mae: 0.0352 - val_mse: 0.0411 - 2s/epoch - 49ms/step\n",
            "Epoch 407/500\n",
            "35/35 - 2s - loss: 0.0022 - mae: 0.0252 - mse: 0.0067 - val_loss: 0.0120 - val_mae: 0.0352 - val_mse: 0.0411 - 2s/epoch - 56ms/step\n",
            "Epoch 408/500\n",
            "35/35 - 2s - loss: 0.0022 - mae: 0.0252 - mse: 0.0067 - val_loss: 0.0120 - val_mae: 0.0352 - val_mse: 0.0411 - 2s/epoch - 49ms/step\n",
            "Epoch 409/500\n",
            "35/35 - 4s - loss: 0.0022 - mae: 0.0252 - mse: 0.0067 - val_loss: 0.0120 - val_mae: 0.0352 - val_mse: 0.0411 - 4s/epoch - 103ms/step\n",
            "Epoch 410/500\n",
            "35/35 - 3s - loss: 0.0022 - mae: 0.0252 - mse: 0.0067 - val_loss: 0.0120 - val_mae: 0.0352 - val_mse: 0.0411 - 3s/epoch - 75ms/step\n",
            "Epoch 411/500\n",
            "35/35 - 2s - loss: 0.0022 - mae: 0.0252 - mse: 0.0067 - val_loss: 0.0120 - val_mae: 0.0352 - val_mse: 0.0411 - 2s/epoch - 48ms/step\n",
            "Epoch 412/500\n",
            "35/35 - 2s - loss: 0.0022 - mae: 0.0252 - mse: 0.0067 - val_loss: 0.0120 - val_mae: 0.0352 - val_mse: 0.0411 - 2s/epoch - 53ms/step\n",
            "Epoch 413/500\n",
            "35/35 - 2s - loss: 0.0022 - mae: 0.0252 - mse: 0.0067 - val_loss: 0.0120 - val_mae: 0.0352 - val_mse: 0.0411 - 2s/epoch - 49ms/step\n",
            "Epoch 414/500\n",
            "35/35 - 3s - loss: 0.0022 - mae: 0.0252 - mse: 0.0067 - val_loss: 0.0120 - val_mae: 0.0352 - val_mse: 0.0411 - 3s/epoch - 94ms/step\n",
            "Epoch 415/500\n",
            "35/35 - 2s - loss: 0.0022 - mae: 0.0252 - mse: 0.0067 - val_loss: 0.0120 - val_mae: 0.0352 - val_mse: 0.0411 - 2s/epoch - 64ms/step\n",
            "Epoch 416/500\n",
            "35/35 - 2s - loss: 0.0022 - mae: 0.0252 - mse: 0.0067 - val_loss: 0.0120 - val_mae: 0.0352 - val_mse: 0.0411 - 2s/epoch - 53ms/step\n",
            "Epoch 417/500\n",
            "35/35 - 2s - loss: 0.0022 - mae: 0.0251 - mse: 0.0067 - val_loss: 0.0120 - val_mae: 0.0351 - val_mse: 0.0411 - 2s/epoch - 53ms/step\n",
            "Epoch 418/500\n",
            "35/35 - 2s - loss: 0.0022 - mae: 0.0251 - mse: 0.0067 - val_loss: 0.0120 - val_mae: 0.0351 - val_mse: 0.0411 - 2s/epoch - 52ms/step\n",
            "Epoch 419/500\n",
            "35/35 - 2s - loss: 0.0022 - mae: 0.0251 - mse: 0.0067 - val_loss: 0.0120 - val_mae: 0.0351 - val_mse: 0.0411 - 2s/epoch - 52ms/step\n",
            "Epoch 420/500\n",
            "35/35 - 3s - loss: 0.0022 - mae: 0.0251 - mse: 0.0067 - val_loss: 0.0120 - val_mae: 0.0351 - val_mse: 0.0411 - 3s/epoch - 92ms/step\n",
            "Epoch 421/500\n",
            "35/35 - 3s - loss: 0.0022 - mae: 0.0251 - mse: 0.0067 - val_loss: 0.0120 - val_mae: 0.0351 - val_mse: 0.0411 - 3s/epoch - 85ms/step\n",
            "Epoch 422/500\n",
            "35/35 - 2s - loss: 0.0022 - mae: 0.0251 - mse: 0.0067 - val_loss: 0.0120 - val_mae: 0.0351 - val_mse: 0.0411 - 2s/epoch - 51ms/step\n",
            "Epoch 423/500\n",
            "35/35 - 2s - loss: 0.0022 - mae: 0.0251 - mse: 0.0067 - val_loss: 0.0120 - val_mae: 0.0351 - val_mse: 0.0411 - 2s/epoch - 53ms/step\n",
            "Epoch 424/500\n",
            "35/35 - 2s - loss: 0.0022 - mae: 0.0251 - mse: 0.0067 - val_loss: 0.0120 - val_mae: 0.0351 - val_mse: 0.0411 - 2s/epoch - 48ms/step\n",
            "Epoch 425/500\n",
            "35/35 - 3s - loss: 0.0022 - mae: 0.0251 - mse: 0.0067 - val_loss: 0.0120 - val_mae: 0.0351 - val_mse: 0.0411 - 3s/epoch - 73ms/step\n",
            "Epoch 426/500\n",
            "35/35 - 3s - loss: 0.0022 - mae: 0.0251 - mse: 0.0067 - val_loss: 0.0120 - val_mae: 0.0351 - val_mse: 0.0411 - 3s/epoch - 97ms/step\n",
            "Epoch 427/500\n",
            "35/35 - 2s - loss: 0.0022 - mae: 0.0251 - mse: 0.0067 - val_loss: 0.0120 - val_mae: 0.0351 - val_mse: 0.0411 - 2s/epoch - 55ms/step\n",
            "Epoch 428/500\n",
            "35/35 - 2s - loss: 0.0022 - mae: 0.0251 - mse: 0.0067 - val_loss: 0.0120 - val_mae: 0.0351 - val_mse: 0.0411 - 2s/epoch - 53ms/step\n",
            "Epoch 429/500\n",
            "35/35 - 2s - loss: 0.0022 - mae: 0.0251 - mse: 0.0067 - val_loss: 0.0120 - val_mae: 0.0351 - val_mse: 0.0411 - 2s/epoch - 56ms/step\n",
            "Epoch 430/500\n",
            "35/35 - 2s - loss: 0.0022 - mae: 0.0251 - mse: 0.0067 - val_loss: 0.0120 - val_mae: 0.0351 - val_mse: 0.0411 - 2s/epoch - 65ms/step\n",
            "Epoch 431/500\n",
            "35/35 - 4s - loss: 0.0022 - mae: 0.0251 - mse: 0.0067 - val_loss: 0.0120 - val_mae: 0.0351 - val_mse: 0.0411 - 4s/epoch - 103ms/step\n",
            "Epoch 432/500\n",
            "35/35 - 2s - loss: 0.0022 - mae: 0.0251 - mse: 0.0067 - val_loss: 0.0120 - val_mae: 0.0351 - val_mse: 0.0411 - 2s/epoch - 48ms/step\n",
            "Epoch 433/500\n",
            "35/35 - 2s - loss: 0.0022 - mae: 0.0251 - mse: 0.0067 - val_loss: 0.0120 - val_mae: 0.0351 - val_mse: 0.0411 - 2s/epoch - 49ms/step\n",
            "Epoch 434/500\n",
            "35/35 - 2s - loss: 0.0022 - mae: 0.0251 - mse: 0.0067 - val_loss: 0.0120 - val_mae: 0.0351 - val_mse: 0.0411 - 2s/epoch - 48ms/step\n",
            "Epoch 435/500\n",
            "35/35 - 2s - loss: 0.0022 - mae: 0.0251 - mse: 0.0067 - val_loss: 0.0120 - val_mae: 0.0351 - val_mse: 0.0411 - 2s/epoch - 52ms/step\n",
            "Epoch 436/500\n",
            "35/35 - 3s - loss: 0.0022 - mae: 0.0251 - mse: 0.0067 - val_loss: 0.0120 - val_mae: 0.0351 - val_mse: 0.0411 - 3s/epoch - 74ms/step\n",
            "Epoch 437/500\n",
            "35/35 - 4s - loss: 0.0022 - mae: 0.0251 - mse: 0.0067 - val_loss: 0.0120 - val_mae: 0.0351 - val_mse: 0.0411 - 4s/epoch - 105ms/step\n",
            "Epoch 438/500\n",
            "35/35 - 2s - loss: 0.0022 - mae: 0.0251 - mse: 0.0067 - val_loss: 0.0120 - val_mae: 0.0351 - val_mse: 0.0411 - 2s/epoch - 53ms/step\n",
            "Epoch 439/500\n",
            "35/35 - 2s - loss: 0.0022 - mae: 0.0251 - mse: 0.0067 - val_loss: 0.0120 - val_mae: 0.0351 - val_mse: 0.0411 - 2s/epoch - 52ms/step\n",
            "Epoch 440/500\n",
            "35/35 - 2s - loss: 0.0022 - mae: 0.0251 - mse: 0.0067 - val_loss: 0.0120 - val_mae: 0.0351 - val_mse: 0.0411 - 2s/epoch - 53ms/step\n",
            "Epoch 441/500\n",
            "35/35 - 2s - loss: 0.0022 - mae: 0.0251 - mse: 0.0067 - val_loss: 0.0120 - val_mae: 0.0351 - val_mse: 0.0411 - 2s/epoch - 53ms/step\n",
            "Epoch 442/500\n",
            "35/35 - 4s - loss: 0.0022 - mae: 0.0251 - mse: 0.0067 - val_loss: 0.0120 - val_mae: 0.0351 - val_mse: 0.0411 - 4s/epoch - 101ms/step\n",
            "Epoch 443/500\n",
            "35/35 - 2s - loss: 0.0022 - mae: 0.0251 - mse: 0.0067 - val_loss: 0.0120 - val_mae: 0.0351 - val_mse: 0.0411 - 2s/epoch - 51ms/step\n",
            "Epoch 444/500\n",
            "35/35 - 2s - loss: 0.0022 - mae: 0.0250 - mse: 0.0067 - val_loss: 0.0120 - val_mae: 0.0350 - val_mse: 0.0411 - 2s/epoch - 51ms/step\n",
            "Epoch 445/500\n",
            "35/35 - 2s - loss: 0.0022 - mae: 0.0250 - mse: 0.0067 - val_loss: 0.0120 - val_mae: 0.0350 - val_mse: 0.0411 - 2s/epoch - 53ms/step\n",
            "Epoch 446/500\n",
            "35/35 - 2s - loss: 0.0022 - mae: 0.0250 - mse: 0.0067 - val_loss: 0.0120 - val_mae: 0.0350 - val_mse: 0.0411 - 2s/epoch - 48ms/step\n",
            "Epoch 447/500\n",
            "35/35 - 3s - loss: 0.0022 - mae: 0.0250 - mse: 0.0067 - val_loss: 0.0120 - val_mae: 0.0350 - val_mse: 0.0411 - 3s/epoch - 76ms/step\n",
            "Epoch 448/500\n",
            "35/35 - 3s - loss: 0.0022 - mae: 0.0250 - mse: 0.0067 - val_loss: 0.0120 - val_mae: 0.0350 - val_mse: 0.0411 - 3s/epoch - 97ms/step\n",
            "Epoch 449/500\n",
            "35/35 - 2s - loss: 0.0022 - mae: 0.0250 - mse: 0.0067 - val_loss: 0.0120 - val_mae: 0.0350 - val_mse: 0.0411 - 2s/epoch - 53ms/step\n",
            "Epoch 450/500\n",
            "35/35 - 2s - loss: 0.0022 - mae: 0.0250 - mse: 0.0067 - val_loss: 0.0120 - val_mae: 0.0350 - val_mse: 0.0411 - 2s/epoch - 47ms/step\n",
            "Epoch 451/500\n",
            "35/35 - 2s - loss: 0.0022 - mae: 0.0250 - mse: 0.0067 - val_loss: 0.0120 - val_mae: 0.0350 - val_mse: 0.0411 - 2s/epoch - 52ms/step\n",
            "Epoch 452/500\n",
            "35/35 - 2s - loss: 0.0022 - mae: 0.0250 - mse: 0.0067 - val_loss: 0.0120 - val_mae: 0.0350 - val_mse: 0.0411 - 2s/epoch - 52ms/step\n",
            "Epoch 453/500\n",
            "35/35 - 2s - loss: 0.0022 - mae: 0.0250 - mse: 0.0067 - val_loss: 0.0120 - val_mae: 0.0350 - val_mse: 0.0411 - 2s/epoch - 49ms/step\n",
            "Epoch 454/500\n",
            "35/35 - 3s - loss: 0.0022 - mae: 0.0250 - mse: 0.0067 - val_loss: 0.0120 - val_mae: 0.0350 - val_mse: 0.0411 - 3s/epoch - 99ms/step\n",
            "Epoch 455/500\n",
            "35/35 - 2s - loss: 0.0022 - mae: 0.0250 - mse: 0.0067 - val_loss: 0.0120 - val_mae: 0.0350 - val_mse: 0.0411 - 2s/epoch - 56ms/step\n",
            "Epoch 456/500\n",
            "35/35 - 2s - loss: 0.0022 - mae: 0.0250 - mse: 0.0067 - val_loss: 0.0120 - val_mae: 0.0350 - val_mse: 0.0411 - 2s/epoch - 48ms/step\n",
            "Epoch 457/500\n",
            "35/35 - 2s - loss: 0.0022 - mae: 0.0250 - mse: 0.0067 - val_loss: 0.0120 - val_mae: 0.0350 - val_mse: 0.0411 - 2s/epoch - 55ms/step\n",
            "Epoch 458/500\n",
            "35/35 - 2s - loss: 0.0022 - mae: 0.0250 - mse: 0.0067 - val_loss: 0.0120 - val_mae: 0.0350 - val_mse: 0.0411 - 2s/epoch - 54ms/step\n",
            "Epoch 459/500\n",
            "35/35 - 4s - loss: 0.0022 - mae: 0.0250 - mse: 0.0067 - val_loss: 0.0120 - val_mae: 0.0350 - val_mse: 0.0411 - 4s/epoch - 105ms/step\n",
            "Epoch 460/500\n",
            "35/35 - 3s - loss: 0.0022 - mae: 0.0250 - mse: 0.0067 - val_loss: 0.0120 - val_mae: 0.0350 - val_mse: 0.0411 - 3s/epoch - 72ms/step\n",
            "Epoch 461/500\n",
            "35/35 - 2s - loss: 0.0022 - mae: 0.0250 - mse: 0.0067 - val_loss: 0.0120 - val_mae: 0.0350 - val_mse: 0.0411 - 2s/epoch - 52ms/step\n",
            "Epoch 462/500\n",
            "35/35 - 2s - loss: 0.0022 - mae: 0.0250 - mse: 0.0067 - val_loss: 0.0120 - val_mae: 0.0350 - val_mse: 0.0411 - 2s/epoch - 49ms/step\n",
            "Epoch 463/500\n",
            "35/35 - 2s - loss: 0.0022 - mae: 0.0250 - mse: 0.0067 - val_loss: 0.0120 - val_mae: 0.0350 - val_mse: 0.0411 - 2s/epoch - 53ms/step\n",
            "Epoch 464/500\n",
            "35/35 - 2s - loss: 0.0022 - mae: 0.0250 - mse: 0.0067 - val_loss: 0.0120 - val_mae: 0.0350 - val_mse: 0.0411 - 2s/epoch - 52ms/step\n",
            "Epoch 465/500\n",
            "35/35 - 3s - loss: 0.0022 - mae: 0.0250 - mse: 0.0067 - val_loss: 0.0120 - val_mae: 0.0350 - val_mse: 0.0411 - 3s/epoch - 94ms/step\n",
            "Epoch 466/500\n",
            "35/35 - 3s - loss: 0.0022 - mae: 0.0250 - mse: 0.0067 - val_loss: 0.0120 - val_mae: 0.0350 - val_mse: 0.0411 - 3s/epoch - 79ms/step\n",
            "Epoch 467/500\n",
            "35/35 - 2s - loss: 0.0022 - mae: 0.0250 - mse: 0.0067 - val_loss: 0.0120 - val_mae: 0.0350 - val_mse: 0.0411 - 2s/epoch - 56ms/step\n",
            "Epoch 468/500\n",
            "35/35 - 2s - loss: 0.0022 - mae: 0.0250 - mse: 0.0067 - val_loss: 0.0120 - val_mae: 0.0350 - val_mse: 0.0411 - 2s/epoch - 52ms/step\n",
            "Epoch 469/500\n",
            "35/35 - 2s - loss: 0.0022 - mae: 0.0250 - mse: 0.0067 - val_loss: 0.0120 - val_mae: 0.0350 - val_mse: 0.0411 - 2s/epoch - 50ms/step\n",
            "Epoch 470/500\n",
            "35/35 - 4s - loss: 0.0022 - mae: 0.0250 - mse: 0.0067 - val_loss: 0.0120 - val_mae: 0.0350 - val_mse: 0.0411 - 4s/epoch - 102ms/step\n",
            "Epoch 471/500\n",
            "35/35 - 2s - loss: 0.0022 - mae: 0.0249 - mse: 0.0067 - val_loss: 0.0120 - val_mae: 0.0349 - val_mse: 0.0411 - 2s/epoch - 51ms/step\n",
            "Epoch 472/500\n",
            "35/35 - 2s - loss: 0.0022 - mae: 0.0249 - mse: 0.0067 - val_loss: 0.0120 - val_mae: 0.0349 - val_mse: 0.0411 - 2s/epoch - 53ms/step\n",
            "Epoch 473/500\n",
            "35/35 - 2s - loss: 0.0022 - mae: 0.0249 - mse: 0.0067 - val_loss: 0.0120 - val_mae: 0.0349 - val_mse: 0.0411 - 2s/epoch - 48ms/step\n",
            "Epoch 474/500\n",
            "35/35 - 2s - loss: 0.0022 - mae: 0.0249 - mse: 0.0067 - val_loss: 0.0120 - val_mae: 0.0349 - val_mse: 0.0411 - 2s/epoch - 57ms/step\n",
            "Epoch 475/500\n",
            "35/35 - 4s - loss: 0.0022 - mae: 0.0249 - mse: 0.0067 - val_loss: 0.0120 - val_mae: 0.0349 - val_mse: 0.0411 - 4s/epoch - 109ms/step\n",
            "Epoch 476/500\n",
            "35/35 - 2s - loss: 0.0022 - mae: 0.0249 - mse: 0.0067 - val_loss: 0.0120 - val_mae: 0.0349 - val_mse: 0.0411 - 2s/epoch - 47ms/step\n",
            "Epoch 477/500\n",
            "35/35 - 2s - loss: 0.0022 - mae: 0.0249 - mse: 0.0067 - val_loss: 0.0120 - val_mae: 0.0349 - val_mse: 0.0411 - 2s/epoch - 54ms/step\n",
            "Epoch 478/500\n",
            "35/35 - 2s - loss: 0.0022 - mae: 0.0249 - mse: 0.0067 - val_loss: 0.0120 - val_mae: 0.0349 - val_mse: 0.0411 - 2s/epoch - 53ms/step\n",
            "Epoch 479/500\n",
            "35/35 - 2s - loss: 0.0022 - mae: 0.0249 - mse: 0.0067 - val_loss: 0.0120 - val_mae: 0.0349 - val_mse: 0.0411 - 2s/epoch - 52ms/step\n",
            "Epoch 480/500\n",
            "35/35 - 3s - loss: 0.0022 - mae: 0.0249 - mse: 0.0067 - val_loss: 0.0120 - val_mae: 0.0349 - val_mse: 0.0411 - 3s/epoch - 75ms/step\n",
            "Epoch 481/500\n",
            "35/35 - 2s - loss: 0.0022 - mae: 0.0249 - mse: 0.0067 - val_loss: 0.0120 - val_mae: 0.0349 - val_mse: 0.0411 - 2s/epoch - 47ms/step\n",
            "Epoch 482/500\n",
            "35/35 - 2s - loss: 0.0022 - mae: 0.0249 - mse: 0.0067 - val_loss: 0.0120 - val_mae: 0.0349 - val_mse: 0.0411 - 2s/epoch - 55ms/step\n",
            "Epoch 483/500\n",
            "35/35 - 2s - loss: 0.0022 - mae: 0.0249 - mse: 0.0067 - val_loss: 0.0120 - val_mae: 0.0349 - val_mse: 0.0411 - 2s/epoch - 54ms/step\n",
            "Epoch 484/500\n",
            "35/35 - 2s - loss: 0.0022 - mae: 0.0249 - mse: 0.0067 - val_loss: 0.0120 - val_mae: 0.0349 - val_mse: 0.0411 - 2s/epoch - 49ms/step\n",
            "Epoch 485/500\n",
            "35/35 - 2s - loss: 0.0022 - mae: 0.0249 - mse: 0.0067 - val_loss: 0.0120 - val_mae: 0.0349 - val_mse: 0.0411 - 2s/epoch - 71ms/step\n",
            "Epoch 486/500\n",
            "35/35 - 3s - loss: 0.0022 - mae: 0.0249 - mse: 0.0067 - val_loss: 0.0120 - val_mae: 0.0349 - val_mse: 0.0411 - 3s/epoch - 97ms/step\n",
            "Epoch 487/500\n",
            "35/35 - 2s - loss: 0.0022 - mae: 0.0249 - mse: 0.0067 - val_loss: 0.0120 - val_mae: 0.0349 - val_mse: 0.0411 - 2s/epoch - 55ms/step\n",
            "Epoch 488/500\n",
            "35/35 - 2s - loss: 0.0022 - mae: 0.0249 - mse: 0.0067 - val_loss: 0.0120 - val_mae: 0.0349 - val_mse: 0.0411 - 2s/epoch - 52ms/step\n",
            "Epoch 489/500\n",
            "35/35 - 2s - loss: 0.0022 - mae: 0.0249 - mse: 0.0067 - val_loss: 0.0120 - val_mae: 0.0349 - val_mse: 0.0410 - 2s/epoch - 49ms/step\n",
            "Epoch 490/500\n",
            "35/35 - 2s - loss: 0.0022 - mae: 0.0249 - mse: 0.0066 - val_loss: 0.0120 - val_mae: 0.0349 - val_mse: 0.0410 - 2s/epoch - 50ms/step\n",
            "Epoch 491/500\n",
            "35/35 - 2s - loss: 0.0022 - mae: 0.0249 - mse: 0.0066 - val_loss: 0.0120 - val_mae: 0.0349 - val_mse: 0.0410 - 2s/epoch - 63ms/step\n",
            "Epoch 492/500\n",
            "35/35 - 4s - loss: 0.0022 - mae: 0.0249 - mse: 0.0066 - val_loss: 0.0120 - val_mae: 0.0349 - val_mse: 0.0410 - 4s/epoch - 108ms/step\n",
            "Epoch 493/500\n",
            "35/35 - 2s - loss: 0.0022 - mae: 0.0249 - mse: 0.0066 - val_loss: 0.0120 - val_mae: 0.0349 - val_mse: 0.0410 - 2s/epoch - 59ms/step\n",
            "Epoch 494/500\n",
            "35/35 - 2s - loss: 0.0022 - mae: 0.0249 - mse: 0.0066 - val_loss: 0.0120 - val_mae: 0.0349 - val_mse: 0.0410 - 2s/epoch - 51ms/step\n",
            "Epoch 495/500\n",
            "35/35 - 2s - loss: 0.0022 - mae: 0.0249 - mse: 0.0066 - val_loss: 0.0120 - val_mae: 0.0349 - val_mse: 0.0410 - 2s/epoch - 54ms/step\n",
            "Epoch 496/500\n",
            "35/35 - 2s - loss: 0.0022 - mae: 0.0249 - mse: 0.0066 - val_loss: 0.0120 - val_mae: 0.0349 - val_mse: 0.0410 - 2s/epoch - 52ms/step\n",
            "Epoch 497/500\n",
            "35/35 - 2s - loss: 0.0022 - mae: 0.0249 - mse: 0.0066 - val_loss: 0.0120 - val_mae: 0.0349 - val_mse: 0.0410 - 2s/epoch - 52ms/step\n",
            "Epoch 498/500\n",
            "35/35 - 3s - loss: 0.0022 - mae: 0.0249 - mse: 0.0066 - val_loss: 0.0120 - val_mae: 0.0349 - val_mse: 0.0410 - 3s/epoch - 94ms/step\n",
            "Epoch 499/500\n",
            "35/35 - 3s - loss: 0.0022 - mae: 0.0248 - mse: 0.0066 - val_loss: 0.0120 - val_mae: 0.0348 - val_mse: 0.0410 - 3s/epoch - 73ms/step\n",
            "Epoch 500/500\n",
            "35/35 - 2s - loss: 0.0022 - mae: 0.0248 - mse: 0.0066 - val_loss: 0.0120 - val_mae: 0.0348 - val_mse: 0.0410 - 2s/epoch - 52ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Visualize the model"
      ],
      "metadata": {
        "id": "tWB20oNRN0ky"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "id": "MD2kyYUVt3O0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "1d856f5a-1b43-40e2-fc8f-d4e1f4a5f3f3"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x600 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x600 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "# Get mae and loss from history log\n",
        "mae=history.history['mae']\n",
        "loss=history.history['loss']\n",
        "\n",
        "# Get number of epochs\n",
        "epochs=range(len(loss))\n",
        "\n",
        "\n",
        "# Plot mae and loss\n",
        "plot_series(\n",
        "    x=epochs,\n",
        "    y=(mae, loss),\n",
        "    title='MAE and Loss',\n",
        "    xlabel='MAE',\n",
        "    ylabel='Loss',\n",
        "    legend=['MAE', 'Loss']\n",
        "    )\n",
        "\n",
        "# print(int(epochs[-1]*0.2))\n",
        "# Only plot the last 80% of the epochs\n",
        "zoom_split = int(epochs[-1] * 0.2)\n",
        "epochs_zoom = epochs[zoom_split:]\n",
        "mae_zoom = mae[zoom_split:]\n",
        "loss_zoom = loss[zoom_split:]\n",
        "\n",
        "# Plot zoomed mae and loss\n",
        "plot_series(\n",
        "    x=epochs_zoom,\n",
        "    y=(mae_zoom, loss_zoom),\n",
        "    title='MAE and Loss',\n",
        "    xlabel='MAE',\n",
        "    ylabel='Loss',\n",
        "    legend=['MAE', 'Loss']\n",
        "    )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "tX6K30XEciYW"
      },
      "source": [
        "# Forcasting"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "TmwYog9BciYW"
      },
      "outputs": [],
      "source": [
        "def model_forecast(model, series, window_size, batch_size):\n",
        "\n",
        "    # Generate a TF Dataset from the series values\n",
        "    ds = tf.data.Dataset.from_tensor_slices(series)\n",
        "\n",
        "    # Window the data but only take those with the specified size\n",
        "    ds = ds.window(window_size, shift=1, drop_remainder=True)\n",
        "\n",
        "    # Flatten the windows by putting its elements in a single batch\n",
        "    ds = ds.flat_map(lambda w: w.batch(window_size))\n",
        "\n",
        "    # Create batches of windows\n",
        "    ds = ds.batch(batch_size).prefetch(1)\n",
        "\n",
        "    # Get predictions on the entire dataset\n",
        "    forecast = model.predict(ds)\n",
        "\n",
        "    return forecast"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h1lN8L7KciYW",
        "outputId": "fa896d3f-59c8-422d-ebcd-42f83d312ab8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "35/35 [==============================] - 3s 18ms/step\n",
            "Output shape: (7, 8)\n",
            "First prediction: \n",
            " [[-0.4071157  -0.41958058  2.7386804  -0.361528   -0.40809157 -0.40695283\n",
            "  -0.32899168 -0.29696998]\n",
            " [-0.40695167 -0.41694748  2.727849   -0.35836852 -0.40724322 -0.40563685\n",
            "  -0.32585555 -0.29588565]\n",
            " [-0.4064793  -0.41913515  2.7173567  -0.35564297 -0.40669444 -0.40466517\n",
            "  -0.32466602 -0.28581664]\n",
            " [-0.40069476 -0.41557178  2.7128313  -0.35261175 -0.40167752 -0.4080875\n",
            "  -0.32590657 -0.2860824 ]\n",
            " [-0.40301982 -0.41856098  2.702012   -0.34879392 -0.39832085 -0.40388474\n",
            "  -0.31479824 -0.28345108]\n",
            " [-0.4050302  -0.41787276  2.6856883  -0.35017762 -0.39785388 -0.40533328\n",
            "  -0.32643718 -0.28241423]\n",
            " [-0.40246445 -0.4181832   2.6827369  -0.3503397  -0.39627185 -0.40928194\n",
            "  -0.33043224 -0.27397272]]\n"
          ]
        }
      ],
      "source": [
        "# First Prediction\n",
        "forecast = model_forecast(model, data, N_PAST, BATCH_SIZE)\n",
        "print('Output shape:', forecast[0].shape)\n",
        "print('First prediction: \\n', forecast[0])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# PASS THE NORMALIZED data IN THE FOLLOWING CODE\n",
        "# forecast = model_forecast(model, data, N_PAST, BATCH_SIZE)\n",
        "forecast = forecast[SPLIT_TIME - N_PAST:-1]\n",
        "# series_val = series_val[:forecast.shape[0]]\n",
        "\n",
        "# print(forecast.shape, series_val.shape)\n",
        "\n",
        "# # Compute the MAE\n",
        "# MAE = tf.keras.metrics.MeanAbsoluteError()\n",
        "# MAE.update_state(series_val[:,:], forecast[:,:]) #Accumulate statistics for the metric.\n",
        "# MAE = MAE.result().numpy() #Compute the current metric value.\n",
        "# print('Validation MAE:', round(MAE, 4))\n",
        "\n",
        "# Plot the results\n",
        "# plot_series(np.squeeze(time_valid)[:series_val.shape[0]], (series_val, forecast))"
      ],
      "metadata": {
        "id": "HflLlhEO7ppy"
      },
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "S9kQJQ0kAg6v"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}