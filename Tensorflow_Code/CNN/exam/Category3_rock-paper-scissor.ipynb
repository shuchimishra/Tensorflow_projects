{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "L4",
      "authorship_tag": "ABX9TyPqnJQQF4vSg4Az3zysrPy3",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/shuchimishra/Tensorflow_projects/blob/main/Tensorflow_Code/CNN/exam/Category3_rock-paper-scissor.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "G3A4OHVubTJf",
        "outputId": "c5ab9ce1-dd77-46d2-a486-d2f00c654963"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 2520 images belonging to 3 classes.\n",
            "Found 372 images belonging to 3 classes.\n",
            "{'paper': 0, 'rock': 1, 'scissors': 2}\n",
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d (Conv2D)             (None, 148, 148, 128)     3584      \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2  (None, 74, 74, 128)       0         \n",
            " D)                                                              \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 72, 72, 128)       147584    \n",
            "                                                                 \n",
            " max_pooling2d_1 (MaxPoolin  (None, 36, 36, 128)       0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_2 (Conv2D)           (None, 34, 34, 128)       147584    \n",
            "                                                                 \n",
            " max_pooling2d_2 (MaxPoolin  (None, 17, 17, 128)       0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_3 (Conv2D)           (None, 15, 15, 128)       147584    \n",
            "                                                                 \n",
            " max_pooling2d_3 (MaxPoolin  (None, 7, 7, 128)         0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 6272)              0         \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 6272)              0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 256)               1605888   \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 3)                 771       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 2052995 (7.83 MB)\n",
            "Trainable params: 2052995 (7.83 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "Epoch 1/100\n",
            " 54/126 [===========>..................] - ETA: 10s - loss: 1.1009 - accuracy: 0.3565"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-15-4946bba26504>\u001b[0m in \u001b[0;36m<cell line: 110>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    110\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'__main__'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    111\u001b[0m     \u001b[0;31m# DO NOT CHANGE THIS CODE\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 112\u001b[0;31m     \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msolution_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    113\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"mymodel.h5\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-15-4946bba26504>\u001b[0m in \u001b[0;36msolution_model\u001b[0;34m()\u001b[0m\n\u001b[1;32m    100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m   \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclear_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 102\u001b[0;31m   \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_generator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_generator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mMCP\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mRLP\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mES\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#ES, callback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    103\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m             \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1805\u001b[0m                         ):\n\u001b[1;32m   1806\u001b[0m                             \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1807\u001b[0;31m                             \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1808\u001b[0m                             \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1809\u001b[0m                                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    830\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    831\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 832\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    833\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    834\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    866\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    867\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 868\u001b[0;31m       return tracing_compilation.call_function(\n\u001b[0m\u001b[1;32m    869\u001b[0m           \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_no_variable_creation_config\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    870\u001b[0m       )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py\u001b[0m in \u001b[0;36mcall_function\u001b[0;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[1;32m    137\u001b[0m   \u001b[0mbound_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m   \u001b[0mflat_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munpack_inputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbound_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 139\u001b[0;31m   return function._call_flat(  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m    140\u001b[0m       \u001b[0mflat_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m   )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/concrete_function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[1;32m   1321\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1322\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1323\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_inference_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall_preflattened\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1324\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1325\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py\u001b[0m in \u001b[0;36mcall_preflattened\u001b[0;34m(self, args)\u001b[0m\n\u001b[1;32m    214\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mcall_preflattened\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mSequence\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m     \u001b[0;34m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 216\u001b[0;31m     \u001b[0mflat_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    217\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpack_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mflat_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py\u001b[0m in \u001b[0;36mcall_flat\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    249\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mrecord\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_recording\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    250\u001b[0m           \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_bound_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 251\u001b[0;31m             outputs = self._bound_context.call_function(\n\u001b[0m\u001b[1;32m    252\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    253\u001b[0m                 \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/context.py\u001b[0m in \u001b[0;36mcall_function\u001b[0;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[1;32m   1484\u001b[0m     \u001b[0mcancellation_context\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcancellation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1485\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcancellation_context\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1486\u001b[0;31m       outputs = execute.execute(\n\u001b[0m\u001b[1;32m   1487\u001b[0m           \u001b[0mname\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"utf-8\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1488\u001b[0m           \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     54\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     55\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "# ========================================================================================\n",
        "# PROBLEM B3\n",
        "#\n",
        "# Build a CNN based classifier for Rock-Paper-Scissors dataset.\n",
        "# Your input layer should accept 150x150 with 3 bytes color as the input shape.\n",
        "# This is unlabeled data, use ImageDataGenerator to automatically label it.\n",
        "# Don't use lambda layers in your model.\n",
        "#\n",
        "# The dataset used in this problem is created by Laurence Moroney (laurencemoroney.com).\n",
        "#\n",
        "# Desired accuracy AND validation_accuracy > 83%\n",
        "# ========================================================================================\n",
        "\n",
        "import urllib.request\n",
        "import zipfile\n",
        "import tensorflow as tf\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "\n",
        "def solution_model():\n",
        "  data_url = 'https://storage.googleapis.com/learning-datasets/rps.zip'\n",
        "  urllib.request.urlretrieve(data_url, 'rps.zip')\n",
        "  local_file = 'rps.zip'\n",
        "  zip_ref = zipfile.ZipFile(local_file, 'r')\n",
        "  zip_ref.extractall('data/')\n",
        "  zip_ref.close()\n",
        "\n",
        "  val_url = 'https://storage.googleapis.com/learning-datasets/rps-test-set.zip'\n",
        "  urllib.request.urlretrieve(val_url, 'rps-test-set.zip')\n",
        "  local_file = 'rps-test-set.zip'\n",
        "  zip_ref = zipfile.ZipFile(local_file, 'r')\n",
        "  zip_ref.extractall('data/')\n",
        "  zip_ref.close()\n",
        "\n",
        "  TRAINING_DIR = \"data/rps\"\n",
        "  VALIDATION_DIR = \"data/rps-test-set\"\n",
        "  training_datagen = ImageDataGenerator(\n",
        "      rescale=1./255,\n",
        "      rotation_range=40,\n",
        "      width_shift_range=0.2,\n",
        "      height_shift_range=0.2,\n",
        "      shear_range=0.2,\n",
        "      zoom_range=0.2,\n",
        "      horizontal_flip=True,\n",
        "      fill_mode='nearest'\n",
        "  )\n",
        "\n",
        "  validation_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "  # YOUR IMAGE SIZE SHOULD BE 150x150\n",
        "  # Make sure you used \"categorical\"\n",
        "  train_generator = training_datagen.flow_from_directory(\n",
        "      TRAINING_DIR,\n",
        "      target_size=(150, 150),\n",
        "      class_mode='categorical',\n",
        "      batch_size=20\n",
        "  )\n",
        "  validation_generator = validation_datagen.flow_from_directory(\n",
        "      VALIDATION_DIR,\n",
        "      target_size=(150, 150),\n",
        "      class_mode='categorical',\n",
        "      batch_size=20\n",
        "  )\n",
        "\n",
        "  #Derive label details\n",
        "  class_dict = train_generator.class_indices # returns ie. {'cat': 0, 'dog': 1}\n",
        "  print(class_dict)\n",
        "  num_classes = len(class_dict)\n",
        "\n",
        "  model = tf.keras.models.Sequential([\n",
        "  # YOUR CODE HERE, end with 3 Neuron Dense, activated by softmax\n",
        "      tf.keras.layers.Conv2D(128, (3, 3), activation='relu', input_shape=(150, 150, 3)),\n",
        "      tf.keras.layers.MaxPooling2D((2, 2)),\n",
        "      tf.keras.layers.Conv2D(128, (3, 3), activation='relu'),\n",
        "      tf.keras.layers.MaxPooling2D((2, 2)),\n",
        "      tf.keras.layers.Conv2D(128, (3, 3), activation='relu'),\n",
        "      tf.keras.layers.MaxPooling2D((2, 2)),\n",
        "      tf.keras.layers.Conv2D(128, (3, 3), activation='relu'),\n",
        "      tf.keras.layers.MaxPooling2D((2, 2)),\n",
        "      tf.keras.layers.Flatten(),\n",
        "      tf.keras.layers.Dropout(0.5),\n",
        "      tf.keras.layers.Dense(256, activation='relu'),\n",
        "      tf.keras.layers.Dense(num_classes, activation='softmax')\n",
        "  ])\n",
        "\n",
        "  model.summary()\n",
        "\n",
        "\n",
        "  #callbacks\n",
        "  # callback = myCallback()\n",
        "  MCP = tf.keras.callbacks.ModelCheckpoint(filepath='bestmodel.h5',monitor='val_accuracy', mode='auto', save_best_only=True, save_weights_only=False, verbose=1)\n",
        "  RLP = tf.keras.callbacks.ReduceLROnPlateau(monitor=\"val_accuracy\",factor=0.1,patience=3, verbose=1,mode=\"auto\",min_lr=0.000000001)\n",
        "  ES = tf.keras.callbacks.EarlyStopping(monitor='val_accuracy',min_delta=1e-4,patience=5,verbose=1,start_from_epoch=5)\n",
        "\n",
        "\n",
        "  #Train and compile model\n",
        "  lr = 0.0001 #1e-5\n",
        "  optimizer = tf.keras.optimizers.Adam(learning_rate=lr, clipnorm=1) #, clipnorm=1\n",
        "  model.compile(optimizer=optimizer,loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "  tf.keras.backend.clear_session()\n",
        "  history = model.fit(train_generator, validation_data=validation_generator, epochs=100, callbacks=[MCP, RLP, ES]) #ES, callback\n",
        "\n",
        "\n",
        "  return model\n",
        "\n",
        "\n",
        "# The code below is to save your model as a .h5 file.\n",
        "# It will be saved automatically in your Submission folder.\n",
        "if __name__ == '__main__':\n",
        "    # DO NOT CHANGE THIS CODE\n",
        "    model=solution_model()\n",
        "    model.save(\"mymodel.h5\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# import urllib.request\n",
        "# import zipfile\n",
        "# import tensorflow as tf\n",
        "# from keras.preprocessing.image import ImageDataGenerator"
      ],
      "metadata": {
        "id": "y_14ivFubfWE"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# data_url = 'https://storage.googleapis.com/learning-datasets/rps.zip'\n",
        "# urllib.request.urlretrieve(data_url, 'rps.zip')\n",
        "# local_file = 'rps.zip'\n",
        "# zip_ref = zipfile.ZipFile(local_file, 'r')\n",
        "# zip_ref.extractall('data/')\n",
        "# zip_ref.close()"
      ],
      "metadata": {
        "id": "5F5_b4FwfYq8"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# val_url = 'https://storage.googleapis.com/learning-datasets/rps-test-set.zip'\n",
        "# urllib.request.urlretrieve(val_url, 'rps-test-set.zip')\n",
        "# local_file = 'rps-test-set.zip'\n",
        "# zip_ref = zipfile.ZipFile(local_file, 'r')\n",
        "# zip_ref.extractall('data/')\n",
        "# zip_ref.close()"
      ],
      "metadata": {
        "id": "IhWmNSeZiBqG"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# TRAINING_DIR = \"data/rps\"\n",
        "# VALIDATION_DIR = \"data/rps-test-set\"\n",
        "# training_datagen = ImageDataGenerator(\n",
        "#     rescale=1./255,\n",
        "#     rotation_range=40,\n",
        "#     width_shift_range=0.2,\n",
        "#     height_shift_range=0.2,\n",
        "#     shear_range=0.2,\n",
        "#     zoom_range=0.2,\n",
        "#     horizontal_flip=True,\n",
        "#     fill_mode='nearest'\n",
        "# )\n",
        "\n",
        "# validation_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "# # YOUR IMAGE SIZE SHOULD BE 150x150\n",
        "# # Make sure you used \"categorical\"\n",
        "# train_generator = training_datagen.flow_from_directory(\n",
        "#     TRAINING_DIR,\n",
        "#     target_size=(150, 150),\n",
        "#     class_mode='categorical',\n",
        "#     batch_size=20\n",
        "# )\n",
        "# validation_generator = validation_datagen.flow_from_directory(\n",
        "#     VALIDATION_DIR,\n",
        "#     target_size=(150, 150),\n",
        "#     class_mode='categorical',\n",
        "#     batch_size=20\n",
        "# )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XmJLkIjafdex",
        "outputId": "e22f1219-49e2-4316-d7f3-50b35721f376"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 2520 images belonging to 3 classes.\n",
            "Found 372 images belonging to 3 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# #Derive label details\n",
        "# class_dict = train_generator.class_indices # returns ie. {'cat': 0, 'dog': 1}\n",
        "# print(class_dict)\n",
        "# num_classes = len(class_dict)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MfD5GwRCf-gU",
        "outputId": "14748c1d-eaf4-43fd-f72f-436cf69a4dfa"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'paper': 0, 'rock': 1, 'scissors': 2}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# model = tf.keras.models.Sequential([\n",
        "# # YOUR CODE HERE, end with 3 Neuron Dense, activated by softmax\n",
        "#     tf.keras.layers.Conv2D(128, (3, 3), activation='relu', input_shape=(150, 150, 3)),\n",
        "#     tf.keras.layers.MaxPooling2D((2, 2)),\n",
        "#     tf.keras.layers.Conv2D(128, (3, 3), activation='relu'),\n",
        "#     tf.keras.layers.MaxPooling2D((2, 2)),\n",
        "#     tf.keras.layers.Conv2D(128, (3, 3), activation='relu'),\n",
        "#     tf.keras.layers.MaxPooling2D((2, 2)),\n",
        "#     tf.keras.layers.Conv2D(128, (3, 3), activation='relu'),\n",
        "#     tf.keras.layers.MaxPooling2D((2, 2)),\n",
        "#     tf.keras.layers.Flatten(),\n",
        "#     tf.keras.layers.Dropout(0.5),\n",
        "#     tf.keras.layers.Dense(256, activation='relu'),\n",
        "#     tf.keras.layers.Dense(num_classes, activation='softmax')\n",
        "# ])\n",
        "\n",
        "# model.summary()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I0aCJgFFbdWe",
        "outputId": "00ee968d-f145-498d-bd63-e4c55db0789d"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d (Conv2D)             (None, 148, 148, 128)     3584      \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2  (None, 74, 74, 128)       0         \n",
            " D)                                                              \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 72, 72, 128)       147584    \n",
            "                                                                 \n",
            " max_pooling2d_1 (MaxPoolin  (None, 36, 36, 128)       0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_2 (Conv2D)           (None, 34, 34, 128)       147584    \n",
            "                                                                 \n",
            " max_pooling2d_2 (MaxPoolin  (None, 17, 17, 128)       0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_3 (Conv2D)           (None, 15, 15, 128)       147584    \n",
            "                                                                 \n",
            " max_pooling2d_3 (MaxPoolin  (None, 7, 7, 128)         0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 6272)              0         \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 6272)              0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 256)               1605888   \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 3)                 771       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 2052995 (7.83 MB)\n",
            "Trainable params: 2052995 (7.83 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# #callbacks\n",
        "# # callback = myCallback()\n",
        "# MCP = tf.keras.callbacks.ModelCheckpoint(filepath='bestmodel.h5',monitor='val_accuracy', mode='auto', save_best_only=True, save_weights_only=False, verbose=1)\n",
        "# RLP = tf.keras.callbacks.ReduceLROnPlateau(monitor=\"val_accuracy\",factor=0.1,patience=3, verbose=1,mode=\"auto\",min_lr=0.000000001)\n",
        "# ES = tf.keras.callbacks.EarlyStopping(monitor='val_accuracy',min_delta=1e-4,patience=5,verbose=1,start_from_epoch=5)\n",
        "\n",
        "\n",
        "# #Train and compile model\n",
        "# lr = 0.0001 #1e-5\n",
        "# optimizer = tf.keras.optimizers.Adam(learning_rate=lr, clipnorm=1) #, clipnorm=1\n",
        "# model.compile(optimizer=optimizer,loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# tf.keras.backend.clear_session()\n",
        "# history = model.fit(train_generator, validation_data=validation_generator, epochs=100, callbacks=[MCP, RLP, ES]) #ES, callback\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cYPZMLc0fnD2",
        "outputId": "1994f4c8-9013-4dc7-d40a-e839160c88bb"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "126/126 [==============================] - ETA: 0s - loss: 1.0763 - accuracy: 0.4032\n",
            "Epoch 1: val_accuracy improved from -inf to 0.59140, saving model to bestmodel.h5\n",
            "126/126 [==============================] - 25s 165ms/step - loss: 1.0763 - accuracy: 0.4032 - val_loss: 0.8972 - val_accuracy: 0.5914 - lr: 1.0000e-04\n",
            "Epoch 2/100\n",
            "126/126 [==============================] - ETA: 0s - loss: 0.8390 - accuracy: 0.6139\n",
            "Epoch 2: val_accuracy improved from 0.59140 to 0.76075, saving model to bestmodel.h5\n",
            "126/126 [==============================] - 20s 161ms/step - loss: 0.8390 - accuracy: 0.6139 - val_loss: 0.5013 - val_accuracy: 0.7608 - lr: 1.0000e-04\n",
            "Epoch 3/100\n",
            "126/126 [==============================] - ETA: 0s - loss: 0.6191 - accuracy: 0.7393\n",
            "Epoch 3: val_accuracy improved from 0.76075 to 0.98118, saving model to bestmodel.h5\n",
            "126/126 [==============================] - 20s 161ms/step - loss: 0.6191 - accuracy: 0.7393 - val_loss: 0.1970 - val_accuracy: 0.9812 - lr: 1.0000e-04\n",
            "Epoch 4/100\n",
            "126/126 [==============================] - ETA: 0s - loss: 0.4184 - accuracy: 0.8468\n",
            "Epoch 4: val_accuracy did not improve from 0.98118\n",
            "126/126 [==============================] - 20s 160ms/step - loss: 0.4184 - accuracy: 0.8468 - val_loss: 0.1522 - val_accuracy: 0.9516 - lr: 1.0000e-04\n",
            "Epoch 5/100\n",
            "126/126 [==============================] - ETA: 0s - loss: 0.3746 - accuracy: 0.8567\n",
            "Epoch 5: val_accuracy did not improve from 0.98118\n",
            "126/126 [==============================] - 20s 160ms/step - loss: 0.3746 - accuracy: 0.8567 - val_loss: 0.1001 - val_accuracy: 0.9731 - lr: 1.0000e-04\n",
            "Epoch 6/100\n",
            "126/126 [==============================] - ETA: 0s - loss: 0.3117 - accuracy: 0.8770\n",
            "Epoch 6: val_accuracy did not improve from 0.98118\n",
            "\n",
            "Epoch 6: ReduceLROnPlateau reducing learning rate to 9.999999747378752e-06.\n",
            "126/126 [==============================] - 20s 160ms/step - loss: 0.3117 - accuracy: 0.8770 - val_loss: 0.1553 - val_accuracy: 0.9489 - lr: 1.0000e-04\n",
            "Epoch 7/100\n",
            "126/126 [==============================] - ETA: 0s - loss: 0.2385 - accuracy: 0.9190\n",
            "Epoch 7: val_accuracy did not improve from 0.98118\n",
            "126/126 [==============================] - 20s 160ms/step - loss: 0.2385 - accuracy: 0.9190 - val_loss: 0.0750 - val_accuracy: 0.9651 - lr: 1.0000e-05\n",
            "Epoch 8/100\n",
            "126/126 [==============================] - ETA: 0s - loss: 0.2363 - accuracy: 0.9183\n",
            "Epoch 8: val_accuracy did not improve from 0.98118\n",
            "126/126 [==============================] - 20s 160ms/step - loss: 0.2363 - accuracy: 0.9183 - val_loss: 0.0757 - val_accuracy: 0.9624 - lr: 1.0000e-05\n",
            "Epoch 9/100\n",
            "126/126 [==============================] - ETA: 0s - loss: 0.2108 - accuracy: 0.9242\n",
            "Epoch 9: val_accuracy did not improve from 0.98118\n",
            "\n",
            "Epoch 9: ReduceLROnPlateau reducing learning rate to 9.999999747378752e-07.\n",
            "126/126 [==============================] - 20s 161ms/step - loss: 0.2108 - accuracy: 0.9242 - val_loss: 0.1106 - val_accuracy: 0.9543 - lr: 1.0000e-05\n",
            "Epoch 10/100\n",
            "126/126 [==============================] - ETA: 0s - loss: 0.2185 - accuracy: 0.9234\n",
            "Epoch 10: val_accuracy did not improve from 0.98118\n",
            "126/126 [==============================] - 20s 161ms/step - loss: 0.2185 - accuracy: 0.9234 - val_loss: 0.0973 - val_accuracy: 0.9597 - lr: 1.0000e-06\n",
            "Epoch 11/100\n",
            "126/126 [==============================] - ETA: 0s - loss: 0.2045 - accuracy: 0.9349\n",
            "Epoch 11: val_accuracy did not improve from 0.98118\n",
            "126/126 [==============================] - 20s 160ms/step - loss: 0.2045 - accuracy: 0.9349 - val_loss: 0.0985 - val_accuracy: 0.9570 - lr: 1.0000e-06\n",
            "Epoch 12/100\n",
            "126/126 [==============================] - ETA: 0s - loss: 0.1964 - accuracy: 0.9313\n",
            "Epoch 12: val_accuracy did not improve from 0.98118\n",
            "\n",
            "Epoch 12: ReduceLROnPlateau reducing learning rate to 9.999999974752428e-08.\n",
            "126/126 [==============================] - 20s 159ms/step - loss: 0.1964 - accuracy: 0.9313 - val_loss: 0.0937 - val_accuracy: 0.9597 - lr: 1.0000e-06\n",
            "Epoch 12: early stopping\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# model.save(\"mymodel.h5\")"
      ],
      "metadata": {
        "id": "eMD69fWKlx2y"
      },
      "execution_count": 13,
      "outputs": []
    }
  ]
}