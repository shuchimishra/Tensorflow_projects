{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "L4",
      "authorship_tag": "ABX9TyOkwbvSET+7p/CI5OAH+qX8",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/shuchimishra/Tensorflow_projects/blob/main/Tensorflow_Code/Intro_to_ANN/exam/Category2_fashion_mnist.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zIzW12CKbZrL",
        "outputId": "d65262d3-0c7c-44bd-dfcd-13ed06c2f07b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_12\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_24 (Conv2D)          (None, 26, 26, 64)        640       \n",
            "                                                                 \n",
            " max_pooling2d_24 (MaxPooli  (None, 13, 13, 64)        0         \n",
            " ng2D)                                                           \n",
            "                                                                 \n",
            " conv2d_25 (Conv2D)          (None, 11, 11, 128)       73856     \n",
            "                                                                 \n",
            " max_pooling2d_25 (MaxPooli  (None, 5, 5, 128)         0         \n",
            " ng2D)                                                           \n",
            "                                                                 \n",
            " dropout_11 (Dropout)        (None, 5, 5, 128)         0         \n",
            "                                                                 \n",
            " flatten_12 (Flatten)        (None, 3200)              0         \n",
            "                                                                 \n",
            " dense_24 (Dense)            (None, 512)               1638912   \n",
            "                                                                 \n",
            " dense_25 (Dense)            (None, 10)                5130      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1718538 (6.56 MB)\n",
            "Trainable params: 1718538 (6.56 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "Epoch 1/50\n",
            "  2/118 [..............................] - ETA: 1:21 - loss: 2.2429 - accuracy: 0.1406"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0063s vs `on_train_batch_end` time: 0.1196s). Check your callbacks.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "118/118 [==============================] - ETA: 0s - loss: 0.7660 - accuracy: 0.7191\n",
            "Epoch 1: val_accuracy improved from -inf to 0.79190, saving model to bestmodel.h5\n",
            "118/118 [==============================] - 9s 43ms/step - loss: 0.7660 - accuracy: 0.7191 - val_loss: 0.5737 - val_accuracy: 0.7919 - lr: 0.0010\n",
            "Epoch 2/50\n",
            "117/118 [============================>.] - ETA: 0s - loss: 0.4813 - accuracy: 0.8216\n",
            "Epoch 2: val_accuracy improved from 0.79190 to 0.81110, saving model to bestmodel.h5\n",
            "118/118 [==============================] - 2s 21ms/step - loss: 0.4812 - accuracy: 0.8216 - val_loss: 0.4770 - val_accuracy: 0.8111 - lr: 0.0010\n",
            "Epoch 3/50\n",
            "114/118 [===========================>..] - ETA: 0s - loss: 0.4176 - accuracy: 0.8457\n",
            "Epoch 3: val_accuracy improved from 0.81110 to 0.83850, saving model to bestmodel.h5\n",
            "118/118 [==============================] - 3s 22ms/step - loss: 0.4166 - accuracy: 0.8462 - val_loss: 0.4282 - val_accuracy: 0.8385 - lr: 0.0010\n",
            "Epoch 4/50\n",
            "118/118 [==============================] - ETA: 0s - loss: 0.3794 - accuracy: 0.8587\n",
            "Epoch 4: val_accuracy improved from 0.83850 to 0.85340, saving model to bestmodel.h5\n",
            "118/118 [==============================] - 2s 20ms/step - loss: 0.3794 - accuracy: 0.8587 - val_loss: 0.3820 - val_accuracy: 0.8534 - lr: 0.0010\n",
            "Epoch 5/50\n",
            "117/118 [============================>.] - ETA: 0s - loss: 0.3496 - accuracy: 0.8711\n",
            "Epoch 5: val_accuracy did not improve from 0.85340\n",
            "118/118 [==============================] - 2s 19ms/step - loss: 0.3498 - accuracy: 0.8711 - val_loss: 0.4176 - val_accuracy: 0.8367 - lr: 0.0010\n",
            "Epoch 6/50\n",
            "116/118 [============================>.] - ETA: 0s - loss: 0.3342 - accuracy: 0.8759\n",
            "Epoch 6: val_accuracy did not improve from 0.85340\n",
            "118/118 [==============================] - 2s 13ms/step - loss: 0.3344 - accuracy: 0.8761 - val_loss: 0.4259 - val_accuracy: 0.8263 - lr: 0.0010\n",
            "Epoch 7/50\n",
            "113/118 [===========================>..] - ETA: 0s - loss: 0.3167 - accuracy: 0.8823\n",
            "Epoch 7: val_accuracy improved from 0.85340 to 0.88210, saving model to bestmodel.h5\n",
            "118/118 [==============================] - 3s 26ms/step - loss: 0.3169 - accuracy: 0.8823 - val_loss: 0.3232 - val_accuracy: 0.8821 - lr: 0.0010\n",
            "Epoch 8/50\n",
            "118/118 [==============================] - ETA: 0s - loss: 0.3004 - accuracy: 0.8870\n",
            "Epoch 8: val_accuracy improved from 0.88210 to 0.89320, saving model to bestmodel.h5\n",
            "118/118 [==============================] - 3s 28ms/step - loss: 0.3004 - accuracy: 0.8870 - val_loss: 0.2909 - val_accuracy: 0.8932 - lr: 0.0010\n",
            "Epoch 9/50\n",
            "118/118 [==============================] - ETA: 0s - loss: 0.2913 - accuracy: 0.8921\n",
            "Epoch 9: val_accuracy did not improve from 0.89320\n",
            "118/118 [==============================] - 2s 20ms/step - loss: 0.2913 - accuracy: 0.8921 - val_loss: 0.2903 - val_accuracy: 0.8924 - lr: 0.0010\n",
            "Epoch 10/50\n",
            "113/118 [===========================>..] - ETA: 0s - loss: 0.2809 - accuracy: 0.8958\n",
            "Epoch 10: val_accuracy improved from 0.89320 to 0.89480, saving model to bestmodel.h5\n",
            "118/118 [==============================] - 2s 15ms/step - loss: 0.2810 - accuracy: 0.8957 - val_loss: 0.2851 - val_accuracy: 0.8948 - lr: 0.0010\n",
            "Epoch 11/50\n",
            "114/118 [===========================>..] - ETA: 0s - loss: 0.2742 - accuracy: 0.8975\n",
            "Epoch 11: val_accuracy improved from 0.89480 to 0.89960, saving model to bestmodel.h5\n",
            "118/118 [==============================] - 3s 29ms/step - loss: 0.2729 - accuracy: 0.8980 - val_loss: 0.2733 - val_accuracy: 0.8996 - lr: 0.0010\n",
            "Epoch 12/50\n",
            "117/118 [============================>.] - ETA: 0s - loss: 0.2650 - accuracy: 0.9013\n",
            "Epoch 12: val_accuracy did not improve from 0.89960\n",
            "118/118 [==============================] - 2s 19ms/step - loss: 0.2650 - accuracy: 0.9012 - val_loss: 0.2891 - val_accuracy: 0.8953 - lr: 0.0010\n",
            "Epoch 13/50\n",
            "117/118 [============================>.] - ETA: 0s - loss: 0.2613 - accuracy: 0.9009\n",
            "Epoch 13: val_accuracy improved from 0.89960 to 0.90950, saving model to bestmodel.h5\n",
            "118/118 [==============================] - 3s 28ms/step - loss: 0.2613 - accuracy: 0.9009 - val_loss: 0.2534 - val_accuracy: 0.9095 - lr: 0.0010\n",
            "Epoch 14/50\n",
            "114/118 [===========================>..] - ETA: 0s - loss: 0.2529 - accuracy: 0.9051\n",
            "Epoch 14: val_accuracy did not improve from 0.90950\n",
            "118/118 [==============================] - 3s 25ms/step - loss: 0.2522 - accuracy: 0.9052 - val_loss: 0.2686 - val_accuracy: 0.9030 - lr: 0.0010\n",
            "Epoch 15/50\n",
            "114/118 [===========================>..] - ETA: 0s - loss: 0.2475 - accuracy: 0.9068\n",
            "Epoch 15: val_accuracy did not improve from 0.90950\n",
            "118/118 [==============================] - 3s 26ms/step - loss: 0.2477 - accuracy: 0.9069 - val_loss: 0.2647 - val_accuracy: 0.9039 - lr: 0.0010\n",
            "Epoch 16/50\n",
            "113/118 [===========================>..] - ETA: 0s - loss: 0.2416 - accuracy: 0.9094\n",
            "Epoch 16: val_accuracy did not improve from 0.90950\n",
            "118/118 [==============================] - 3s 26ms/step - loss: 0.2422 - accuracy: 0.9092 - val_loss: 0.2586 - val_accuracy: 0.9017 - lr: 0.0010\n",
            "Epoch 17/50\n",
            "114/118 [===========================>..] - ETA: 0s - loss: 0.2350 - accuracy: 0.9109\n",
            "Epoch 17: val_accuracy did not improve from 0.90950\n",
            "118/118 [==============================] - 4s 33ms/step - loss: 0.2359 - accuracy: 0.9107 - val_loss: 0.2856 - val_accuracy: 0.8888 - lr: 0.0010\n",
            "Epoch 18/50\n",
            "118/118 [==============================] - ETA: 0s - loss: 0.2302 - accuracy: 0.9136\n",
            "Epoch 18: val_accuracy improved from 0.90950 to 0.91130, saving model to bestmodel.h5\n",
            "118/118 [==============================] - 3s 22ms/step - loss: 0.2302 - accuracy: 0.9136 - val_loss: 0.2499 - val_accuracy: 0.9113 - lr: 0.0010\n",
            "Epoch 19/50\n",
            "117/118 [============================>.] - ETA: 0s - loss: 0.2255 - accuracy: 0.9145\n",
            "Epoch 19: val_accuracy improved from 0.91130 to 0.91140, saving model to bestmodel.h5\n",
            "118/118 [==============================] - 2s 15ms/step - loss: 0.2256 - accuracy: 0.9144 - val_loss: 0.2412 - val_accuracy: 0.9114 - lr: 0.0010\n",
            "Epoch 20/50\n",
            "113/118 [===========================>..] - ETA: 0s - loss: 0.2198 - accuracy: 0.9169\n",
            "Epoch 20: val_accuracy did not improve from 0.91140\n",
            "118/118 [==============================] - 2s 21ms/step - loss: 0.2193 - accuracy: 0.9171 - val_loss: 0.2422 - val_accuracy: 0.9111 - lr: 0.0010\n",
            "Epoch 21/50\n",
            "113/118 [===========================>..] - ETA: 0s - loss: 0.2163 - accuracy: 0.9178\n",
            "Epoch 21: val_accuracy improved from 0.91140 to 0.91160, saving model to bestmodel.h5\n",
            "118/118 [==============================] - 2s 20ms/step - loss: 0.2167 - accuracy: 0.9176 - val_loss: 0.2415 - val_accuracy: 0.9116 - lr: 0.0010\n",
            "Epoch 22/50\n",
            "118/118 [==============================] - ETA: 0s - loss: 0.2124 - accuracy: 0.9193\n",
            "Epoch 22: val_accuracy improved from 0.91160 to 0.91290, saving model to bestmodel.h5\n",
            "118/118 [==============================] - 3s 27ms/step - loss: 0.2124 - accuracy: 0.9193 - val_loss: 0.2370 - val_accuracy: 0.9129 - lr: 0.0010\n",
            "Epoch 23/50\n",
            "118/118 [==============================] - ETA: 0s - loss: 0.2082 - accuracy: 0.9222\n",
            "Epoch 23: val_accuracy improved from 0.91290 to 0.91420, saving model to bestmodel.h5\n",
            "118/118 [==============================] - 2s 20ms/step - loss: 0.2082 - accuracy: 0.9222 - val_loss: 0.2343 - val_accuracy: 0.9142 - lr: 0.0010\n",
            "Epoch 24/50\n",
            "113/118 [===========================>..] - ETA: 0s - loss: 0.2013 - accuracy: 0.9243\n",
            "Epoch 24: val_accuracy did not improve from 0.91420\n",
            "118/118 [==============================] - 2s 14ms/step - loss: 0.2023 - accuracy: 0.9241 - val_loss: 0.2457 - val_accuracy: 0.9091 - lr: 0.0010\n",
            "Epoch 25/50\n",
            "117/118 [============================>.] - ETA: 0s - loss: 0.2014 - accuracy: 0.9239\n",
            "Epoch 25: val_accuracy improved from 0.91420 to 0.91920, saving model to bestmodel.h5\n",
            "118/118 [==============================] - 3s 21ms/step - loss: 0.2014 - accuracy: 0.9238 - val_loss: 0.2244 - val_accuracy: 0.9192 - lr: 0.0010\n",
            "Epoch 26/50\n",
            "114/118 [===========================>..] - ETA: 0s - loss: 0.1962 - accuracy: 0.9266\n",
            "Epoch 26: val_accuracy did not improve from 0.91920\n",
            "118/118 [==============================] - 2s 21ms/step - loss: 0.1967 - accuracy: 0.9263 - val_loss: 0.2247 - val_accuracy: 0.9173 - lr: 0.0010\n",
            "Epoch 27/50\n",
            "113/118 [===========================>..] - ETA: 0s - loss: 0.1950 - accuracy: 0.9267\n",
            "Epoch 27: val_accuracy did not improve from 0.91920\n",
            "118/118 [==============================] - 2s 19ms/step - loss: 0.1947 - accuracy: 0.9268 - val_loss: 0.2232 - val_accuracy: 0.9184 - lr: 0.0010\n",
            "Epoch 28/50\n",
            "113/118 [===========================>..] - ETA: 0s - loss: 0.1915 - accuracy: 0.9284\n",
            "Epoch 28: val_accuracy did not improve from 0.91920\n",
            "118/118 [==============================] - 2s 21ms/step - loss: 0.1913 - accuracy: 0.9284 - val_loss: 0.2227 - val_accuracy: 0.9181 - lr: 0.0010\n",
            "Epoch 29/50\n",
            "114/118 [===========================>..] - ETA: 0s - loss: 0.1866 - accuracy: 0.9296\n",
            "Epoch 29: val_accuracy did not improve from 0.91920\n",
            "118/118 [==============================] - 3s 27ms/step - loss: 0.1868 - accuracy: 0.9294 - val_loss: 0.2266 - val_accuracy: 0.9177 - lr: 0.0010\n",
            "Epoch 30/50\n",
            "113/118 [===========================>..] - ETA: 0s - loss: 0.1843 - accuracy: 0.9307\n",
            "Epoch 30: val_accuracy did not improve from 0.91920\n",
            "\n",
            "Epoch 30: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
            "118/118 [==============================] - 2s 21ms/step - loss: 0.1850 - accuracy: 0.9304 - val_loss: 0.2265 - val_accuracy: 0.9146 - lr: 0.0010\n",
            "Epoch 31/50\n",
            "116/118 [============================>.] - ETA: 0s - loss: 0.1668 - accuracy: 0.9370\n",
            "Epoch 31: val_accuracy improved from 0.91920 to 0.92340, saving model to bestmodel.h5\n",
            "118/118 [==============================] - 2s 15ms/step - loss: 0.1669 - accuracy: 0.9369 - val_loss: 0.2123 - val_accuracy: 0.9234 - lr: 1.0000e-04\n",
            "Epoch 32/50\n",
            "116/118 [============================>.] - ETA: 0s - loss: 0.1607 - accuracy: 0.9390\n",
            "Epoch 32: val_accuracy improved from 0.92340 to 0.92360, saving model to bestmodel.h5\n",
            "118/118 [==============================] - 2s 21ms/step - loss: 0.1608 - accuracy: 0.9390 - val_loss: 0.2092 - val_accuracy: 0.9236 - lr: 1.0000e-04\n",
            "Epoch 33/50\n",
            "115/118 [============================>.] - ETA: 0s - loss: 0.1595 - accuracy: 0.9399\n",
            "Epoch 33: val_accuracy improved from 0.92360 to 0.92410, saving model to bestmodel.h5\n",
            "118/118 [==============================] - 3s 27ms/step - loss: 0.1591 - accuracy: 0.9402 - val_loss: 0.2074 - val_accuracy: 0.9241 - lr: 1.0000e-04\n",
            "Epoch 34/50\n",
            "117/118 [============================>.] - ETA: 0s - loss: 0.1563 - accuracy: 0.9413\n",
            "Epoch 34: val_accuracy improved from 0.92410 to 0.92540, saving model to bestmodel.h5\n",
            "118/118 [==============================] - 2s 14ms/step - loss: 0.1564 - accuracy: 0.9413 - val_loss: 0.2065 - val_accuracy: 0.9254 - lr: 1.0000e-04\n",
            "Epoch 35/50\n",
            "116/118 [============================>.] - ETA: 0s - loss: 0.1580 - accuracy: 0.9411\n",
            "Epoch 35: val_accuracy improved from 0.92540 to 0.92560, saving model to bestmodel.h5\n",
            "118/118 [==============================] - 5s 44ms/step - loss: 0.1582 - accuracy: 0.9410 - val_loss: 0.2064 - val_accuracy: 0.9256 - lr: 1.0000e-04\n",
            "Epoch 36/50\n",
            "113/118 [===========================>..] - ETA: 0s - loss: 0.1556 - accuracy: 0.9416\n",
            "Epoch 36: val_accuracy improved from 0.92560 to 0.92570, saving model to bestmodel.h5\n",
            "118/118 [==============================] - 2s 21ms/step - loss: 0.1558 - accuracy: 0.9414 - val_loss: 0.2058 - val_accuracy: 0.9257 - lr: 1.0000e-04\n",
            "Epoch 37/50\n",
            "114/118 [===========================>..] - ETA: 0s - loss: 0.1550 - accuracy: 0.9426\n",
            "Epoch 37: val_accuracy improved from 0.92570 to 0.92700, saving model to bestmodel.h5\n",
            "118/118 [==============================] - 3s 25ms/step - loss: 0.1546 - accuracy: 0.9429 - val_loss: 0.2052 - val_accuracy: 0.9270 - lr: 1.0000e-04\n",
            "Epoch 38/50\n",
            "117/118 [============================>.] - ETA: 0s - loss: 0.1559 - accuracy: 0.9409\n",
            "Epoch 38: val_accuracy did not improve from 0.92700\n",
            "118/118 [==============================] - 2s 14ms/step - loss: 0.1558 - accuracy: 0.9409 - val_loss: 0.2057 - val_accuracy: 0.9259 - lr: 1.0000e-04\n",
            "Epoch 39/50\n",
            "114/118 [===========================>..] - ETA: 0s - loss: 0.1523 - accuracy: 0.9423\n",
            "Epoch 39: val_accuracy did not improve from 0.92700\n",
            "118/118 [==============================] - 3s 22ms/step - loss: 0.1524 - accuracy: 0.9422 - val_loss: 0.2064 - val_accuracy: 0.9255 - lr: 1.0000e-04\n",
            "Epoch 40/50\n",
            "118/118 [==============================] - ETA: 0s - loss: 0.1530 - accuracy: 0.9425\n",
            "Epoch 40: val_accuracy did not improve from 0.92700\n",
            "118/118 [==============================] - 2s 21ms/step - loss: 0.1530 - accuracy: 0.9425 - val_loss: 0.2059 - val_accuracy: 0.9262 - lr: 1.0000e-04\n",
            "Epoch 41/50\n",
            "113/118 [===========================>..] - ETA: 0s - loss: 0.1516 - accuracy: 0.9428\n",
            "Epoch 41: val_accuracy improved from 0.92700 to 0.92710, saving model to bestmodel.h5\n",
            "118/118 [==============================] - 2s 21ms/step - loss: 0.1518 - accuracy: 0.9427 - val_loss: 0.2043 - val_accuracy: 0.9271 - lr: 1.0000e-04\n",
            "Epoch 42/50\n",
            "113/118 [===========================>..] - ETA: 0s - loss: 0.1528 - accuracy: 0.9431\n",
            "Epoch 42: val_accuracy did not improve from 0.92710\n",
            "118/118 [==============================] - 2s 19ms/step - loss: 0.1528 - accuracy: 0.9430 - val_loss: 0.2046 - val_accuracy: 0.9271 - lr: 1.0000e-04\n",
            "Epoch 43/50\n",
            "114/118 [===========================>..] - ETA: 0s - loss: 0.1511 - accuracy: 0.9435\n",
            "Epoch 43: val_accuracy did not improve from 0.92710\n",
            "118/118 [==============================] - 3s 28ms/step - loss: 0.1508 - accuracy: 0.9437 - val_loss: 0.2046 - val_accuracy: 0.9270 - lr: 1.0000e-04\n",
            "Epoch 44/50\n",
            "117/118 [============================>.] - ETA: 0s - loss: 0.1495 - accuracy: 0.9440\n",
            "Epoch 44: val_accuracy improved from 0.92710 to 0.92790, saving model to bestmodel.h5\n",
            "118/118 [==============================] - 2s 14ms/step - loss: 0.1496 - accuracy: 0.9440 - val_loss: 0.2048 - val_accuracy: 0.9279 - lr: 1.0000e-04\n",
            "Epoch 45/50\n",
            "114/118 [===========================>..] - ETA: 0s - loss: 0.1495 - accuracy: 0.9437\n",
            "Epoch 45: val_accuracy improved from 0.92790 to 0.92810, saving model to bestmodel.h5\n",
            "118/118 [==============================] - 3s 22ms/step - loss: 0.1490 - accuracy: 0.9440 - val_loss: 0.2038 - val_accuracy: 0.9281 - lr: 1.0000e-04\n",
            "Epoch 46/50\n",
            "117/118 [============================>.] - ETA: 0s - loss: 0.1474 - accuracy: 0.9458\n",
            "Epoch 46: val_accuracy did not improve from 0.92810\n",
            "118/118 [==============================] - 2s 20ms/step - loss: 0.1475 - accuracy: 0.9458 - val_loss: 0.2040 - val_accuracy: 0.9279 - lr: 1.0000e-04\n",
            "Epoch 47/50\n",
            "118/118 [==============================] - ETA: 0s - loss: 0.1479 - accuracy: 0.9458\n",
            "Epoch 47: val_accuracy did not improve from 0.92810\n",
            "118/118 [==============================] - 2s 19ms/step - loss: 0.1479 - accuracy: 0.9458 - val_loss: 0.2038 - val_accuracy: 0.9264 - lr: 1.0000e-04\n",
            "Epoch 48/50\n",
            "114/118 [===========================>..] - ETA: 0s - loss: 0.1465 - accuracy: 0.9446\n",
            "Epoch 48: val_accuracy did not improve from 0.92810\n",
            "118/118 [==============================] - 3s 28ms/step - loss: 0.1469 - accuracy: 0.9446 - val_loss: 0.2074 - val_accuracy: 0.9250 - lr: 1.0000e-04\n",
            "Epoch 49/50\n",
            "117/118 [============================>.] - ETA: 0s - loss: 0.1480 - accuracy: 0.9445\n",
            "Epoch 49: val_accuracy did not improve from 0.92810\n",
            "118/118 [==============================] - 2s 20ms/step - loss: 0.1479 - accuracy: 0.9445 - val_loss: 0.2041 - val_accuracy: 0.9275 - lr: 1.0000e-04\n",
            "Epoch 50/50\n",
            "117/118 [============================>.] - ETA: 0s - loss: 0.1467 - accuracy: 0.9451\n",
            "Epoch 50: val_accuracy did not improve from 0.92810\n",
            "\n",
            "Epoch 50: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
            "118/118 [==============================] - 3s 22ms/step - loss: 0.1467 - accuracy: 0.9450 - val_loss: 0.2041 - val_accuracy: 0.9279 - lr: 1.0000e-04\n",
            "313/313 [==============================] - 2s 6ms/step - loss: 0.2041 - accuracy: 0.9279\n"
          ]
        }
      ],
      "source": [
        "# ======================================================================\n",
        "# There are 5 questions in this exam with increasing difficulty from 1-5.\n",
        "# Please note that the weight of the grade for the question is relative\n",
        "# to its difficulty. So your Category 1 question will score significantly\n",
        "# less than your Category 5 question.\n",
        "#\n",
        "# Don't use lambda layers in your model.\n",
        "# You do not need them to solve the question.\n",
        "# Lambda layers are not supported by the grading infrastructure.\n",
        "#\n",
        "# You must use the Submit and Test button to submit your model\n",
        "# at least once in this category before you finally submit your exam,\n",
        "# otherwise you will score zero for this category.\n",
        "# ======================================================================\n",
        "#\n",
        "# Basic Datasets Question\n",
        "#\n",
        "# Create a classifier for the Fashion MNIST dataset\n",
        "# Note that the test will expect it to classify 10 classes and that the\n",
        "# input shape should be the native size of the Fashion MNIST dataset which is\n",
        "# 28x28 monochrome. Do not resize the data. Your input layer should accept\n",
        "# (28,28) as the input shape only. If you amend this, the tests will fail.\n",
        "#\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.optimizers import RMSprop\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "physical_devices = tf.config.list_physical_devices('GPU')\n",
        "try:\n",
        "    tf.config.experimental.set_memory_growth(physical_devices[0], True)\n",
        "except:\n",
        "    pass\n",
        "\n",
        "class myCallBack(keras.callbacks.Callback):\n",
        "  def on_epoch_end(self, epoch, logs={}):\n",
        "    if (logs['val_accuracy'] > 0.99):\n",
        "      print(\"Cancelling training since accuracy reached 99%\")\n",
        "      self.model.stop_training=True\n",
        "\n",
        "def solution_model():\n",
        "\n",
        "  #Load datasets\n",
        "  fmnist = keras.datasets.fashion_mnist\n",
        "  (train_images,train_labels),(test_images,test_labels) = fmnist.load_data()\n",
        "\n",
        "  #number of classes\n",
        "  n_classes = len(set(train_labels))\n",
        "\n",
        "  #normalize image\n",
        "  train_images = train_images/255\n",
        "  test_images = test_images/255\n",
        "\n",
        "  #callbacks\n",
        "  callback = myCallBack()\n",
        "  MCP = keras.callbacks.ModelCheckpoint(filepath='bestmodel.h5',monitor='val_accuracy',\n",
        "                                        mode='auto',save_best_only=True,save_weights_only=False,verbose=1)\n",
        "  RLP = keras.callbacks.ReduceLROnPlateau(monitor=\"val_accuracy\",factor=0.1,patience=5,\n",
        "                                          verbose=1,mode=\"auto\",min_lr=0.000000001)\n",
        "  # ES = keras.callbacks.EarlyStopping(monitor='val_accuracy',min_delta=1e-4,patience=5,verbose=1)\n",
        "\n",
        "  # model = keras.models.Sequential()\n",
        "  # model.add(keras.layers.Flatten())\n",
        "  # model.add(keras.layers.Dense(64, activation='relu'))\n",
        "  # model.add(keras.layers.Dropout(0.2))\n",
        "  # model.add(keras.layers.Dense(n_classes, activation='softmax'))\n",
        "\n",
        "  model = keras.models.Sequential([\n",
        "      keras.layers.Conv2D(64, (3,3), activation='relu',input_shape=(28,28,1)),\n",
        "      keras.layers.MaxPooling2D((2,2)),\n",
        "      keras.layers.Conv2D(128, (3,3), activation='relu'),\n",
        "      keras.layers.MaxPooling2D((2,2)),\n",
        "      keras.layers.Dropout(0.7),\n",
        "      keras.layers.Flatten(),\n",
        "      keras.layers.Dense(512, activation='relu'),\n",
        "      keras.layers.Dense(n_classes, activation='softmax')])\n",
        "\n",
        "  model.summary()\n",
        "\n",
        "  model.compile(optimizer='RMSprop',\n",
        "                 loss='sparse_categorical_crossentropy',\n",
        "                 metrics='accuracy')\n",
        "\n",
        "  # model.fit(train_images, train_labels, epochs=50, validation_data=(test_images, test_labels),\n",
        "  #           callbacks=[callback,MCP,RLP,ES], verbose=1)\n",
        "\n",
        "  model.fit(\n",
        "        train_images, train_labels,\n",
        "        batch_size=512,\n",
        "        epochs=50,\n",
        "        verbose=1,\n",
        "        validation_data=(test_images, test_labels),\n",
        "        callbacks=[callback,MCP,RLP] #RLP,ES\n",
        "    )\n",
        "\n",
        "  # model.summary()\n",
        "  #Evaluate against test images\n",
        "  model.evaluate(test_images, test_labels)\n",
        "\n",
        "   # YOUR CODE HERE\n",
        "  return model\n",
        "\n",
        "\n",
        "# Note that you'll need to save your model as a .h5 like this.\n",
        "# When you press the Submit and Test button, your saved .h5 model will\n",
        "# be sent to the testing infrastructure for scoring\n",
        "# and the score will be returned to you.\n",
        "if __name__ == '__main__':\n",
        "    model = solution_model()\n",
        "\n",
        "\n",
        "\n",
        "    model.save(\"mymodel.h5\")\n"
      ]
    }
  ]
}