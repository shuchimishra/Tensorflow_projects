{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/shuchimishra/Tensorflow_projects/blob/main/Tensorflow_Code/NLP/Sarcasm_w_GRU_LSTM_Conv1D_%26_KerasTuner.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YEdilk144fzb"
      },
      "source": [
        "# **# Training a Sarcasm Detection Model using a Convolution Layer**\n",
        "\n",
        "You will be doing the same steps here as the previous lab but will be using a convolution layer instead. As usual, try tweaking the parameters and observe how it affects the results.\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Install keras-tuner library; uncomment if necessary\n",
        "!pip install keras-tuner -q"
      ],
      "metadata": {
        "id": "13iZFsweFVRA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from keras.optimizers import RMSprop, SGD, Adam\n",
        "import keras_tuner\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "import matplotlib.pyplot as plt\n",
        "import urllib"
      ],
      "metadata": {
        "id": "mXQ1PP10ehgH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Helper Functions**"
      ],
      "metadata": {
        "id": "GEzFsmqPHg2j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "%matplotlib inline\n",
        "%config InlineBackend.fugure_format = 'retina'\n",
        "def plot_loss_acc(history):\n",
        "  #-----------------------------------------------------------\n",
        "  # Retrieve a list of list results on training and test data\n",
        "  # sets for each training epoch\n",
        "  #-----------------------------------------------------------\n",
        "  acc      = history.history[     'accuracy' ]\n",
        "  val_acc  = history.history[ 'val_accuracy' ]\n",
        "  loss     = history.history[    'loss' ]\n",
        "  val_loss = history.history['val_loss' ]\n",
        "  epochs   = range(len(acc)) # Get number of epochs\n",
        "  #------------------------------------------------\n",
        "  # Plot training and validation accuracy per epoch\n",
        "  #------------------------------------------------\n",
        "  plt.plot  ( epochs,     acc, label='Training accuracy' )\n",
        "  plt.plot  ( epochs, val_acc, label='Validation accuracy' )\n",
        "  plt.title ('Training and validation accuracy')\n",
        "  plt.grid()\n",
        "  plt.legend()\n",
        "  plt.xlabel(\"Epochs\")\n",
        "  plt.ylabel(\"Accuracy\")\n",
        "  plt.figure()\n",
        "  #------------------------------------------------\n",
        "  # Plot training and validation loss per epoch\n",
        "  #------------------------------------------------\n",
        "  plt.plot  ( epochs,     loss, label='Training loss' )\n",
        "  plt.plot  ( epochs, val_loss, label='Validation loss' )\n",
        "  plt.grid()\n",
        "  plt.legend()\n",
        "  plt.xlabel(\"Epochs\")\n",
        "  plt.ylabel(\"Loss\")\n",
        "  plt.title ('Training and validation loss'   )"
      ],
      "metadata": {
        "id": "TV0ZKq4eFeYM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pmokcpHc5u1R"
      },
      "source": [
        "# **Download the Dataset**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dxezdGoV29Yz"
      },
      "outputs": [],
      "source": [
        "# # Download the dataset\n",
        "# !wget https://storage.googleapis.com/tensorflow-1-public/course3/sarcasm.json"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Download the dataset\n",
        "url = 'https://storage.googleapis.com/download.tensorflow.org/data/sarcasm.json'\n",
        "urllib.request.urlretrieve(url, 'sarcasm.json')"
      ],
      "metadata": {
        "id": "HIsoQjxlVfCm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Parsing Sentences and Labels**"
      ],
      "metadata": {
        "id": "wDpcWSrYGfM6"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BTcGA2Po2_nN"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "\n",
        "# Load the JSON file\n",
        "with open(\"./sarcasm.json\", 'r') as f:\n",
        "    datastore = json.load(f)\n",
        "\n",
        "# Initialize the lists\n",
        "sentences = []\n",
        "labels = []\n",
        "\n",
        "# Collect sentences and labels into the lists\n",
        "for item in datastore:\n",
        "    sentences.append(item['headline'])\n",
        "    labels.append(item['is_sarcastic'])"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Parameters**"
      ],
      "metadata": {
        "id": "nPJbqIoOWB5k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "vocab_size = 1000\n",
        "embedding_dim = 16\n",
        "max_length = 120\n",
        "trunc_type = 'post'\n",
        "padding_type = 'post'\n",
        "oov_tok = \"<OOV>\"\n",
        "training_size = 20000"
      ],
      "metadata": {
        "id": "dFEllxGwWBVn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F2zXSds45s2P"
      },
      "source": [
        "# **Split the Dataset**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "baDwTn9S3ENB"
      },
      "outputs": [],
      "source": [
        "# split_size = 0.8\n",
        "# training_size = round(len(labels) * split_size)\n",
        "\n",
        "# Split the sentences\n",
        "training_sentences = sentences[:training_size]\n",
        "testing_sentences = sentences[training_size:]\n",
        "\n",
        "# Split the labels\n",
        "training_labels = labels[:training_size]\n",
        "testing_labels = labels[training_size:]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NdpLY-or5pTP"
      },
      "source": [
        "# **Tokenize Sentences**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RHjZR4oi3LOq"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "# vocab_size = 10000\n",
        "# max_length = 120\n",
        "# trunc_type='post'\n",
        "# padding_type='post'\n",
        "# oov_tok = \"<OOV>\"\n",
        "\n",
        "\n",
        "# Initialize the Tokenizer class\n",
        "tokenizer = Tokenizer(num_words=vocab_size, oov_token=oov_tok)\n",
        "\n",
        "# Generate the word index dictionary\n",
        "tokenizer.fit_on_texts(training_sentences)\n",
        "word_index = tokenizer.word_index\n",
        "\n",
        "# Generate and pad the training sequences\n",
        "training_sequences = tokenizer.texts_to_sequences(training_sentences)\n",
        "training_padded = pad_sequences(training_sequences, maxlen=max_length, padding=padding_type, truncating=trunc_type)\n",
        "\n",
        "# Generate and pad the testing sequences\n",
        "testing_sequences = tokenizer.texts_to_sequences(testing_sentences)\n",
        "testing_padded = pad_sequences(testing_sequences, maxlen=max_length, padding=padding_type, truncating=trunc_type)\n",
        "\n",
        "# Convert the labels lists into numpy arrays\n",
        "training_labels = np.array(training_labels)\n",
        "testing_labels = np.array(testing_labels)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Keras Hyperparameter tuning**"
      ],
      "metadata": {
        "id": "u3C8O4RXH5wz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tf.keras.backend.clear_session()"
      ],
      "metadata": {
        "id": "Ly8Ax0aVH42h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Build the model\n",
        "\n",
        "def build_model(hp):\n",
        "\n",
        "  model_tune = tf.keras.Sequential()\n",
        "  model_tune.add(tf.keras.layers.Embedding(input_dim=vocab_size,\n",
        "                                          #  output_dim=hp.Choice(\"output_dim\", values=[8,16,32,64]),\n",
        "                                           output_dim=embedding_dim,\n",
        "                                           input_length=max_length))\n",
        "\n",
        "  model_type = hp.Choice(\"model_type\", [\"DNN\", \"CNN\", \"GRU\", \"LSTM\"])\n",
        "\n",
        "  with hp.conditional_scope(\"model_type\", [\"DNN\"]):\n",
        "    if model_type == \"DNN\":\n",
        "      model_tune.add(tf.keras.layers.Flatten())\n",
        "\n",
        "      # Tune whether to use dropout.\n",
        "      if hp.Boolean(\"dropout-1\"):\n",
        "        model_tune.add(tf.keras.layers.Dropout(rate=hp.Float('rate-1', min_value=0, max_value=1.0, step=0.1, sampling='linear')))\n",
        "\n",
        "      # Tune whether to use dense layer.\n",
        "      if hp.Boolean(\"dense\"):\n",
        "        model_tune.add(tf.keras.layers.Dense(units=hp.Choice(\"unit-7\", values=[16,32,64,128,256,512,1024]),activation=\"relu\"))\n",
        "\n",
        "  with hp.conditional_scope(\"model_type\", [\"CNN\"]):\n",
        "\n",
        "    if model_type == \"CNN\":\n",
        "      model_tune.add(tf.keras.layers.Conv1D(filters=hp.Choice(\"filters\", values=[16,32,64,128,256]),\n",
        "                     kernel_size=hp.Int('kernel_size', min_value=1, max_value=7, step=1, sampling='linear'),activation='relu'))\n",
        "      model_tune.add(tf.keras.layers.GlobalAveragePooling1D())\n",
        "\n",
        "      # Tune whether to use dropout.\n",
        "      if hp.Boolean(\"dropout-2\"):\n",
        "        model_tune.add(tf.keras.layers.Dropout(rate=hp.Float('rate-2', min_value=0, max_value=1.0, step=0.1, sampling='linear')))\n",
        "\n",
        "  with hp.conditional_scope(\"model_type\", [\"GRU\"]):\n",
        "\n",
        "    if model_type == \"GRU\":\n",
        "\n",
        "      # Tune whether to use additional GRU.\n",
        "      if hp.Boolean(\"gru\"):\n",
        "        model_tune.add(tf.keras.layers.Bidirectional(tf.keras.layers.GRU(units=hp.Choice(\"unit-1\", values=[16,32,64,128,256]), return_sequences=True)))\n",
        "\n",
        "      model_tune.add(tf.keras.layers.Bidirectional(tf.keras.layers.GRU(units=hp.Choice(\"unit-2\", values=[16,32,64,128,256]), return_sequences=True)))\n",
        "      model_tune.add(tf.keras.layers.Bidirectional(tf.keras.layers.GRU(units=hp.Choice(\"unit-3\", values=[16,32,64,128,256]))))\n",
        "\n",
        "  with hp.conditional_scope(\"model_type\", [\"LSTM\"]):\n",
        "\n",
        "    if model_type == \"LSTM\":\n",
        "\n",
        "      if hp.Boolean(\"lstm\"):\n",
        "        model_tune.add(tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(units=hp.Choice(\"unit-4\", values=[16,32,64,128,256]), return_sequences=True)))\n",
        "\n",
        "      model_tune.add(tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(units=hp.Choice(\"unit-5\", values=[16,32,64,128,256]), return_sequences=True)))\n",
        "      model_tune.add(tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(units=hp.Choice(\"unit-6\", values=[16,32,64,128,256]))))\n",
        "\n",
        "  # Dense layers\n",
        "  # model_tune.add(tf.keras.layers.Dense(units=hp.Choice(\"unit\", values=[16,32,64,128,256,512,1024]),activation=\"relu\"))\n",
        "  model_tune.add(tf.keras.layers.Dense(units=hp.Choice(\"unit-8\", values=[16,32,64,128,256,512,1024]),activation=\"relu\"))\n",
        "  model_tune.add(tf.keras.layers.Dense(1, activation='sigmoid'))\n",
        "\n",
        "\n",
        "\n",
        "  # Select optimizer\n",
        "  optimizer=hp.Choice('optimizer', values=['adam', 'RMSprop', 'SGD'])\n",
        "\n",
        "  # Conditional for each optimizer\n",
        "  if optimizer == 'adam':\n",
        "    learning_rate = hp.Float('lrate', min_value=1e-6, max_value=1e-1, sampling='LOG')\n",
        "\n",
        "  elif optimizer == 'RMSprop':\n",
        "    learning_rate = hp.Float('lrate', min_value=1e-6, max_value=1e-1, sampling='LOG')\n",
        "\n",
        "  elif optimizer == 'SGD':\n",
        "    learning_rate = hp.Float('lrate', min_value=1e-6, max_value=1e-1, sampling='LOG')\n",
        "    momentum = hp.Float('momentum', min_value=0, max_value=1.0, step=0.1, sampling='linear')\n",
        "\n",
        "  #compile the model\n",
        "  model_tune.compile(optimizer=optimizer,\n",
        "                loss=tf.keras.losses.BinaryCrossentropy(),\n",
        "                metrics=['accuracy'])\n",
        "\n",
        "  model_tune.summary()\n",
        "\n",
        "  return model_tune"
      ],
      "metadata": {
        "id": "d3FwQ3lAH-EI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "build_model(keras_tuner.HyperParameters())"
      ],
      "metadata": {
        "id": "CcUffHKLebBt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tuner = keras_tuner.BayesianOptimization( #can be Hyperband, RandomSearch, or BayesianOptimization\n",
        "    hypermodel=build_model,\n",
        "    objective=\"val_accuracy\",\n",
        "    max_trials=10,\n",
        "    executions_per_trial=1,\n",
        "    overwrite=True, #Control whether to overwrite the previous results in the same directory or resume the previous search instead.\n",
        "    directory=\"./Model-Tuner\",\n",
        "    project_name=\"KerasTuning\",\n",
        ")"
      ],
      "metadata": {
        "id": "1UfhocZVfV3M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Print summary of search space\n",
        "tuner.search_space_summary()"
      ],
      "metadata": {
        "id": "XxuD3e3mf4o5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Callbacks**"
      ],
      "metadata": {
        "id": "v-I2RnXlgga8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#just clean the sessio, recomendable if we execute some times the model.\n",
        "keras.backend.clear_session()\n",
        "\n",
        "#This callback saves the best model based in val_accuracy\n",
        "\n",
        "\n",
        "MCP = keras.callbacks.ModelCheckpoint(filepath='bestmodel.h5',monitor='val_accuracy',\n",
        "                                          mode='auto',save_best_only=True,save_weights_only=False,verbose=1)\n",
        "\n",
        "RLP = keras.callbacks.ReduceLROnPlateau(monitor=\"val_accuracy\",factor=0.1,patience=5,\n",
        "                                            verbose=1,mode=\"auto\",min_lr=0.000000001)\n",
        "\n",
        "ES = keras.callbacks.EarlyStopping(monitor='val_accuracy',mode='auto', min_delta=1e-4,patience=5,verbose=1)"
      ],
      "metadata": {
        "id": "p9Uhotz3gZNd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tf.keras.backend.clear_session()\n",
        "\n",
        "#Train the model\n",
        "num_epochs = 30\n",
        "\n",
        "# Train the model\n",
        "history = tuner.search(training_padded, training_labels, epochs=num_epochs, validation_data=(testing_padded, testing_labels),\n",
        "                       callbacks=[ES, MCP, RLP, keras.callbacks.TensorBoard(\"./tb_logs\")])"
      ],
      "metadata": {
        "id": "8EmGPMpqgd0A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **View logs on Tensorboard**"
      ],
      "metadata": {
        "id": "EXVA6G7ghWoR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Code to see the results in Tensorboard\n",
        "\n",
        "%load_ext tensorboard\n",
        "# %reload_ext tensorboard\n",
        "\n",
        "%tensorboard --logdir ./tb_logs"
      ],
      "metadata": {
        "id": "n90K-VCqhaMC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Query the results**"
      ],
      "metadata": {
        "id": "X6dnsQXChdaK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from keras_tuner.engine.hyperparameters import HyperParameters\n",
        "\n",
        "# Get the top 2 models.\n",
        "models = tuner.get_best_models(num_models=2).expect_partial()\n",
        "best_model = models[0]\n",
        "best_model.summary()\n"
      ],
      "metadata": {
        "id": "6-eHAKP0hnQ8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Return best 5 trials\n",
        "best_trials = tuner.oracle.get_best_trials(num_trials=10)\n",
        "\n",
        "for trial in best_trials:\n",
        "    print(\"**********Trail id: \", trial.trial_id)\n",
        "    trial.summary()\n",
        "    print('\\n')"
      ],
      "metadata": {
        "id": "MWUuCewzhsaa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# After hyperparameter tuning, retrieve the best hyperparameters.\n",
        "best_hp = tuner.get_best_hyperparameters()[0]\n",
        "best_hp.values"
      ],
      "metadata": {
        "id": "ZrMhqRBfMowS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Save the model**"
      ],
      "metadata": {
        "id": "894tL72bhu0V"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pprint import pprint\n",
        "pprint(best_hp.get_config(), compact=True)"
      ],
      "metadata": {
        "id": "j6TkZgmF_Mj8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# save the model\n",
        "best_model.save('./best/best_model.h5')\n",
        "best_model.save('./best/best_model_new_version')"
      ],
      "metadata": {
        "id": "xA2nbf_vh6qN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Override the best model\n",
        "load first K best models then we need to use tuner's get_best_models method as below"
      ],
      "metadata": {
        "id": "HjdH6f33M37G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# This will load 10 best hyper tuned models with the weights\n",
        "# corresponding to their best checkpoint (at the end of the best epoch of best trial).\n",
        "best_model_count = 10\n",
        "bo_tuner_best_models = tuner.get_best_models(num_models=best_model_count).expect_partial()"
      ],
      "metadata": {
        "id": "CiADg_DBM3OX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Then you can access a specific best model as below:"
      ],
      "metadata": {
        "id": "FWKCTwWnNgL_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "best_model_id = 1\n",
        "override_model = bo_tuner_best_models[best_model_id]\n",
        "override_model.summary()"
      ],
      "metadata": {
        "id": "1MWedY9vNcNh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This method is for querying the models trained during the search. For best performance, it is recommended to retrain your Model on the full dataset using the best hyperparameters found during search, which can be obtained using tuner.get_best_hyperparameters().\n",
        "\n",
        "The best model according to me is second best model"
      ],
      "metadata": {
        "id": "JONAqh9gNHNA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tuner_best_hyperparameters = tuner.get_best_hyperparameters(num_trials=10)\n",
        "best_hp = tuner_best_hyperparameters[1]\n",
        "model_override = tuner.hypermodel.build(best_hp)\n",
        "best_hp.values"
      ],
      "metadata": {
        "id": "5od2CjoqOuBp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Visualize the model**"
      ],
      "metadata": {
        "id": "o8lBCYysiBtC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# !pip install graphviz\n",
        "from tensorflow.keras.utils import plot_model\n",
        "plot_model(model_override, to_file='model_plot.png', show_shapes=True, show_layer_names=True)"
      ],
      "metadata": {
        "id": "4I8Z5zeQiGMy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Retrain the model(optional)**"
      ],
      "metadata": {
        "id": "JvVyiGcciG9Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Build the model with the best hp.\n",
        "# model = build_model(best_hps)\n",
        "model_override = tuner.hypermodel.build(best_hp)\n",
        "\n",
        "num_epochs = 30\n",
        "# Fit with the entire dataset.\n",
        "history = model_override.fit(training_padded, training_labels, epochs=num_epochs, validation_data=(testing_padded, testing_labels),\n",
        "                       callbacks=[ES, MCP, RLP], verbose=2)"
      ],
      "metadata": {
        "id": "nvESEcDriNX-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot training results\n",
        "plot_loss_acc(history)"
      ],
      "metadata": {
        "id": "zbsHETu7iSY0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_override.evaluate(testing_padded, testing_labels)"
      ],
      "metadata": {
        "id": "RkoBLQe2TphV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Trial 09 summary\n",
        "\n",
        "Hyperparameters:\n",
        "\n",
        "model_type: GRU\n",
        "\n",
        "unit-8: 128\n",
        "\n",
        "optimizer: RMSprop\n",
        "\n",
        "lrate: 0.013022460723757403\n",
        "\n",
        "gru: False\n",
        "\n",
        "unit-2: 64\n",
        "\n",
        "unit-3: 64\n",
        "\n",
        "unit-1: 256\n",
        "\n",
        "momentum: 0.30000000000000004\n",
        "\n",
        "Score: 0.8394693732261658"
      ],
      "metadata": {
        "id": "wVOWRVHgTB-2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = tf.keras.Sequential()\n",
        "model.add(tf.keras.layers.Embedding(input_dim=vocab_size,\n",
        "                                           output_dim=embedding_dim,\n",
        "                                           input_length=max_length))\n",
        "\n",
        "# model.add(tf.keras.layers.Bidirectional(tf.keras.layers.GRU(256, return_sequences=True)))\n",
        "model.add(tf.keras.layers.Bidirectional(tf.keras.layers.GRU(64, return_sequences=True)))\n",
        "model.add(tf.keras.layers.Bidirectional(tf.keras.layers.GRU(64)))\n",
        "\n",
        "model.add(tf.keras.layers.Dense(128,activation=\"relu\"))\n",
        "model.add(tf.keras.layers.Dense(1, activation='sigmoid'))\n",
        "\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "5axf_Q_GUNLZ"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "toc_visible": true,
      "machine_shape": "hm",
      "gpuType": "L4",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}